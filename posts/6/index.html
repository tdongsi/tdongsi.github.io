
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Personal Programming Notes</title>
  <meta name="author" content="Cuong Dong-Si">

  
  <meta name="description" content="Amazon Web Services (AWS) is a collection of web services that deliver computing resources (hardware and software) to end-users over the Internet. &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://tdongsi.github.io/posts/6/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Personal Programming Notes" type="application/atom+xml">
  <link href="/stylesheets/data-table.css" media="screen, projection" rel="stylesheet" type="text/css" />
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

<!-- MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Personal Programming Notes</a></h1>
  
    <h2>To err is human; to debug, divine.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="tdongsi.github.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/disclaimer">Disclaimer</a></li>
  <li><a href="/resume">Resume</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/14/aws-building-the-foundation/">AWS: Overview of Services</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-01-14T18:36:45-08:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>14</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>6:36 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Amazon Web Services (AWS) is a collection of web services that deliver computing resources (hardware and software) to end-users over the Internet.
Not all AWS are equal but for AWS beginners, we usually don&rsquo;t know which are more important and which are secondary, supporting services.
Personally, I am initially overwhelmed by the number of services offered as well as large amount of documentation associated with each service.</p>

<p>This post documents my understanding on some key AWS services and concepts. In this post, AWS concepts and services can be divided into layers. Those layers, from bottom up, are:</p>

<ul>
<li>AWS Infrastructure: Physical data centers and physical network connections.</li>
<li>Infrastructure Services (IaaS).</li>
<li>Platform Services (PaaS).</li>
</ul>


<h3>AWS Global Infrastructure</h3>

<p>AWS are available in many locations world-wide. These locations are divided into <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html">regions and Availability Zones</a>.
As of January 2016, there are 11 regions, each <strong>region</strong> contains two or more Availability Zones.
Your resources, such as EC2 instances, reside in the region of your choice.
AWS regions are isolated from each other and you usually cannot access resources in another region.
Furthermore, some newer services may be available in some regions while not in others.</p>

<p>Each <strong>Availability Zone</strong> (AZ) is basically a separate physical data center, and provides low latency connectivity to all other AZs in the same region.
Although you cannot access resources in another region, but you can seamlessly manage resources in different AZs within the same region.
It is recommended that you provision your resources across multiple AZs to achieve redundancy. When a single AZ has a problem, your resources will be still available in other AZs.
For example, S3 stores your data in multiple AZs within your region of choice.</p>

<p><strong>Edge locations</strong> serve requests for CloudFront and Route 53 services. CloudFront is a content delivery network
(CDN), while Route 53 is a DNS service.
Requests going to either one of these services will be automatically routed to the nearest edge location (out of 53 available edge locations, as of Jan 2016). This allows for low latency no matter where the end user is located.</p>

<h3>Infrastructure Services</h3>

<p>AWS offerings are divided into two large groups: Infrastructure and Platform, which are further divided into different categories.
In addition to plain explanation to each service, I added its typical non-cloud, closest equivalent applications or technologies in &ldquo;Use it like&rdquo; column next to &ldquo;AWS name&rdquo; column.
Note that they are just analogies, purely for illustration purposes.
The official service names are in bold (e.g., EC2 and S3), while their respective full names (e.g., Elastic Compute Cloud and Simple Storage Service, respectively) are in brackets.</p>

<p>The grouping of Amazon Web Services as below is purely for review purpose (and remembering their numerous acronyms and names) since these services rarely work alone or are limited to a small group of services.
For example, EC2 instances are usually deployed in some Auto Scaling Groups, all of these groups are in some VPC, accepting traffic from some ELBs.
In a more sophisticated example, you can have some web application running on EC2 instances which store application data in Amazon DynamoDB which, in turn, store its index in some Amazon S3 buckets.
This Amazon DynamoDB have some database &ldquo;triggers&rdquo; implemented with AWS Lambda. These services can be monitored for performance using CloudWatch and access-controlled by IAM.
These examples show that how these AWS offerings can be inter-dependent and inter-connected in practice.</p>

<h4>Compute</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>Amazon EC2</strong> <br/>(Elastic Compute Cloud) </td>
<td> Application server </td>
<td> Remote, virtual server instances. <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html">What is EC2</a> <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html">Instance types</a> <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Tags.html">Tags</a> <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html">Key Pairs</a> <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-vpc.html">EC2 and VPC</a> <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instances-and-amis.html">AMI</a></td>
</tr>
<tr>
<td> <strong>Amazon ELB</strong> <br/>(Elastic Load Balancing) </td>
<td>  </td>
<td> Incoming traffic load balancing. <br/><a href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/how-elb-works.html">ELB</a> <br/><a href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/how-elb-works.html">ELB Terms and Concepts</a></td>
</tr>
<tr>
<td> <strong>AWS Lambda</strong> </td>
<td>  </td>
<td> Like a cluster of one node.</td>
</tr>
<tr>
<td> <strong>Amazon EC2 <br/>Container Service</strong> </td>
<td> </td>
<td> Deployment Service </td>
</tr>
<tr>
<td> <strong>Auto Scaling</strong> </td>
<td> </td>
<td> Scaling <br/><a href="http://docs.aws.amazon.com/AutoScaling/latest/DeveloperGuide/how-as-works.html">Auto Scaling Group</a></td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Networking</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <a href="http://aws.amazon.com/vpc/"><strong>VPC</strong></a> <br>(Virtual Private Cloud) </td>
<td> VLAN </td>
<td> Virtual networking environment. <br/>Interaction with EC2 instances as if you are in the same existing network. </td>
</tr>
<tr>
<td> <strong>Amazon Route 53</strong> </td>
<td> DNS server </td>
<td> DNS service. </td>
</tr>
<tr>
<td> <strong>AWS Direct Connect</strong> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td> <strong>Amazon CloudFront</strong> </td>
<td> CDN </td>
<td> Content delivery service. <br/>Working like a cache for frequently accessed web pages or images to reduce latency. </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Storage</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <a href="http://aws.amazon.com/s3/"><strong>Amazon S3</strong></a> <br/>(Simple Storage Service) </td>
<td> FTP server. </td>
<td> Object store. Not a file system like EBS. <br/> More on <a href="http://stackoverflow.com/questions/2288402/should-i-persist-images-on-ebs-or-s3">S3 vs. EBS</a>.</td>
</tr>
<tr>
<td> <strong>Amazon EBS</strong> <br/>(Elastic Block Storage) </td>
<td> Hard drive to EC2. </td>
<td> Block storage. You can choose file system to format. <br/>You need a EC2 instance attach to it. </td>
</tr>
<tr>
<td> <a href="http://aws.amazon.com/glacier/"><strong>Glacier</strong></a> </td>
<td> <a href="https://en.wikipedia.org/wiki/Memory_hierarchy">Tape backup</a>. </td>
<td> Cold storage for archives, i.e., infrequently accessed files. <br/>It takes much longer to access Glacier files than S3.</td>
</tr>
<tr>
<td> <strong>Elastic File System</strong> </td>
<td> File system. </td>
<td> Currently in Preview. <br/>EBS cannot be connected to multiple EC2 instances. <br/>One Elastic File System instance can be connected to multiple EC2 instances. <br/> More on <a href="http://stackoverflow.com/questions/29575877/aws-efs-vs-ebs-vs-s3-differences-when-to-use">EFS vs. EBS vs. S3</a>.</td>
</tr>
</tbody>
</table>


<p><br/></p>

<!-- 
EBS means you need to manage a volume + machines to attach it to. You need to add space as it's filling up and perform backups (not saying you shouldn't back up your S3 data, just that it's not as critical).

It also makes it harder to scale: when you want to add additional machines, you either need to pull off the images to a separate machine or clone the images across all. This also means you're adding a bottleneck: you'll have to manage your own upload process that will either upload to all machines or have a single machine managing it.

S3 is mostly recommended for static files: like a FTP service. You might want to use EBS if you have a private application that requires private read/write access to some storage.
-->


<h4>Administration &amp; Security</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <a href="http://aws.amazon.com/iam/"><strong>AWS IAM</strong></a></td>
<td> </td>
<td> Manage users, keys, and certificates. <br/>You can set up additional users and new AWS keys, modify policies. <br/>Follow <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html">Best Practices</a></td>
</tr>
<tr>
<td> <strong>CloudWatch</strong> </td>
<td> </td>
<td> Monitoring metrics and performance. </td>
</tr>
<tr>
<td> <strong>CloudTrail</strong> </td>
<td> </td>
<td> Logging calls to services. </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Applications</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>WorkSpaces</strong> </td>
<td> VirtualBox <br/>Remote Desktop </td>
<td> Desktop as a Service. <br/> Cloud-based desktop service with installed common applications. </td>
</tr>
<tr>
<td> <strong>WorkDocs</strong> </td>
<td> </td>
<td> </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h3>Platform Services</h3>

<h4>Databases</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <a href="https://aws.amazon.com/rds/"><strong>RDS</strong></a> <br/>(Relational Database Service) </td>
<td> MySQL, PostgreSQL, etc. <br/>Relational databases. </td>
<td> Managed relational databases in the cloud. <br/>Amazon Aurora, Oracle, Microsoft SQL Server, PostgreSQL, MySQL and MariaDB.</td>
</tr>
<tr>
<td> <a href="https://aws.amazon.com/elasticache/"><strong>ElastiCache</strong></a></td>
<td> Memcached </td>
<td> For information retrieval from memory-based cache nodes instead of slower disk-based databases. <br/>It supports Memcached and Redis caching engine. </td>
</tr>
<tr>
<td> <a href="https://aws.amazon.com/dynamodb/"><strong>DynamoDB</strong></a> </td>
<td> MongoDB </td>
<td> NoSQL database service. </td>
</tr>
<tr>
<td> <a href="https://aws.amazon.com/redshift/"><strong>Redshift</strong></a> </td>
<td> OLAP system </td>
<td> Data warehouse service. </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Analytics</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>Kinesis</strong> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td> <a href="https://aws.amazon.com/elasticmapreduce/"><strong>EMR</strong></a> <br/>(Elastic MapReduce) </td>
<td> MapReduce. </td>
<td> Big Data processing. <br/>Spark is also available.</td>
</tr>
<tr>
<td> <strong>Data Pipeline</strong> </td>
<td> </td>
<td> </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>App Services</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>Cloud Search</strong> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td> <strong>SES</strong> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td> <strong>SWF</strong> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td> <strong>Elastic Transcoder</strong> </td>
<td> </td>
<td> </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Deployment &amp; Management</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>Code Commit</strong> </td>
<td> Git </td>
<td> Source control service.</td>
</tr>
<tr>
<td> <strong>Code Deploy</strong> </td>
<td> </td>
<td> Code deployment service. </td>
</tr>
<tr>
<td> <strong>CloudFormation</strong> </td>
<td> Chef </td>
<td> Infrastructure as Code. <br/>Provisioning using source-controlled codes.</td>
</tr>
<tr>
<td> <strong>Elastic Beanstalk</strong> </td>
<td> </td>
<td> </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Mobile Services</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>SNS</strong> </td>
<td> </td>
<td> Notifications. </td>
</tr>
<tr>
<td> <strong>Cognito</strong> </td>
<td> </td>
<td> Mobile authentication and data syncing. </td>
</tr>
<tr>
<td> <strong>Mobile Analytics</strong> </td>
<td> </td>
<td> Measure and analyze mobile application usage data. </td>
</tr>
</tbody>
</table>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/10/find-and-replace-a-string-in-multiple-files/">Using Virtual Machine for ETL Testing</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-01-10T23:49:15-08:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>10</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>11:49 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h3>Vertica Virtual Machine as sandbox test environment</h3>

<p>When developing data-warehouse solutions in Vertica, you want to set up some test environment.
Ideally, you should have separate schema for each developer.
However, it is usually NOT possible in my experience: developers and test engineers have to share very few schemas in development environment.
The explanation that I usually get is that having a schema for each developer will not scale in database maintenance and administration, and there are likely some limits in Vertica&rsquo;s commercial license.
If that is the case, I recommend that we look into using Vertica Community Edition on <strong>Virtual Machines (VMs)</strong> for sandbox test environment, as a cheap alternative.</p>

<p>Are VMs really necessary in data-warehouse testing? When testing Extract-Transform-Load (ETL) processes, I find that many of test cases require regular set-up and tear-down, adding mock records to force rare logical branches and corner cases, and/or running ETLs multiple times to simulate daily runs of those processes.
Regular tear-down requires dropping multiple tables regularly, which requires much greater care and drains much mental energy when working with others' data and tables.
Similarly, adding mock records into some commonly shared tables might affect others when they assume the data is production-like.
Running ETL scripts regularly, which could be computationally intensive, on a shared Vertica cluster might affect the performance or get affected by others' processes.
In short, for these tests, I cannot use the common schema that is shared with others since it might interfere others and/or destroy valuable common data.
Using a Vertica VM as the sandbox test environment helps us minimize interference to and from others' data and activities.</p>

<h3>Single-node VM and KSAFE clause</h3>

<p>I have been using a <strong>single-node</strong> Vertica VM to run tests for sometime. And it works wonderfully for testing purpose, especially when you want to isolate issues, for example, a corner case. The Vertica VM can be downloaded from HP Vertica&rsquo;s support website (NOTE: As of 2016 Jan 1st, the Vertica 7.1 VM is taken down while the Vertica 7.2 VM is not available).</p>

<p>The only minor problem is when we add <code>KSAFE 1</code> in our DDL scripts (i.e., <code>CREATE TABLE</code> statements) for production purposes. This gives error on single-node VM when running DDL scripts to set up schema.
The reason is that Vertica database with one or two hosts cannot be <em>k-safe</em> (i.e., it may lose data if it crashes) and three-node cluster is the minimum requirement to have <code>KSAFE 1</code> in <code>CREATE TABLE</code> statements to work.</p>

<p>Even then, the workaround for running those DDL scripts in tests is easy enough if all DDL scripts are all located in a single folder. The idea is that since <code>KSAFE 1</code> does not affect ETL processes' transform logics, we can remove those KSAFE clauses to set up the test schema and go ahead with our ETL testing. Specifically, in my project, my workflow for ETL testing with <strong>Git</strong> is as follows:</p>

<ul>
<li>Branch the latest code (<code>develop</code> branch) into a temporary branch (e.g., <code>local/develop</code> branch).</li>
<li>Find and remove <code>KSAFE 1</code> in all DDL files (see subsection below).</li>
<li>While still in <code>local/develop</code> branch, commit all these changes in a <strong>single</strong> commit with some unique description (e.g., &ldquo;KSAFE REMOVAL&rdquo;).</li>
<li>Add unit and functional tests to ETL scripts in this branch.</li>
<li>After tests are properly developed and checked-in, reverse the &ldquo;KSAFE REMOVAL&rdquo; commit above.

<ul>
<li>In SourceTree, it could be done by a simple right-click on that commit and selecting &ldquo;Reverse Commit&rdquo;.</li>
</ul>
</li>
<li>Merge <code>local/develop</code> branch into <code>develop</code> branch (create a pull request if needed). You will now have your tests with the latest codes in <code>develop</code> branch.</li>
</ul>


<h4>Find and replace a string in multiple files</h4>

<p>There are times and times again that you find that you have to replace every single occurrences of some string in multiple files with another string. Finding and removing <code>KSAFE 1</code> like the above workflow is an example where &ldquo;removing string&rdquo; is a special case of &ldquo;replacing string&rdquo; with nothing. This operation can be quickly done by the following bash command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>grep -rl match_string your_dir/ | xargs sed -i 's/old_string/new_string/g'</span></code></pre></td></tr></table></div></figure>


<p>If you are familiar with bash scripting, the above command is straight forward. This quick explanation is for anyone who does not understand the command:</p>

<ul>
<li><code>grep</code> command finds all files in <code>your_dir</code> directory that contain <code>match_string</code>. <code>-l</code> option makes sure it will return a list of files</li>
<li><code>sed</code> command then execute the replacement regex on all those files. A regex tip: the forward slash <code>/</code> delimiter could be another delimiter (e.g., <code>#</code>). This might be useful if you need to search HTML files.</li>
</ul>


<p>Example: In my case, all the DDL scripts are in multiple sub-directories under <code>tables</code> directory. To find and remove all <code>KSAFE 1</code> occurrences, the command is:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>grep -rl 'KSAFE 1' tables | xargs sed -i 's/KSAFE 1//g'</span></code></pre></td></tr></table></div></figure>


<p>This will search for the string <code>KSAFE 1</code> in all files in the <code>tables</code> directory and replace <code>KSAFE 1</code> with nothing <code>''</code> for each occurrence of the string in each file.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/12/18/vertica-tip-find-empty-tables-in-a-schema/">Vertica Tip: Find Empty Tables</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-12-18T21:39:56-08:00'><span class='date'><span class='date-month'>Dec</span> <span class='date-day'>18</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>9:39 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>This post is a reminder of using Vertica&rsquo;s system tables for administrating and monitoring our own tables. One common house-cleaning operation when developing/testing in Vertica is to find and drop tables that are empty (truncated) and never used again.</p>

<p>You might ask why the tables are not dropped directly when I truncated the table in the first place. The answer is that all those tables have some specific designs on projection segmentation and partition, and those information will be lost if I drop the tables. These tables are frequently populated with data and cleared for testing purposes, and truncating and inserting with <code>direct</code> <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/Statements/INSERT.htm">hint</a> will give a significant performance boost (see <a href="/blog/2015/12/16/vertica-tip-best-practices/">Best practices</a>).</p>

<h3>v_monitor schema and COLUMN_STORAGE system table</h3>

<p>The <a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/SystemTables/MONITOR/COLUMN_STORAGE.htm">COLUMN_STORAGE system table</a> in <code>v_monitor</code> schema returns the &ldquo;amount of disk storage used by each column of each projection on each node&rdquo;. Therefore, to get the size of each table, you only need to aggregate the <code>used_byte</code> data, grouped by schema name and table name.</p>

<figure class='code'><figcaption><span>Query to list tables' sizes in a schema</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="n">anchor_table_schema</span><span class="p">,</span> <span class="n">anchor_table_name</span><span class="p">,</span> <span class="k">sum</span><span class="p">(</span><span class="n">used_bytes</span><span class="p">)</span>
</span><span class='line'><span class="k">FROM</span> <span class="n">v_monitor</span><span class="p">.</span><span class="n">column_storage</span>
</span><span class='line'><span class="k">where</span> <span class="n">anchor_table_schema</span> <span class="o">=</span> <span class="s1">&#39;some_schema&#39;</span>
</span><span class='line'><span class="k">group</span> <span class="k">by</span> <span class="n">anchor_table_schema</span><span class="p">,</span> <span class="n">anchor_table_name</span>
</span></code></pre></td></tr></table></div></figure>


<p>According to <a href="http://vertica.tips/2014/01/25/table-size/">here</a>, the number from the above query is the <em>compressed</em> size of the Vertica tables. To get the <em>raw</em> size of the tables, which probably only matters for license limit, perform a <em>license audit</em>, and query the system table <code>license_audits</code> in <code>v_catalog</code> schema. However, the most important takeaway is that empty tables will not appear in this <code>COLUMN_STORAGE</code> system table.</p>

<h3>v_catalog schema and TABLES system table</h3>

<p>The <a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/SystemTables/CATALOG/TABLES.htm">TABLES system table</a> is probably more well-known. It contains all the information about all the tables in all the schemas. For example, to list all the tables in some schema:</p>

<figure class='code'><figcaption><span>Query to list all tables in a schema</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="n">table_schema</span><span class="p">,</span> <span class="k">table_name</span> <span class="k">from</span> <span class="n">tables</span>
</span><span class='line'><span class="k">where</span> <span class="n">table_schema</span> <span class="o">=</span> <span class="s1">&#39;some_schema&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Another useful system table in <code>v_catalog</code> schema is <code>USER_FUNCTIONS</code> which lists all user-defined functions and their function signatures in the database.</p>

<h3>Find all the empty (truncated) tables</h3>

<p>Having all the tables in <code>v_catalog.tables</code> table and only non-empty tables in <code>v_monitor.column_storage</code> table, finding empty tables is pretty straight-forward in SQL:</p>

<figure class='code'><figcaption><span>Query to find empty tables in a schema</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="k">table_name</span>
</span><span class='line'><span class="k">from</span> <span class="n">v_catalog</span><span class="p">.</span><span class="n">tables</span>
</span><span class='line'><span class="k">where</span> <span class="n">table_schema</span> <span class="o">=</span> <span class="s1">&#39;some_schema&#39;</span>
</span><span class='line'><span class="k">EXCEPT</span>
</span><span class='line'><span class="k">select</span> <span class="n">anchor_table_name</span>
</span><span class='line'><span class="k">from</span> <span class="n">v_monitor</span><span class="p">.</span><span class="n">column_storage</span>
</span><span class='line'><span class="k">where</span> <span class="n">anchor_table_schema</span> <span class="o">=</span> <span class="s1">&#39;some_schema&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<h3>External Links</h3>

<ol>
<li><a href="http://vertica.tips/2014/01/25/table-size/">Finding table&rsquo;s compressed size</a></li>
<li><a href="http://vertica.tips/2014/01/24/license-audit-utilization-raw-size/">Vertica License audit</a></li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/SystemTables/MONITOR/COLUMN_STORAGE.htm">COLUMN_STORAGE system table</a></li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/SystemTables/CATALOG/TABLES.htm">TABLES system table</a></li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/SystemTables/CATALOG/USER_FUNCTIONS.htm">USER_FUNCTIONS system table</a></li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/12/17/vertica-tip-using-vsql/">Vertica Tip: Using Vsql CLI</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-12-17T22:54:07-08:00'><span class='date'><span class='date-month'>Dec</span> <span class='date-day'>17</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>10:54 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h3>Using vsql</h3>

<p>You can connect to Vertica database with username and password. When doing this, note that the password might be seen in the command history.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vsql -h internal.vertica.net -p 5433 -d VMart -U vertica_user -w password </span></code></pre></td></tr></table></div></figure>


<p>Or you can connect to Vertica with Kerberos authentication.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vsql -h internal.vertica.net -p 5433 -d VMart -k KerberosServiceName -K KerberosHostName</span></code></pre></td></tr></table></div></figure>


<p>Note that from time to time, you could run into Kerberos GSI failure because the ticket expired. This is how you can renew and extend the ticket: run the following command to refresh Kerberos cache for the headless account <code>vertica_user</code>.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kinit -kt /home/path/to/vertica_user.keytab vertica_user@CORP.INTERNAL.NET</span></code></pre></td></tr></table></div></figure>


<p>You can also run a single SQL command from command line with <code>-c</code> option or, alternatively, a SQL script file with multiple commands with <code>-f</code> option.
These options can be very useful to automate in shell/python scripts.
Note that you can also parameterize your scripts by using <code>-v</code> option to assign variables inside your SQL scripts.</p>

<h3>Vsql meta commands</h3>

<p>Here is list of commonly used vsql <a href="http://my.vertica.com/docs/7.0.x/HTML/index.htm#Authoring/ProgrammersGuide/vsql/Meta-Commands.htm">meta commands</a>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>dbadmin=&gt; \dt — (list of all tables)
</span><span class='line'>dbadmin=&gt; \dt user* — (list of tables starting with user)
</span><span class='line'>dbadmin=&gt; \d tablename — (describe table)
</span><span class='line'>dbadmin=&gt; \dv — (list of all views)</span></code></pre></td></tr></table></div></figure>


<p>Here are the vsql commands to export a file:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>dbadmin=&gt; \o sample_users_lists.csv
</span><span class='line'>dbadmin=&gt; \f|
</span><span class='line'>dbadmin=&gt; select * from my_dwh.users limit 20;
</span><span class='line'>dbadmin=&gt; \o
</span><span class='line'>dbadmin=&gt; \q</span></code></pre></td></tr></table></div></figure>


<h3>External links</h3>

<ol>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/ConnectingToHPVertica/vsql/CommandLineOptions.htm">Command line options</a></li>
<li><a href="http://my.vertica.com/docs/7.0.x/HTML/index.htm#Authoring/ProgrammersGuide/vsql/Meta-Commands.htm">Meta Commands</a></li>
<li><a href="http://my.vertica.com/docs/7.0.x/HTML/index.htm#Authoring/ProgrammersGuide/vsql/Meta-Commands/TheDPATTERNMeta-commands.htm">Meta Commands: \d[Pattern]</a></li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/12/16/vertica-tip-best-practices/">Vertica Tip: Best Practices</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-12-16T23:12:06-08:00'><span class='date'><span class='date-month'>Dec</span> <span class='date-day'>16</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>11:12 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>This post lists some tips and tricks that I learnt when working with Vertica database.</p>

<h3>General Tips and Tricks</h3>

<h4>CREATE (INSERT)</h4>

<ul>
<li><p>If you want to write data directly to disk and bypass memory, then you should include <code>/*+ direct */</code> as a &ldquo;hint&rdquo; in your <code>INSERT</code> statement. This is especially helpful when you are loading data from big files into Vertica. If you don&rsquo;t use <code>/*+ direct */</code>, then <code>INSERT</code> statement first uses memory, which may be more useful when you want to optimally do inserts and run queries.</p></li>
<li><p>ALWAYS include <code>COMMIT</code> in your SQL statements when you are creating or updating Vertica schemas, because there is NO auto commit in Vertica.</p></li>
<li><p>If you are copying a table, <strong>DO NOT</strong> use <code>CREATE TABLE copy AS SELECT * FROM source</code>. This will give you a copy table with default projections and storage policy. Instead, you should use <code>CREATE TABLE</code> statement with the <a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/AdministratorsGuide/Tables/CreatingATableLikeAnother.htm"><code>LIKE existing_table</code> clause</a> and use <code>INSERT /*+ direct */</code> statement. Creating a table with <code>LIKE</code> option replicates the table definition and storage policy associated with the source table, which can make a significant difference in data loading performance. Note that the <code>LIKE</code> clause does not work if the existing source table is a temporary table.</p></li>
</ul>


<figure class='code'><figcaption><span>DO NOT do this</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">create</span> <span class="k">table</span> <span class="n">to_schema</span><span class="p">.</span><span class="n">to_table_name</span>
</span><span class='line'><span class="k">as</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">from_schema</span><span class="p">.</span><span class="n">from_table_name</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>DO this</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">to_schema</span><span class="p">.</span><span class="n">to_table_name</span> <span class="k">LIKE</span> <span class="n">from_schema</span><span class="p">.</span><span class="n">from_table_name</span> <span class="k">INCLUDING</span> <span class="n">PROJECTIONS</span><span class="p">;</span>
</span><span class='line'><span class="k">INSERT</span> <span class="cm">/*+ direct */</span> <span class="k">INTO</span> <span class="n">to_schema</span><span class="p">.</span><span class="n">to_table_name</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">from</span> <span class="n">from_schema</span><span class="p">.</span><span class="n">from_table_name</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Before making a copy of a table, be sure to consider alternatives in order to execute optimal queries: create views, rewrite queries, use sub-queries, limit queries to only a subset of data for analysis.</li>
</ul>


<h4>READ</h4>

<ul>
<li><p>Avoid joining large tables (e.g., > 50M records). Run a <code>count(*)</code> on tables before joining and use <code>MERGE JOIN</code> to optimally join tables. When you use smaller subsets of data, the Vertica Optimizer will pick the <code>MERGE JOIN</code> algorithm instead of the <code>HASH JOIN</code> one, which is less optimal.</p></li>
<li><p>When an approximate value will be enough, Vertica offers an alternative to <code>COUNT(DISTINCT)</code>: <code>APPROXIMATE_COUNT_DISTINCT</code>. This function is recommended when you have a large data set and you do not require an exact count of distinct values: e.g., sanity checks that verify the tables are populated. According to <a href="http://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/AnalyzingData/Optimizations/OptimizingCOUNTDISTINCTByCalculatingApproximateCounts.htm">this documentation</a>, you can get much better performance than <code>COUNT(DISTINCT)</code>. <a href="http://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/Functions/Aggregate/APPROXIMATE_COUNT_DISTINCT.htm">Here</a> is an example of the <code>APPROXIMATE_COUNT_DISTINCT</code> syntax that you should use.</p></li>
</ul>


<h4>UPDATE &amp; DELETE</h4>

<ul>
<li><p>Deletes and updates take exclusive locks on the table. Hence, only one <code>DELETE</code> or <code>UPDATE</code> transaction on that table can be in progress at a time and only when no <code>INSERTs</code> are in progress. Deletes and updates on different tables can be run concurrently.</p></li>
<li><p>Try to avoid <code>DELETE</code> or <code>UPDATE</code> as much as you can, especially on shared Vertica databases. Instead, it may work better to move the data you want to update to a new temporary table, work on that copy, drop the original table, and rename the temporary table with the original table name. For example:</p></li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="n">temp_table</span> <span class="k">LIKE</span> <span class="n">src_table</span> <span class="k">INCLUDING</span> <span class="n">PROJECTIONS</span><span class="p">;</span>
</span><span class='line'><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">temp_table</span> <span class="p">(</span><span class="k">SELECT</span> <span class="k">statement</span> <span class="n">based</span> <span class="k">on</span> <span class="n">the</span> <span class="n">updated</span> <span class="k">data</span> <span class="k">or</span> <span class="n">the</span> <span class="n">needed</span> <span class="k">rows</span><span class="p">);</span>
</span><span class='line'><span class="k">DROP</span> <span class="k">TABLE</span> <span class="n">src_table</span><span class="p">;</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">temp_table</span> <span class="k">RENAME</span> <span class="k">TO</span> <span class="n">src_table</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Delete from tables marks rows with delete vectors and stores them so data can be rolled back to a previous epoch. The data must be eventually purged before the database can reclaim disk space.</li>
</ul>


<h3>Query plan</h3>

<p>A query plan is a sequence of step-like paths that the HP Vertica cost-based query optimizer selects to access or alter information in your HP Vertica database. You can get information about <a href="https://my.vertica.com/docs/7.0.x/HTML/Content/Authoring/AdministratorsGuide/EXPLAIN/HowToGetQueryPlanInformation.htm">query plans</a> by prefixing the SQL query with the <code>EXPLAIN</code> command.</p>

<figure class='code'><figcaption><span>EXPLAIN statement</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">EXPLAIN</span> <span class="k">SELECT</span> <span class="n">customer_name</span><span class="p">,</span> <span class="n">customer_state</span> <span class="k">FROM</span> <span class="n">customer_dimension</span>
</span><span class='line'><span class="k">WHERE</span> <span class="n">customer_state</span> <span class="k">in</span> <span class="p">(</span><span class="s1">&#39;MA&#39;</span><span class="p">,</span><span class="s1">&#39;NH&#39;</span><span class="p">)</span> <span class="k">AND</span> <span class="n">customer_gender</span> <span class="o">=</span> <span class="s1">&#39;Male&#39;</span>
</span><span class='line'><span class="k">ORDER</span> <span class="k">BY</span> <span class="n">customer_name</span> <span class="k">LIMIT</span> <span class="mi">10</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>The output from a query plan is presented in a tree-like structure, where each step path represents a single operation in the database that the optimizer uses for its execution strategy. The following example output is based on the previous query:</p>

<figure class='code'><figcaption><span>Query Plan description</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>EXPLAIN SELECT
</span><span class='line'>customer_name,
</span><span class='line'>customer_state
</span><span class='line'>FROM customer_dimension
</span><span class='line'>WHERE customer_state in <span class="o">(</span><span class="s1">&#39;MA&#39;</span>,<span class="s1">&#39;NH&#39;</span><span class="o">)</span>
</span><span class='line'>AND <span class="nv">customer_gender</span> <span class="o">=</span> <span class="s1">&#39;Male&#39;</span>
</span><span class='line'>ORDER BY customer_name
</span><span class='line'>LIMIT 10<span class="p">;</span>
</span><span class='line'>Access Path:
</span><span class='line'>+-SELECT  LIMIT <span class="m">10</span> <span class="o">[</span>Cost: 370, Rows: 10<span class="o">]</span> <span class="o">(</span>PATH ID: 0<span class="o">)</span>
</span><span class='line'><span class="p">|</span>  Output Only: <span class="m">10</span> tuples
</span><span class='line'><span class="p">|</span>  Execute on: Query Initiator
</span><span class='line'><span class="p">|</span> +---&gt; SORT <span class="o">[</span>Cost: 370, Rows: 544<span class="o">]</span> <span class="o">(</span>PATH ID: 1<span class="o">)</span>
</span><span class='line'><span class="p">|</span> <span class="p">|</span>      Order: customer_dimension.customer_name ASC
</span><span class='line'><span class="p">|</span> <span class="p">|</span>      Output Only: <span class="m">10</span> tuples
</span><span class='line'><span class="p">|</span> <span class="p">|</span>      Execute on: Query Initiator
</span><span class='line'><span class="p">|</span> <span class="p">|</span> +---&gt; STORAGE ACCESS <span class="k">for</span> customer_dimension <span class="o">[</span>Cost: 331, Rows: 544<span class="o">]</span> <span class="o">(</span>PATH ID: 2<span class="o">)</span>
</span><span class='line'><span class="p">|</span> <span class="p">|</span> <span class="p">|</span>      Projection: public.customer_dimension_DBD_1_rep_vmartdb_design_vmartdb_design_node0001
</span><span class='line'><span class="p">|</span> <span class="p">|</span> <span class="p">|</span>      Materialize: customer_dimension.customer_state, customer_dimension.customer_name
</span><span class='line'><span class="p">|</span> <span class="p">|</span> <span class="p">|</span>      Filter: <span class="o">(</span>customer_dimension.customer_gender <span class="o">=</span> <span class="s1">&#39;Male&#39;</span><span class="o">)</span>
</span><span class='line'><span class="p">|</span> <span class="p">|</span> <span class="p">|</span>      Filter: <span class="o">(</span>customer_dimension.customer_state <span class="o">=</span> ANY <span class="o">(</span>ARRAY<span class="o">[</span><span class="s1">&#39;MA&#39;</span>, <span class="s1">&#39;NH&#39;</span><span class="o">]))</span>
</span><span class='line'><span class="p">|</span> <span class="p">|</span> <span class="p">|</span>      Execute on: Query Initiator
</span></code></pre></td></tr></table></div></figure>


<p>If you want to understand the details of the query plan, observe the real-time flow of data through the plan to identify possible query bottlenecks, you can:</p>

<ol>
<li>query the <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/SystemTables/MONITOR/QUERY_PLAN_PROFILES.htm">V_MONITOR.QUERY_PLAN_PROFILES</a> system table.</li>
<li>review <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/AdministratorsGuide/Profiling/ProfilingQueryPlanProfiles.htm">Profiling Query Plans</a>.</li>
<li>use <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/Statements/PROFILE.htm">PROFILE</a> statement to view further detailed analysis of your query.</li>
</ol>


<h3>External Links</h3>

<ol>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm">Vertica documentation</a></li>
<li><a href="http://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/Functions/Aggregate/APPROXIMATE_COUNT_DISTINCT.htm">APPROXIMATE_COUNT_DISTINCT</a></li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/AdministratorsGuide/Tables/CreatingATableLikeAnother.htm">Create a Table Like Another</a></li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/SystemTables/MONITOR/QUERY_PLAN_PROFILES.htm">V_MONITOR.QUERY_PLAN_PROFILES</a> system table.</li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/AdministratorsGuide/Profiling/ProfilingQueryPlanProfiles.htm">Profiling Query Plans</a>.</li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/Statements/PROFILE.htm">PROFILE</a> statement.</li>
</ol>

</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/7">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/posts/5">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
    <h1>About Me</h1>
    <p>I write about random things that come to mind, mostly for my future self and any visitor who might find useful.</p>
</section><section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/04/25/convert-python-objects-to-json-ordered-keys/">Convert Python Objects to JSON (Ordered Keys)</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/04/21/convert-python-objects-to-json/">Convert Python Objects to JSON</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/04/20/rabin-miller-primality-test/">Rabin-Miller Primality Test</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/04/18/best-friend-forever/">Best Friend Forever</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/04/17/sql-unit-data-parity/">(Pt. 7) Extending for Data Parity Checks</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/tdongsi">@tdongsi</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'tdongsi',
            count: 5,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section>
  <h1>Categories</h1>
    <ul id="category-list"><li><a href='/blog/categories/algorithm/'>algorithm (2)</a></li><li><a href='/blog/categories/automation/'>automation (13)</a></li><li><a href='/blog/categories/aws/'>aws (4)</a></li><li><a href='/blog/categories/bash/'>bash (5)</a></li><li><a href='/blog/categories/book/'>book (9)</a></li><li><a href='/blog/categories/cassandra/'>cassandra (1)</a></li><li><a href='/blog/categories/centos/'>centos (4)</a></li><li><a href='/blog/categories/cloudera/'>cloudera (2)</a></li><li><a href='/blog/categories/database/'>database (6)</a></li><li><a href='/blog/categories/eclipse/'>eclipse (1)</a></li><li><a href='/blog/categories/git/'>git (2)</a></li><li><a href='/blog/categories/hadoop/'>hadoop (10)</a></li><li><a href='/blog/categories/hdfs/'>hdfs (1)</a></li><li><a href='/blog/categories/hive/'>hive (8)</a></li><li><a href='/blog/categories/java/'>java (11)</a></li><li><a href='/blog/categories/jdbc/'>jdbc (2)</a></li><li><a href='/blog/categories/jmockit/'>jmockit (1)</a></li><li><a href='/blog/categories/junit/'>junit (1)</a></li><li><a href='/blog/categories/macosx/'>macosx (4)</a></li><li><a href='/blog/categories/math/'>math (2)</a></li><li><a href='/blog/categories/matplotlib/'>matplotlib (2)</a></li><li><a href='/blog/categories/maven/'>maven (1)</a></li><li><a href='/blog/categories/netezza/'>netezza (2)</a></li><li><a href='/blog/categories/numpy/'>numpy (1)</a></li><li><a href='/blog/categories/performance/'>performance (4)</a></li><li><a href='/blog/categories/perl/'>perl (1)</a></li><li><a href='/blog/categories/python/'>python (8)</a></li><li><a href='/blog/categories/security/'>security (1)</a></li><li><a href='/blog/categories/sql/'>sql (19)</a></li><li><a href='/blog/categories/sqlite/'>sqlite (1)</a></li><li><a href='/blog/categories/testing/'>testing (12)</a></li><li><a href='/blog/categories/ubuntu/'>ubuntu (2)</a></li><li><a href='/blog/categories/unicode/'>unicode (1)</a></li><li><a href='/blog/categories/vertica/'>vertica (14)</a></li><li><a href='/blog/categories/vmware/'>vmware (1)</a></li><li><a href='/blog/categories/windows/'>windows (2)</a></li></ul>
</section>



  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - Cuong Dong-Si -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
