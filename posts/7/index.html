
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Personal Programming Notes</title>
  <meta name="author" content="Cuong Dong-Si">

  
  <meta name="description" content="The Amazon Resource Name (ARN) is used to uniquely identify an AWS resource. You will need to use ARNs to connect your services and data in AWS. &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://tdongsi.github.io/posts/7/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Personal Programming Notes" type="application/atom+xml">
  <link href="/stylesheets/data-table.css" media="screen, projection" rel="stylesheet" type="text/css" />
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

<!-- MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Personal Programming Notes</a></h1>
  
    <h2>To err is human; to debug, divine.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="tdongsi.github.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/disclaimer">Disclaimer</a></li>
  <li><a href="/resume">Resume</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/19/aws-connecting-applications-and-data/">AWS: Amazon Resource Name</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-01-19T18:37:02-08:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>19</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>6:37 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>The <a href="http://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html">Amazon Resource Name</a> (ARN) is used to uniquely identify an AWS resource. You will need to use ARNs to connect your services and data in AWS.</p>

<p>Format:</p>

<ul>
<li>arn:partition:service:region:account-id:resource</li>
<li>arn:partition:service:region:account-id:resourcetype/resource</li>
<li>arn:partition:service:region:account-id:resourcetype:resource</li>
</ul>


<p>Examples:</p>

<ul>
<li>Amazon DynamoDB table: <code>arn:aws:dynamodb:us-west-2:558892968354:table/accounts</code></li>
<li>Amazon S3 bucket: <code>arn:aws:s3:::survey_bucket/*</code></li>
<li>Amazon SNS topic: <code>arn:aws:sns:us-west-2:558892968354:EmailSNSTopic</code></li>
<li>SNS topic subscription ID: <code>arn:aws:sns:us-west-2:558892968354:EmailSNSTopic:3c31c16b-3d53-48a6-ba54-385a06c29a45</code></li>
</ul>


<p>The components of the ARN are:</p>

<ul>
<li>Partition: The partition that the resource is in. For standard AWS regions, the partition is <code>aws</code>. If you have resources in other partitions, the partition is <code>aws-[partitionname]</code>. For example, the partition for resources in the China region is <code>aws-cn</code>.</li>
<li>Service: The service namespace that identifies the AWS product (for example, <code>s3</code>, <code>sns</code>).</li>
<li>Region: The region that the resource resides in (for example, <code>us-west-2</code>). Some services are global, such as S3. Those services do not require a region specified.</li>
<li>Account: The ID of the AWS account that owns the resource, without the hyphens, for example, <code>558892968354</code>. Note that the ARNs for some resources don&rsquo;t require an account number.</li>
<li><code>Resource</code>, <code>resourcetype:resource</code>, or <code>resourcetype/resource</code>: The content of this part of the ARN varies by service, as shown in examples above. Some services allows paths for resource names.</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/18/aws-developing-with-amazon-s3/">AWS: Developing With Amazon S3</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-01-18T17:13:28-08:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>18</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>5:13 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Amazon Simple Storage Service or S3 is a simple, scalable web services to store and retrieve data.
This post talks about basic concepts of buckets and objects in S3, basic and advanced operations on objects in S3, and standard development considerations when working with S3 using SDK.</p>

<h3>S3 Buckets and Objects</h3>

<p>Files of any kind such as text, video, photo are stored as objects in S3 <em>buckets</em>.
The bucket name must be globally unique across Amazon S3. It is your responsibility to ensure uniqueness of the bucket name.
A bucket can be <em>versioning-enabled</em>, it will store every version of every object in the bucket.</p>

<p>Each <em>object</em> in S3 is identified by a unique key. The object key is used for upload and retrieval. Alphanumeric characters and <code>!-_.*'/</code> are allowed in a key name.</p>

<p>Bucket naming tips:</p>

<ul>
<li>To ensure uniqueness, you might prefix the bucket name with the name of your organization.</li>
<li>Avoid using a period in the bucket name. Buckets that have a period in the bucket name can cause certificate exception when accessing with HTTPS-based URLs.</li>
</ul>


<p>Object key naming tips:</p>

<ul>
<li>Use prefixes and <code>/</code> (or other delimiters) to logically group your objects. For example, <code>prog/java/arrays.html</code>. There is no hierarchy of objects (e.g., folder) or nested buckets in S3.

<ul>
<li>However, the Amazon S3 console supports the <a href="http://docs.aws.amazon.com/AmazonS3/latest/UG/FolderOperations.html">folder concept</a> for convenience and usability. Amazon S3 does this by using key name prefixes for objects.</li>
</ul>
</li>
<li>For performance and scalability, consider using hash as the outermost prefix, in addition to other logical grouping prefixes. See &ldquo;Programming Considerations&rdquo; section below.</li>
</ul>


<h3>Operations on Objects</h3>

<p>Basic operations on S3 objects and buckets are:</p>

<ul>
<li>Put: upload or copy object, up to 5 GB. You can use multi-part upload API for larger objects up to 5 TB.</li>
<li>Get: Retrieve a whole object or part of an object.</li>
<li><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/ListingKeysHierarchy.html">List Keys</a>: List object keys by prefix and delimiter.</li>
<li>Delete: Delete one or more objects.

<ul>
<li>If versioning is not enabled, an object is permanently deleted by specifying its key.</li>
<li>If versioning is enabled, you delete an object by specifying a key and version ID. You must delete all versions of an object to remove it.</li>
<li>If versioning is enabled and version is not specified, S3 adds a delete marker to current version of the object. Trying to retrieve an object with a delete marker will returns a &ldquo;404 Not Found&rdquo; error by S3.</li>
</ul>
</li>
<li>Restore: Restore an object archived on Amazon Glacier.</li>
</ul>


<h4>Other operations in S3</h4>

<p>Advanced operations that you should know when situations arise.</p>

<p><strong>Scenario 1</strong>: You want to let users upload files to your buckets for some time duration.
<strong>Solution 1</strong>: You should never share your AWS credentials to let users upload files to your buckets.
Instead, generate a <strong>pre-signed URL</strong> with your security credentials, bucket name, object key, HTTP method (PUT or GET), and expiration date and time.
You share this pre-signed URL to users who will use this to access your S3 buckets.</p>

<p><strong>Scenario 2</strong>: Encryption and strict data security is required.
<strong>Solution 2</strong>: You can enable:</p>

<ul>
<li>Securing data in transit.

<ul>
<li>SSL-encrypted data transfer by using HTTPS</li>
<li><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingClientSideEncryption.html">Client-side encryption</a></li>
</ul>
</li>
<li>Securing data at rest on AWS server.

<ul>
<li><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html">Server-side encryption</a></li>
</ul>
</li>
</ul>


<p><strong>Scenario 3</strong>: You want your web applications that are loaded in one domain to interact with S3 resources in a different domain.
<strong>Solution 3</strong>: Check out <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html">CORS</a>.</p>

<h3>Programming considerations</h3>

<ul>
<li>According to <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/request-rate-perf-considerations.html">this guideline</a>, <strong>avoid</strong> using some sequential prefix (e.g., timestamp or alphabetical sequence) for your objects' key names. Instead, prefix the key name with its hash and, optionally, store the original key name in the object&rsquo;s metadata. See examples in the link for more information.</li>
<li>If your application uses fixed buckets, avoid unnecessary requests by checking the existence of buckets. Instead, handle <a href="http://docs.aws.amazon.com/AmazonS3/latest/API/ErrorResponses.html">NoSuchBucket errors</a> when buckets do not exist.</li>
<li>Set the object metadata before uploading an object. Otherwise, you will have extra requests to do copy operation to update metadata.</li>
<li>Cache bucket and key names if possible.</li>
<li>Set bucket region closest to latency-sensitive users.</li>
<li>Compress objects to reduce the size of data transferred and storage used.</li>
<li>Use an exponential back-off algorithm to retry after failed connection attempts. See <a href="http://docs.aws.amazon.com/general/latest/gr/api-retries.html">here</a>.</li>
<li>Enable application logging. For example, <a href="http://docs.aws.amazon.com/AWSSdkDocsJava/latest/DeveloperGuide/java-dg-logging.html">in Java</a>.</li>
<li>Enable <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html">server access logging</a>.</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/17/aws-set-up-aws-credentials-on-mac-osx/">AWS: Getting Started on Mac OSX</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-01-17T20:57:35-08:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>17</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>8:57 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>First, you need to set up your AWS credentials on your Mac by creating the following files at the following specific locations:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MTVL1288aeea2-82:~ cdongsi$ mkdir ~/.aws
</span><span class='line'>MTVL1288aeea2-82:~ cdongsi$ touch ~/.aws/credentials
</span><span class='line'>MTVL1288aeea2-82:~ cdongsi$ touch ~/.aws/config</span></code></pre></td></tr></table></div></figure>


<p>In Windows, the locations of those files will be <code>C:\Users\USERNAME\.aws\credentials</code> and <code>C:\Users\USERNAME\.aws\config</code>, respectively.
You <em>must</em> fill in your AWS access credentials (Access Key ID and Secret Access Key) into the file <code>credentials</code>. Optionally, you can set the default region in the <code>config</code> file.
The content of the files will look like the following:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MTVL1288aeea2-82:~ cdongsi$ cat ~/.aws/credentials
</span><span class='line'>[default]
</span><span class='line'>aws_access_key_id = your_access_key_id
</span><span class='line'>aws_secret_access_key = your_secret_access_key
</span><span class='line'>
</span><span class='line'>MTVL1288aeea2-82:~ cdongsi$ cat ~/.aws/config
</span><span class='line'>[default]
</span><span class='line'>region=us-west-2</span></code></pre></td></tr></table></div></figure>


<h3>HelloAws using Java</h3>

<p>Now, you can install AWS Toolkit for Eclipse from <a href="http://aws.amazon.com/eclipse/">this link</a>. Follow the instruction in that page to install AWS Toolkit.</p>

<p>After AWS Toolkit is installed, you are ready to run the first <code>HelloAws</code> Java application. In Eclipse, create a AWS Console application.</p>

<ol>
<li>Click the new orange button on Eclipse taskbar named &ldquo;AWS Toolkit for Eclipse&rdquo;.</li>
<li>Click the link named &ldquo;Create a New AWS Java Project&rdquo;.</li>
<li>Fill in &ldquo;Project name&rdquo; as &ldquo;HelloAws&rdquo;. Check &ldquo;AWS Console Application&rdquo; from &ldquo;AWS SDK for Java Samples&rdquo; panel.</li>
</ol>


<p>Note that the sample generated has the following instruction in its main class. If you haven&rsquo;t do it, follow the steps above to set up your AWS access credentials.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">AwsConsoleApp</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="cm">/*</span>
</span><span class='line'><span class="cm">     * Before running the code:</span>
</span><span class='line'><span class="cm">     *      Fill in your AWS access credentials in the provided credentials</span>
</span><span class='line'><span class="cm">     *      file template, and be sure to move the file to the default location</span>
</span><span class='line'><span class="cm">     *      (/Users/cdongsi/.aws/credentials) where the sample code will load the</span>
</span><span class='line'><span class="cm">     *      credentials from.</span>
</span><span class='line'><span class="cm">     *      https://console.aws.amazon.com/iam/home?#security_credential</span>
</span><span class='line'><span class="cm">     *</span>
</span><span class='line'><span class="cm">     * WARNING:</span>
</span><span class='line'><span class="cm">     *      To avoid accidental leakage of your credentials, DO NOT keep</span>
</span><span class='line'><span class="cm">     *      the credentials file in your source directory.</span>
</span><span class='line'><span class="cm">     */</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">static</span> <span class="n">AmazonEC2</span>      <span class="n">ec2</span><span class="o">;</span>
</span><span class='line'>    <span class="kd">static</span> <span class="n">AmazonS3</span>       <span class="n">s3</span><span class="o">;</span>
</span><span class='line'>    <span class="kd">static</span> <span class="n">AmazonSimpleDB</span> <span class="n">sdb</span><span class="o">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>If your AWS credentials are ready, simply run the sample AWS console code as &ldquo;Java Application&rdquo;. The output will look something like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>===========================================
</span><span class='line'>Welcome to the AWS Java SDK!
</span><span class='line'>===========================================
</span><span class='line'>You have access to 4 Availability Zones.
</span><span class='line'>You have 0 Amazon EC2 instance(s) running.
</span><span class='line'>You have 0 Amazon SimpleDB domain(s)containing a total of 0 items.
</span><span class='line'>You have 0 Amazon S3 bucket(s), containing 0 objects with a total size of 0 bytes.</span></code></pre></td></tr></table></div></figure>


<h3>HelloAws using Python</h3>

<p>To install <a href="http://aws.amazon.com/sdk-for-python/">AWS SDK for Python</a>, run the following the command as instructed in that page:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pip install boto3
</span></code></pre></td></tr></table></div></figure>


<p>In my case, I used a slightly different command to avoid permission errors on Mac OSX:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pip install boto3 --user</span></code></pre></td></tr></table></div></figure>


<p>I use PyCharm/IntelliJ as IDE for Python and, apparently, there is no Python sample for it. In PyCharm, you can use the following Python script as your <code>HelloAws</code> program:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">boto3</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">botocore.exceptions</span> <span class="kn">import</span> <span class="n">ClientError</span><span class="p">,</span><span class="n">NoCredentialsError</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">sys</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">getS3BucketNumber</span><span class="p">():</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">try</span><span class="p">:</span>
</span><span class='line'>        <span class="n">s3</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">resource</span><span class="p">(</span><span class="s">&#39;s3&#39;</span><span class="p">)</span>
</span><span class='line'>        <span class="n">buckets</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="k">except</span> <span class="n">NoCredentialsError</span><span class="p">:</span>
</span><span class='line'>        <span class="k">print</span> <span class="s">&quot;No AWS Credentials&quot;</span>
</span><span class='line'>        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">try</span><span class="p">:</span>
</span><span class='line'>        <span class="n">bucket_num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">s3</span><span class="o">.</span><span class="n">buckets</span><span class="o">.</span><span class="n">all</span><span class="p">()))</span>
</span><span class='line'>        <span class="k">print</span> <span class="s">&quot;Number of buckets: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bucket_num</span><span class="p">)</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">bucket_num</span>
</span><span class='line'>    <span class="k">except</span> <span class="n">ClientError</span> <span class="k">as</span> <span class="n">ex</span><span class="p">:</span>
</span><span class='line'>        <span class="k">print</span><span class="p">(</span><span class="n">ex</span><span class="p">)</span>
</span><span class='line'>        <span class="k">return</span> <span class="mi">0</span>
</span><span class='line'>
</span><span class='line'><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&#39;__main__&#39;</span><span class="p">:</span>
</span><span class='line'>    <span class="n">getS3BucketNumber</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that it is based on the <a href="https://github.com/boto/boto3#quick-start">Quick start on Github</a>. In PyCharm, running the above Python should print the following output:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Number of buckets: 0</span></code></pre></td></tr></table></div></figure>


<h3>Quick note on Python API vs. Java API</h3>

<p>Note that Boto3 SDK for Python support <a href="http://boto3.readthedocs.org/en/latest/guide/resources.html">&ldquo;Resource API&rdquo;</a>.
As opposed to &ldquo;Service Client API&rdquo; like AWS SDK for Java, Resource API provides a higher level interface to the service and it is easier to understand and simpler to use.</p>

<p>For example, the generated example for AWS&rsquo;s Java SDK uses a Service Client API. It uses a class AmazonS3Client that controls the requests you make to the S3 service.
Meanwhile, the Boto3 SDK for Python has classes representing the conceptual resources (e.g., s3.Bucket) that you interact with when using the S3 service.
This is a higher level abstraction compared to a client class like AmazonS3Client making low-level calls to the service API.</p>

<h3>External Links</h3>

<ul>
<li>Python

<ul>
<li><a href="https://boto3.readthedocs.org/en/latest/guide/index.html">Developer Guide</a></li>
<li><a href="https://boto3.readthedocs.org/en/latest/reference/core/index.html">API Documentation</a></li>
</ul>
</li>
<li>Java

<ul>
<li><a href="http://docs.aws.amazon.com/AWSSdkDocsJava/latest/DeveloperGuide/welcome.html">Developer Guide</a></li>
<li><a href="http://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/index.html">API Documentation</a></li>
</ul>
</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/14/aws-overview-of-services/">AWS: Overview of Services</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-01-14T18:36:45-08:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>14</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>6:36 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Amazon Web Services (AWS) is a collection of web services that deliver computing resources (hardware and software) to end-users over the Internet.
Not all AWS are equal but for AWS beginners, we usually don&rsquo;t know which are more important and which are secondary, supporting services.
Personally, I am initially overwhelmed by the number of services offered as well as large amount of documentation associated with each service.</p>

<p>This post documents my understanding on some key AWS services and concepts. In this post, AWS concepts and services can be divided into layers. Those layers, from bottom up, are:</p>

<ul>
<li>AWS Infrastructure: Physical data centers and physical network connections.</li>
<li>Infrastructure Services (IaaS).</li>
<li>Platform Services (PaaS).</li>
</ul>


<h3>AWS Global Infrastructure</h3>

<p>AWS are available in many locations world-wide. These locations are divided into <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html">regions and Availability Zones</a>.
As of January 2016, there are 11 regions, each <strong>region</strong> contains two or more Availability Zones.
Your resources, such as EC2 instances, reside in the region of your choice.
AWS regions are isolated from each other and you usually cannot access resources in another region.
Furthermore, some newer services may be available in some regions while not in others.</p>

<p>Each <strong>Availability Zone</strong> (AZ) is basically a separate physical data center, and provides low latency connectivity to all other AZs in the same region.
Although you cannot access resources in another region, but you can seamlessly manage resources in different AZs within the same region.
It is recommended that you provision your resources across multiple AZs to achieve redundancy. When a single AZ has a problem, your resources will be still available in other AZs.
For example, S3 stores your data in multiple AZs within your region of choice.</p>

<p><strong>Edge locations</strong> serve requests for CloudFront and Route 53 services. CloudFront is a content delivery network
(CDN), while Route 53 is a DNS service.
Requests going to either one of these services will be automatically routed to the nearest edge location (out of 53 available edge locations, as of Jan 2016). This allows for low latency no matter where the end user is located.</p>

<h3>Infrastructure Services</h3>

<p>AWS offerings are divided into two large groups: Infrastructure and Platform, which are further divided into different categories.
In addition to plain explanation to each service, I added its typical non-cloud, closest equivalent applications or technologies in &ldquo;Use it like&rdquo; column next to &ldquo;AWS name&rdquo; column.
Note that they are just analogies, purely for illustration purposes.
The official service names are in bold (e.g., EC2 and S3), while their respective full names (e.g., Elastic Compute Cloud and Simple Storage Service, respectively) are in parentheses.</p>

<p>The grouping of Amazon Web Services as below is purely for review purpose (and remembering their numerous acronyms and names) since these services rarely work alone or are limited to a small group of services.
For example, EC2 instances are usually deployed in some Auto Scaling Groups, all of these groups are in some VPC, accepting traffic from some ELBs.
In a more sophisticated example, you can have some web application running on EC2 instances which store application data in Amazon DynamoDB which, in turn, store its index in some Amazon S3 buckets.
This Amazon DynamoDB have some database &ldquo;triggers&rdquo; implemented with AWS Lambda. These services can be monitored for performance using CloudWatch and access-controlled by IAM.
These examples show that how these AWS offerings can be inter-dependent and inter-connected in practice.</p>

<h4>Compute</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>Amazon EC2</strong> <br/>(Elastic Compute Cloud) </td>
<td> Application server </td>
<td> Remote, virtual server instances. <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html">What is EC2</a> <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html">Instance types</a> <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Tags.html">Tags</a> <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html">Key Pairs</a> <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-vpc.html">EC2 and VPC</a> <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instances-and-amis.html">AMI</a></td>
</tr>
<tr>
<td> <strong>Amazon ELB</strong> <br/>(Elastic Load Balancing) </td>
<td>  </td>
<td> Incoming traffic load balancing. <br/><a href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/how-elb-works.html">ELB</a> <br/><a href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/how-elb-works.html">ELB Terms and Concepts</a></td>
</tr>
<tr>
<td> <strong>AWS Lambda</strong> </td>
<td>  </td>
<td> Like a cluster of one node.</td>
</tr>
<tr>
<td> <strong>Amazon EC2 <br/>Container Service</strong> </td>
<td> </td>
<td> Deployment Service </td>
</tr>
<tr>
<td> <strong>Auto Scaling</strong> </td>
<td> </td>
<td> Scaling <br/><a href="http://docs.aws.amazon.com/AutoScaling/latest/DeveloperGuide/how-as-works.html">Auto Scaling Group</a></td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Networking</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <a href="http://aws.amazon.com/vpc/"><strong>VPC</strong></a> <br>(Virtual Private Cloud) </td>
<td> VLAN </td>
<td> Virtual networking environment. <br/>Interaction with EC2 instances as if you are in the same existing network. </td>
</tr>
<tr>
<td> <strong>Amazon Route 53</strong> </td>
<td> DNS server </td>
<td> DNS service. <br/>Use Route 53 for <em>cross-region</em> failover configuration. </td>
</tr>
<tr>
<td> <strong>AWS Direct Connect</strong> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td> <strong>Amazon CloudFront</strong> </td>
<td> CDN </td>
<td> Content delivery service. <br/>Working like a cache for frequently accessed web pages or images to reduce latency. </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Storage</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <a href="http://aws.amazon.com/s3/"><strong>Amazon S3</strong></a> <br/>(Simple Storage Service) </td>
<td> FTP server. </td>
<td> Object store. Not a file system like EBS. <br/> More on <a href="http://stackoverflow.com/questions/2288402/should-i-persist-images-on-ebs-or-s3">S3 vs. EBS</a>.</td>
</tr>
<tr>
<td> <strong>Amazon EBS</strong> <br/>(Elastic Block Storage) </td>
<td> Hard drive to EC2. </td>
<td> Block storage. You can choose file system to format. <br/>You need a EC2 instance attach to it. </td>
</tr>
<tr>
<td> <a href="http://aws.amazon.com/glacier/"><strong>Glacier</strong></a> </td>
<td> <a href="https://en.wikipedia.org/wiki/Memory_hierarchy">Tape backup</a>. </td>
<td> Cold storage for archives, i.e., infrequently accessed files. <br/>It takes much longer to access Glacier files than S3.</td>
</tr>
<tr>
<td> <strong>Elastic File System</strong> </td>
<td> File system. </td>
<td> Currently in Preview. <br/>EBS cannot be connected to multiple EC2 instances. <br/>One Elastic File System instance can be connected to multiple EC2 instances. <br/> More on <a href="http://stackoverflow.com/questions/29575877/aws-efs-vs-ebs-vs-s3-differences-when-to-use">EFS vs. EBS vs. S3</a>.</td>
</tr>
</tbody>
</table>


<p><br/></p>

<!-- 
EBS means you need to manage a volume + machines to attach it to. You need to add space as it's filling up and perform backups (not saying you shouldn't back up your S3 data, just that it's not as critical).

It also makes it harder to scale: when you want to add additional machines, you either need to pull off the images to a separate machine or clone the images across all. This also means you're adding a bottleneck: you'll have to manage your own upload process that will either upload to all machines or have a single machine managing it.

S3 is mostly recommended for static files: like a FTP service. You might want to use EBS if you have a private application that requires private read/write access to some storage.
-->


<h4>Administration &amp; Security</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <a href="http://aws.amazon.com/iam/"><strong>AWS IAM</strong></a></td>
<td> </td>
<td> Manage users, keys, and certificates. <br/>You can set up additional users and new AWS keys, modify policies. <br/>Follow <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html">Best Practices</a></td>
</tr>
<tr>
<td> <strong>CloudWatch</strong> </td>
<td> </td>
<td> Monitoring metrics and performance. </td>
</tr>
<tr>
<td> <strong>CloudTrail</strong> </td>
<td> </td>
<td> Logging calls to services. </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Applications</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>WorkSpaces</strong> </td>
<td> VirtualBox <br/>Remote Desktop </td>
<td> Desktop as a Service. <br/> Cloud-based desktop service with installed common applications. </td>
</tr>
<tr>
<td> <strong>WorkDocs</strong> </td>
<td> </td>
<td> </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h3>Platform Services</h3>

<h4>Databases</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <a href="https://aws.amazon.com/rds/"><strong>RDS</strong></a> <br/>(Relational Database Service) </td>
<td> MySQL, PostgreSQL, etc. <br/>Relational databases. </td>
<td> Managed relational databases in the cloud. <br/>Amazon Aurora, Oracle, Microsoft SQL Server, PostgreSQL, MySQL and MariaDB.</td>
</tr>
<tr>
<td> <a href="https://aws.amazon.com/rds/aurora/"><strong>Aurora</strong></a> </td>
<td> Managed MySQL. </td>
<td> MySQL users can import their data. </td>
</tr>
<tr>
<td> <a href="https://aws.amazon.com/elasticache/"><strong>ElastiCache</strong></a></td>
<td> Memcached. Redis. </td>
<td> For information retrieval from memory-based cache nodes instead of slower disk-based databases. <br/>It supports Memcached and Redis caching engine. </td>
</tr>
<tr>
<td> <a href="https://aws.amazon.com/dynamodb/"><strong>DynamoDB</strong></a> </td>
<td> MongoDB </td>
<td> Managed NoSQL database service. </td>
</tr>
<tr>
<td> <a href="https://aws.amazon.com/redshift/"><strong>Redshift</strong></a> </td>
<td> OLAP system </td>
<td> Data warehouse service. </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Analytics</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <a href="https://aws.amazon.com/kinesis/"><strong>Kinesis</strong></a> </td>
<td> Apache Kafka, Storm. </td>
<td> Event stream processing platform. </td>
</tr>
<tr>
<td> <a href="https://aws.amazon.com/elasticmapreduce/"><strong>EMR</strong></a> <br/>(Elastic MapReduce) </td>
<td> MapReduce. HBase. </td>
<td> Big Data processing. <br/>Spark is also available.</td>
</tr>
<tr>
<td> <strong>Data Pipeline</strong> </td>
<td> </td>
<td> </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>App Services</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>Cloud Search</strong> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td> <strong>SES</strong> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td> <strong>SWF</strong> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td> <strong>Elastic Transcoder</strong> </td>
<td> </td>
<td> </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Deployment &amp; Management</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>Code Commit</strong> </td>
<td> Git </td>
<td> Source control service.</td>
</tr>
<tr>
<td> <strong>Code Deploy</strong> </td>
<td> </td>
<td> Code deployment service. </td>
</tr>
<tr>
<td> <strong>CloudFormation</strong> </td>
<td> Chef (in JSON) </td>
<td> Infrastructure as Code. <br/>Provisioning using source-controlled codes.</td>
</tr>
<tr>
<td> <strong>Elastic Beanstalk</strong> </td>
<td> CloudFormation simplified for WebApps. </td>
<td> Higher-level of CloudFormation for web applications. <br/>Example usage: Blue-Green deployment (easier than CloudFormation).  </td>
</tr>
<tr>
<td> <strong>OpsWork</strong> </td>
<td> Chef </td>
<td> Higher-level of CloudFormation. <br/>Configuration Management.  </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Mobile Services</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>SNS</strong> </td>
<td> </td>
<td> Notifications. </td>
</tr>
<tr>
<td> <strong>Cognito</strong> </td>
<td> </td>
<td> Mobile authentication and data syncing. </td>
</tr>
<tr>
<td> <strong>Mobile Analytics</strong> </td>
<td> </td>
<td> Measure and analyze mobile application usage data. </td>
</tr>
</tbody>
</table>


<h3>Other information</h3>

<p>Globally accessible services:</p>

<ul>
<li>IAM</li>
<li>Route 53</li>
<li>Cloud Front</li>
<li>Web App Firewall</li>
</ul>


<p>Regionally accessible services:</p>

<ul>
<li>S3</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/10/find-and-replace-a-string-in-multiple-files/">Using Virtual Machine for ETL Testing</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-01-10T23:49:15-08:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>10</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>11:49 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h3>Vertica Virtual Machine as sandbox test environment</h3>

<p>When developing data-warehouse solutions in Vertica, you want to set up some test environment.
Ideally, you should have separate schema for each developer.
However, it is usually NOT possible in my experience: developers and test engineers have to share very few schemas in development environment.
The explanation that I usually get is that having a schema for each developer will not scale in database maintenance and administration, and there are likely some limits in Vertica&rsquo;s commercial license.
If that is the case, I recommend that we look into using Vertica Community Edition on <strong>Virtual Machines (VMs)</strong> for sandbox test environment, as a cheap alternative.</p>

<p>Are VMs really necessary in data-warehouse testing? When testing Extract-Transform-Load (ETL) processes, I find that many of test cases require regular set-up and tear-down, adding mock records to force rare logical branches and corner cases, and/or running ETLs multiple times to simulate daily runs of those processes.
Regular tear-down requires dropping multiple tables regularly, which requires much greater care and drains much mental energy when working with others' data and tables.
Similarly, adding mock records into some commonly shared tables might affect others when they assume the data is production-like.
Running ETL scripts regularly, which could be computationally intensive, on a shared Vertica cluster might affect the performance or get affected by others' processes.
In short, for these tests, I cannot use the common schema that is shared with others since it might interfere others and/or destroy valuable common data.
Using a Vertica VM as the sandbox test environment helps us minimize interference to and from others' data and activities.</p>

<h3>Single-node VM and KSAFE clause</h3>

<p>I have been using a <strong>single-node</strong> Vertica VM to run tests for sometime. And it works wonderfully for testing purpose, especially when you want to isolate issues, for example, a corner case. The Vertica VM can be downloaded from HP Vertica&rsquo;s support website (NOTE: As of 2016 Jan 1st, the Vertica 7.1 VM is taken down while the Vertica 7.2 VM is not available).</p>

<p>The only minor problem is when we add <code>KSAFE 1</code> in our DDL scripts (i.e., <code>CREATE TABLE</code> statements) for production purposes. This gives error on single-node VM when running DDL scripts to set up schema.
The reason is that Vertica database with one or two hosts cannot be <em>k-safe</em> (i.e., it may lose data if it crashes) and three-node cluster is the minimum requirement to have <code>KSAFE 1</code> in <code>CREATE TABLE</code> statements to work.</p>

<p>Even then, the workaround for running those DDL scripts in tests is easy enough if all DDL scripts are all located in a single folder. The idea is that since <code>KSAFE 1</code> does not affect ETL processes' transform logics, we can remove those KSAFE clauses to set up the test schema and go ahead with our ETL testing. Specifically, in my project, my workflow for ETL testing with <strong>Git</strong> is as follows:</p>

<ul>
<li>Branch the latest code (<code>develop</code> branch) into a temporary branch (e.g., <code>local/develop</code> branch).</li>
<li>Find and remove <code>KSAFE 1</code> in all DDL files (see subsection below).</li>
<li>While still in <code>local/develop</code> branch, commit all these changes in a <strong>single</strong> commit with some unique description (e.g., &ldquo;KSAFE REMOVAL&rdquo;).</li>
<li>Add unit and functional tests to ETL scripts in this branch.</li>
<li>After tests are properly developed and checked-in, reverse the &ldquo;KSAFE REMOVAL&rdquo; commit above.

<ul>
<li>In SourceTree, it could be done by a simple right-click on that commit and selecting &ldquo;Reverse Commit&rdquo;.</li>
</ul>
</li>
<li>Merge <code>local/develop</code> branch into <code>develop</code> branch (create a pull request if needed). You will now have your tests with the latest codes in <code>develop</code> branch.</li>
</ul>


<h4>Find and replace a string in multiple files</h4>

<p>There are times and times again that you find that you have to replace every single occurrences of some string in multiple files with another string. Finding and removing <code>KSAFE 1</code> like the above workflow is an example where &ldquo;removing string&rdquo; is a special case of &ldquo;replacing string&rdquo; with nothing. This operation can be quickly done by the following bash command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>grep -rl match_string your_dir/ | xargs sed -i 's/old_string/new_string/g'</span></code></pre></td></tr></table></div></figure>


<p>If you are familiar with bash scripting, the above command is straight forward. This quick explanation is for anyone who does not understand the command:</p>

<ul>
<li><code>grep</code> command finds all files in <code>your_dir</code> directory that contain <code>match_string</code>. <code>-l</code> option makes sure it will return a list of files</li>
<li><code>sed</code> command then execute the replacement regex on all those files. A regex tip: the forward slash <code>/</code> delimiter could be another delimiter (e.g., <code>#</code>). This might be useful if you need to search HTML files.</li>
</ul>


<p>Example: In my case, all the DDL scripts are in multiple sub-directories under <code>tables</code> directory. To find and remove all <code>KSAFE 1</code> occurrences, the command is:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>grep -rl 'KSAFE 1' tables | xargs sed -i 's/KSAFE 1//g'</span></code></pre></td></tr></table></div></figure>


<p>This will search for the string <code>KSAFE 1</code> in all files in the <code>tables</code> directory and replace <code>KSAFE 1</code> with nothing <code>''</code> for each occurrence of the string in each file.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/8">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/posts/6">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
    <h1>About Me</h1>
    <p>I write about random things that come to mind, mostly for my future self and any visitor who might find useful.</p>
</section><section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2017/05/25/sending-emails-from-docker-containers/">Sending Emails From Docker Containers</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/05/20/gradle-settings-in-jenkinsfile/">Maven and Gradle Builds in Jenkinsfile</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/05/15/kubernetes-kube-router/">Kubernetes: Kube-router</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/04/18/groovy-code-in-jenkins-pipeline/">Groovy Script in Jenkins Pipeline</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/03/17/jenkins-pipeline-shared-libraries/">Jenkins Pipeline Shared Libraries</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/tdongsi">@tdongsi</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'tdongsi',
            count: 5,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section>
  <h1>Categories</h1>
    <ul id="category-list"><li><a href='/blog/categories/algorithm/'>algorithm (3)</a></li><li><a href='/blog/categories/automation/'>automation (6)</a></li><li><a href='/blog/categories/aws/'>aws (5)</a></li><li><a href='/blog/categories/bash/'>bash (7)</a></li><li><a href='/blog/categories/book/'>book (9)</a></li><li><a href='/blog/categories/cassandra/'>cassandra (1)</a></li><li><a href='/blog/categories/centos/'>centos (2)</a></li><li><a href='/blog/categories/database/'>database (6)</a></li><li><a href='/blog/categories/docker/'>docker (7)</a></li><li><a href='/blog/categories/eclipse/'>eclipse (2)</a></li><li><a href='/blog/categories/git/'>git (5)</a></li><li><a href='/blog/categories/gradle/'>gradle (1)</a></li><li><a href='/blog/categories/groovy/'>groovy (3)</a></li><li><a href='/blog/categories/hadoop/'>hadoop (10)</a></li><li><a href='/blog/categories/hive/'>hive (8)</a></li><li><a href='/blog/categories/java/'>java (10)</a></li><li><a href='/blog/categories/jdbc/'>jdbc (2)</a></li><li><a href='/blog/categories/jenkins/'>jenkins (7)</a></li><li><a href='/blog/categories/jmockit/'>jmockit (3)</a></li><li><a href='/blog/categories/junit/'>junit (2)</a></li><li><a href='/blog/categories/kubernetes/'>kubernetes (5)</a></li><li><a href='/blog/categories/macosx/'>macosx (3)</a></li><li><a href='/blog/categories/math/'>math (1)</a></li><li><a href='/blog/categories/matplotlib/'>matplotlib (2)</a></li><li><a href='/blog/categories/maven/'>maven (4)</a></li><li><a href='/blog/categories/mysql/'>mysql (1)</a></li><li><a href='/blog/categories/numpy/'>numpy (1)</a></li><li><a href='/blog/categories/performance/'>performance (4)</a></li><li><a href='/blog/categories/perl/'>perl (1)</a></li><li><a href='/blog/categories/python/'>python (10)</a></li><li><a href='/blog/categories/ruby/'>ruby (1)</a></li><li><a href='/blog/categories/security/'>security (3)</a></li><li><a href='/blog/categories/sql/'>sql (12)</a></li><li><a href='/blog/categories/testing/'>testing (6)</a></li><li><a href='/blog/categories/testng/'>testng (3)</a></li><li><a href='/blog/categories/vertica/'>vertica (11)</a></li><li><a href='/blog/categories/windows/'>windows (2)</a></li></ul>
</section>



  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2017 - Cuong Dong-Si -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
