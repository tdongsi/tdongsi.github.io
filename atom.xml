<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Personal Programming Notes]]></title>
  <link href="http://tdongsi.github.io/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/"/>
  <updated>2016-01-11T18:33:38-08:00</updated>
  <id>http://tdongsi.github.io/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Using Virtual Machine for ETL Testing]]></title>
    <link href="http://tdongsi.github.io/blog/2016/01/10/find-and-replace-a-string-in-multiple-files/"/>
    <updated>2016-01-10T23:49:15-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/01/10/find-and-replace-a-string-in-multiple-files</id>
    <content type="html"><![CDATA[<h3>Vertica Virtual Machine as sandbox test environment</h3>

<p>When developing data-warehouse solutions in Vertica, you want to set up some test environment.
Ideally, you should have separate schema for each developer.
However, it is usually NOT possible in my experience: developers and test engineers have to share very few schemas in development environment.
The explanation that I usually get is that having a schema for each developer will not scale in database maintainance and administration, and there are likely some limits in Vertica&rsquo;s commercial license.
If that is the case, I recommend that we look into using Vertica Community Edition on <strong>Virtual Machines (VMs)</strong> for sandbox test environment, as a cheap alternative.</p>

<p>Are VMs really necessary in data-warehouse testing? When testing Extract-Transform-Load (ETL) processes, I find that many of test cases require regular set-up and tear-down, adding mock records to represent corner cases, and/or running ETLs multiple times to simulate daily runs of those processes.
Regular tear-down requires dropping multiple tables regularly, which requires much greater care and drains much mental energy when working with others' data and tables.
Similarly, adding mock records into some commonly shared tables might affect others when they assume the data is production-like.
Running ETL scripts regularly, which could be computationally intensive, on a shared Vertica cluster might affect the performance or get affected by others' processes.</p>

<p>In short, for these tests, I cannot use the common schema that is shared with others since it might interfere others and/or destroy valuable common data.
Using a Vertica VM as the sandbox test environment helps us minimize interference to and from others' data and activities.</p>

<h3>Single-node VM and KSAFE clause</h3>

<p>I have been using a <strong>single-node</strong> Vertica VM to run tests for sometime. And it works wonderfully for testing purpose, especially when you want to isolate issues, for example, a corner case. The Vertica VM can be downloaded from HP Vertica&rsquo;s support website (NOTE: As of 2016 Jan 1st, the Vertica 7.1 VM is taken down while the Vertica 7.2 VM is not avaialble).</p>

<p>The only minor problem is when we add <code>KSAFE 1</code> in our DDL scripts (i.e., <code>CREATE TABLE</code> statements) for production purposes which gives error on single-node VM when running DDL scripts to set up schema.
The reason is that Vertica database with 1 or 2 hosts cannot be <em>k-safe</em> (i.e., it may lose data if it crashes) and three-node cluster is the minimum requirement to have <code>KSAFE 1</code> in <code>CREATE TABLE</code> statements to work.</p>

<p>Even then, the workaround for running those DDL scripts in tests is easy enough if all DDL scripts are all located in a single folder. The idea is that since <code>KSAFE 1</code> does not affect ETL processes&rsquo;s transform logics, we can remove those KSAFE clauses to set up the test schema and go ahead with our ETL testing. Specifically, in my project, my workflow for ETL testing with <strong>Git</strong> is as follows:</p>

<ul>
<li>Branch the latest code (<code>develop</code> branch) into a temporary branch (e.g., <code>local/develop</code> branch).</li>
<li>Find and remove <code>KSAFE 1</code> in all DDL files (see subsection below).</li>
<li>While still in <code>local/develop</code> branch, commit all these changes in a <strong>single</strong> commmit with some unique description (e.g., &ldquo;KSAFE REMOVAL&rdquo;).</li>
<li>Add unit and functional tests to ETL scripts in this branch.</li>
<li>After tests are properly developed and checked-in, reverse the &ldquo;KSAFE REMOVAL&rdquo; commit above.

<ul>
<li>In SourceTree, it could be done by a simple right-click on that commit and selecting &ldquo;Reverse Commit&rdquo;.</li>
</ul>
</li>
<li>Merge <code>local/develop</code> branch into <code>develop</code> branch. You will now have your tests with the latest codes in <code>develop</code> branch.</li>
</ul>


<h4>Find and replace a string in multiple files</h4>

<p>There are times and times again that you find that you have to replace every single occurences of some string in multiple files with another string. Finding and removing <code>KSAFE 1</code> like the above workflow is an example where &ldquo;removing string&rdquo; is a special case of &ldquo;replacing string&rdquo; with nothing. This operation can be quickly done by the following bash command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>grep -rl match_string your_dir/ | xargs sed -i 's/old_string/new_string/g'</span></code></pre></td></tr></table></div></figure>


<p>If you are familiar with bash scripting, the above command is straight forward. This quick explanation is for anyone who does not understand the command:</p>

<ul>
<li><code>grep</code> command finds all files in <code>your_dir</code> directory that contain <code>match_string</code>. <code>-l</code> option makes sure it will return a list of files</li>
<li><code>sed</code> command then execute the replacement regex on all those files. A regex tip: the forward slash <code>/</code> delimiter could be another delimiter (e.g., <code>#</code>). This might be useful if you need to search HTML files.</li>
</ul>


<p>Example: In my case, all the DDL scripts are in multiple sub-directories under <code>tables</code> directory. To find and remove all <code>KSAFE 1</code> occurences, the command is:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>grep -rl 'KSAFE 1' tables | xargs sed -i 's/KSAFE 1//g'</span></code></pre></td></tr></table></div></figure>


<p>This will search for the string <code>KSAFE 1</code> in all files in the <code>tables</code> directory and replace <code>KSAFE 1</code> with nothing <code>''</code> for each occurrence of the string in each file.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vertica Tip: Find Empty Tables]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/18/vertica-tip-find-empty-tables-in-a-schema/"/>
    <updated>2015-12-18T21:39:56-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/18/vertica-tip-find-empty-tables-in-a-schema</id>
    <content type="html"><![CDATA[<p>This post is a reminder of using Vertica&rsquo;s system tables for administrating and monitoring our own tables. One common house-cleaning operation when developing/testing in Vertica is to find and drop tables that are empty (truncated) and never used again.</p>

<p>You might ask why the tables are not dropped directly when I truncated the table in the first place. The answer is that all those tables have some specific designs on projection segmentation and partition, and those information will be lost if I drop the tables. These tables are frequently populated with data and cleared for testing purposes, and truncating and inserting with <code>direct</code> <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/Statements/INSERT.htm">hint</a> will give a significant performance boost (see <a href="http://tdongsi.github.io/blog/2015/12/16/vertica-tip-best-practices/">Best practices</a>).</p>

<h3>v_monitor schema and COLUMN_STORAGE system table</h3>

<p>The <a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/SystemTables/MONITOR/COLUMN_STORAGE.htm">COLUMN_STORAGE system table</a> in <code>v_monitor</code> schema returns the &ldquo;amount of disk storage used by each column of each projection on each node&rdquo;. Therefore, to get the size of each table, you only need to aggregate the <code>used_byte</code> data, grouped by schema name and table name.</p>

<figure class='code'><figcaption><span>Query to list tables' sizes in a schema</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="n">anchor_table_schema</span><span class="p">,</span> <span class="n">anchor_table_name</span><span class="p">,</span> <span class="k">sum</span><span class="p">(</span><span class="n">used_bytes</span><span class="p">)</span>
</span><span class='line'><span class="k">FROM</span> <span class="n">v_monitor</span><span class="p">.</span><span class="n">column_storage</span>
</span><span class='line'><span class="k">where</span> <span class="n">anchor_table_schema</span> <span class="o">=</span> <span class="s1">&#39;some_schema&#39;</span>
</span><span class='line'><span class="k">group</span> <span class="k">by</span> <span class="n">anchor_table_schema</span><span class="p">,</span> <span class="n">anchor_table_name</span>
</span></code></pre></td></tr></table></div></figure>


<p>According to <a href="http://vertica.tips/2014/01/25/table-size/">here</a>, the number from the above query is the <em>compressed</em> size of the Vertica tables. To get the <em>raw</em> size of the tables, which probably only matters for license limit, perform a <em>license audit</em>, and query the system table <code>license_audits</code> in <code>v_catalog</code> schema. However, the most important takeaway is that empty tables will not appear in this <code>COLUMN_STORAGE</code> system table.</p>

<h3>v_catalog schema and TABLES system table</h3>

<p>The <a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/SystemTables/CATALOG/TABLES.htm">TABLES system table</a> is probably more well-known. It contains all the information about all the tables in all the schemas. For example, to list all the tables in some schema:</p>

<figure class='code'><figcaption><span>Query to list all tables in a schema</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="n">table_schema</span><span class="p">,</span> <span class="k">table_name</span> <span class="k">from</span> <span class="n">tables</span>
</span><span class='line'><span class="k">where</span> <span class="n">table_schema</span> <span class="o">=</span> <span class="s1">&#39;some_schema&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Another useful system table in <code>v_catalog</code> shema is <code>USER_FUNCTIONS</code> which lists all user-defined functions and their function signatures in the database.</p>

<h3>Find all the empty (truncated) tables</h3>

<p>Having all the tables in <code>v_catalog.tables</code> table and only non-empty tables in <code>v_monitor.column_storage</code> table, finding empty tables is pretty straight-forward in SQL:</p>

<figure class='code'><figcaption><span>Query to find empty tables in a schema</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="k">table_name</span>
</span><span class='line'><span class="k">from</span> <span class="n">v_catalog</span><span class="p">.</span><span class="n">tables</span>
</span><span class='line'><span class="k">where</span> <span class="n">table_schema</span> <span class="o">=</span> <span class="s1">&#39;some_schema&#39;</span>
</span><span class='line'><span class="k">EXCEPT</span>
</span><span class='line'><span class="k">select</span> <span class="n">anchor_table_name</span>
</span><span class='line'><span class="k">from</span> <span class="n">v_monitor</span><span class="p">.</span><span class="n">column_storage</span>
</span><span class='line'><span class="k">where</span> <span class="n">anchor_table_schema</span> <span class="o">=</span> <span class="s1">&#39;some_schema&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<h3>External Links</h3>

<ol>
<li><a href="http://vertica.tips/2014/01/25/table-size/">Finding table&rsquo;s compressed size</a></li>
<li><a href="http://vertica.tips/2014/01/24/license-audit-utilization-raw-size/">Vertica License audit</a></li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/SystemTables/MONITOR/COLUMN_STORAGE.htm">COLUMN_STORAGE system table</a></li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/SystemTables/CATALOG/TABLES.htm">TABLES system table</a></li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/SystemTables/CATALOG/USER_FUNCTIONS.htm">USER_FUNCTIONS system table</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vertica Tip: Using Vsql CLI]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/17/vertica-tip-using-vsql/"/>
    <updated>2015-12-17T22:54:07-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/17/vertica-tip-using-vsql</id>
    <content type="html"><![CDATA[<h3>Using vsql</h3>

<p>You can connect to Vertica database with username and password. When doing this, note that the password might be seen in the command history.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vsql -h internal.vertica.net -p 5433 -d VMart -U vertica_user -w password </span></code></pre></td></tr></table></div></figure>


<p>Or you can connect to Vertica with Kerberos authentication.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vsql -h internal.vertica.net -p 5433 -d VMart -k KerberosServiceName -K KerberosHostName</span></code></pre></td></tr></table></div></figure>


<p>Note that from time to time, you could run into Kerberos GSI failure because the ticket expired. This is how you can renew and extend the ticket: run the following command to refresh Kerberos cache for the headless account <code>vertica_user</code>.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kinit -kt /home/path/to/vertica_user.keytab vertica_user@CORP.INTERNAL.NET</span></code></pre></td></tr></table></div></figure>


<p>You can also run a single SQL command from command line with <code>-c</code> option or, alternatively, a SQL script file with multiple commands with <code>-f</code> option. These options can be very useful to automate in shell/python scripts. Note that you can also parameterize your sripts by using <code>-v</code> option to assign variables inside your SQL scripts.</p>

<h3>Vsql meta commands</h3>

<p>Here is list of commonly used vsql <a href="http://my.vertica.com/docs/7.0.x/HTML/index.htm#Authoring/ProgrammersGuide/vsql/Meta-Commands.htm">meta commands</a>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>dbadmin=&gt; \dt — (list of all tables)
</span><span class='line'>dbadmin=&gt; \dt user* — (list of tables starting with user)
</span><span class='line'>dbadmin=&gt; \d tablename — (describe table)
</span><span class='line'>dbadmin=&gt; \dv — (list of all views)</span></code></pre></td></tr></table></div></figure>


<p>Here are the vsql commands to export a file:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>dbadmin=&gt; \o sample_users_lists.csv
</span><span class='line'>dbadmin=&gt; \f|
</span><span class='line'>dbadmin=&gt; select * from my_dwh.users limit 20;
</span><span class='line'>dbadmin=&gt; \o
</span><span class='line'>dbadmin=&gt; \q</span></code></pre></td></tr></table></div></figure>


<h3>External links</h3>

<ol>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/ConnectingToHPVertica/vsql/CommandLineOptions.htm">Command line options</a></li>
<li><a href="http://my.vertica.com/docs/7.0.x/HTML/index.htm#Authoring/ProgrammersGuide/vsql/Meta-Commands.htm">Meta Commands</a></li>
<li><a href="http://my.vertica.com/docs/7.0.x/HTML/index.htm#Authoring/ProgrammersGuide/vsql/Meta-Commands/TheDPATTERNMeta-commands.htm">Meta Commands: \d[Pattern]</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vertica Tip: Best Practices]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/16/vertica-tip-best-practices/"/>
    <updated>2015-12-16T23:12:06-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/16/vertica-tip-best-practices</id>
    <content type="html"><![CDATA[<p>This post lists some tips and tricks that I learnt when working with Vertica database.</p>

<h3>General Tips and Tricks</h3>

<h4>CREATE (INSERT)</h4>

<ul>
<li><p>If you want to write data directly to disk and bypass memory, then you should include <code>/*+ direct */</code> as a &ldquo;hint&rdquo; in your <code>INSERT</code> statement. This is especially helpful when you are loading data from big files into Vertica. If you don&rsquo;t use <code>/*+ direct */</code>, then <code>INSERT</code> statement first uses memory, which may be more useful when you want to optimally do inserts and run queries.</p></li>
<li><p>ALWAYS include <code>COMMIT</code> in your SQL statements when you are creating or updating Vertica schemas, because there is NO auto commit in Vertica.</p></li>
<li><p>If you are copying a table, <strong>DO NOT</strong> use <code>CREATE TABLE copy AS SELECT * FROM source</code>. This will give you a copy table with default projections and storage policy. Instead, you should use <code>CREATE TABLE</code> statement with the <a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/AdministratorsGuide/Tables/CreatingATableLikeAnother.htm"><code>LIKE existing_table</code> clause</a> and use <code>INSERT /*+ direct */</code> statement. Creating a table with <code>LIKE</code> option replicates the table definition and storage policy associated with the source table, which can make a significant difference in data loading performance. Note that the <code>LIKE</code> clause does not work if the existing source table is a temporary table.</p></li>
</ul>


<figure class='code'><figcaption><span>DO NOT do this</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">create</span> <span class="k">table</span> <span class="n">to_schema</span><span class="p">.</span><span class="n">to_table_name</span>
</span><span class='line'><span class="k">as</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">from_schema</span><span class="p">.</span><span class="n">from_table_name</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>DO this</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">to_schema</span><span class="p">.</span><span class="n">to_table_name</span> <span class="k">LIKE</span> <span class="n">from_schema</span><span class="p">.</span><span class="n">from_table_name</span> <span class="k">INCLUDING</span> <span class="n">PROJECTIONS</span><span class="p">;</span>
</span><span class='line'><span class="k">INSERT</span> <span class="cm">/*+ direct */</span> <span class="k">INTO</span> <span class="n">to_schema</span><span class="p">.</span><span class="n">to_table_name</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">from</span> <span class="n">from_schema</span><span class="p">.</span><span class="n">from_table_name</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Before making a copy of a table, be sure to consider alternatives in order to execute optimal queries: create views, rewrite queries, use sub-queries, limit queries to only a subset of data for analysis.</li>
</ul>


<h4>READ</h4>

<ul>
<li><p>Avoid joining large tables (e.g., > 50M records). Run a <code>count(*)</code> on tables before joining and use <code>MERGE JOIN</code> to optimally join tables. When you use smaller subsets of data, the Vertica Optimizer will pick the <code>MERGE JOIN</code> algorithm instead of the <code>HASH JOIN</code> one, which is less optimal.</p></li>
<li><p>When an approximate value will be enough, Vertica offers an alternative to <code>COUNT(DISTINCT)</code>: <code>APPROXIMATE_COUNT_DISTINCT</code>. This function is recommended when you have a large data set and you do not require an exact count of distinct values: e.g., sanity checks that verify the tables are populated. According to <a href="http://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/AnalyzingData/Optimizations/OptimizingCOUNTDISTINCTByCalculatingApproximateCounts.htm">this documentation</a>, you can get much better performance than <code>COUNT(DISTINCT)</code>. <a href="http://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/Functions/Aggregate/APPROXIMATE_COUNT_DISTINCT.htm">Here</a> is an example of the <code>APPROXIMATE_COUNT_DISTINCT</code> syntax that you should use.</p></li>
</ul>


<h4>UPDATE &amp; DELETE</h4>

<ul>
<li><p>Deletes and updates take exclusive locks on the table. Hence, only one <code>DELETE</code> or <code>UPDATE</code> transaction on that table can be in progress at a time and only when no <code>INSERTs</code> are in progress. Deletes and updates on different tables can be run concurrently.</p></li>
<li><p>Try to avoid <code>DELETE</code> or <code>UPDATE</code> as much as you can, especially on shared Vertica databases. Instead, it may work better to move the data you want to update to a new temporary table, work on that copy, drop the original table, and rename the temporary table with the original table name. For example:</p></li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="n">temp_table</span> <span class="k">LIKE</span> <span class="n">src_table</span> <span class="k">INCLUDING</span> <span class="n">PROJECTIONS</span><span class="p">;</span>
</span><span class='line'><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">temp_table</span> <span class="p">(</span><span class="k">SELECT</span> <span class="k">statement</span> <span class="n">based</span> <span class="k">on</span> <span class="n">the</span> <span class="n">updated</span> <span class="k">data</span> <span class="k">or</span> <span class="n">the</span> <span class="n">needed</span> <span class="k">rows</span><span class="p">);</span>
</span><span class='line'><span class="k">DROP</span> <span class="k">TABLE</span> <span class="n">src_table</span><span class="p">;</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">temp_table</span> <span class="k">RENAME</span> <span class="k">TO</span> <span class="n">src_table</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Delete from tables marks rows with delete vectors and stores them so data can be rolled back to a previous epoch. The data must be eventually purged before the database can reclaim disk space.</li>
</ul>


<h3>Query plan</h3>

<p>A query plan is a sequence of step-like paths that the HP Vertica cost-based query optimizer selects to access or alter information in your HP Vertica database. You can get information about query plans by prefixing the SQL query with the <code>EXPLAIN</code> command.</p>

<figure class='code'><figcaption><span>EXPLAIN statement</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">EXPLAIN</span> <span class="k">SELECT</span> <span class="n">customer_name</span><span class="p">,</span> <span class="n">customer_state</span> <span class="k">FROM</span> <span class="n">customer_dimension</span>
</span><span class='line'><span class="k">WHERE</span> <span class="n">customer_state</span> <span class="k">in</span> <span class="p">(</span><span class="s1">&#39;MA&#39;</span><span class="p">,</span><span class="s1">&#39;NH&#39;</span><span class="p">)</span> <span class="k">AND</span> <span class="n">customer_gender</span> <span class="o">=</span> <span class="s1">&#39;Male&#39;</span>
</span><span class='line'><span class="k">ORDER</span> <span class="k">BY</span> <span class="n">customer_name</span> <span class="k">LIMIT</span> <span class="mi">10</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>The output from a query plan is presented in a tree-like structure, where each step path represents a single operation in the database that the optimizer uses for its execution strategy. The following example output is based on the previous query:</p>

<figure class='code'><figcaption><span>Query Plan description</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>EXPLAIN SELECT
</span><span class='line'>customer_name,
</span><span class='line'>customer_state
</span><span class='line'>FROM customer_dimension
</span><span class='line'>WHERE customer_state in <span class="o">(</span><span class="s1">&#39;MA&#39;</span>,<span class="s1">&#39;NH&#39;</span><span class="o">)</span>
</span><span class='line'>AND <span class="nv">customer_gender</span> <span class="o">=</span> <span class="s1">&#39;Male&#39;</span>
</span><span class='line'>ORDER BY customer_name
</span><span class='line'>LIMIT 10<span class="p">;</span>
</span><span class='line'>Access Path:
</span><span class='line'>+-SELECT  LIMIT <span class="m">10</span> <span class="o">[</span>Cost: 370, Rows: 10<span class="o">]</span> <span class="o">(</span>PATH ID: 0<span class="o">)</span>
</span><span class='line'><span class="p">|</span>  Output Only: <span class="m">10</span> tuples
</span><span class='line'><span class="p">|</span>  Execute on: Query Initiator
</span><span class='line'><span class="p">|</span> +---&gt; SORT <span class="o">[</span>Cost: 370, Rows: 544<span class="o">]</span> <span class="o">(</span>PATH ID: 1<span class="o">)</span>
</span><span class='line'><span class="p">|</span> <span class="p">|</span>      Order: customer_dimension.customer_name ASC
</span><span class='line'><span class="p">|</span> <span class="p">|</span>      Output Only: <span class="m">10</span> tuples
</span><span class='line'><span class="p">|</span> <span class="p">|</span>      Execute on: Query Initiator
</span><span class='line'><span class="p">|</span> <span class="p">|</span> +---&gt; STORAGE ACCESS <span class="k">for</span> customer_dimension <span class="o">[</span>Cost: 331, Rows: 544<span class="o">]</span> <span class="o">(</span>PATH ID: 2<span class="o">)</span>
</span><span class='line'><span class="p">|</span> <span class="p">|</span> <span class="p">|</span>      Projection: public.customer_dimension_DBD_1_rep_vmartdb_design_vmartdb_design_node0001
</span><span class='line'><span class="p">|</span> <span class="p">|</span> <span class="p">|</span>      Materialize: customer_dimension.customer_state, customer_dimension.customer_name
</span><span class='line'><span class="p">|</span> <span class="p">|</span> <span class="p">|</span>      Filter: <span class="o">(</span>customer_dimension.customer_gender <span class="o">=</span> <span class="s1">&#39;Male&#39;</span><span class="o">)</span>
</span><span class='line'><span class="p">|</span> <span class="p">|</span> <span class="p">|</span>      Filter: <span class="o">(</span>customer_dimension.customer_state <span class="o">=</span> ANY <span class="o">(</span>ARRAY<span class="o">[</span><span class="s1">&#39;MA&#39;</span>, <span class="s1">&#39;NH&#39;</span><span class="o">]))</span>
</span><span class='line'><span class="p">|</span> <span class="p">|</span> <span class="p">|</span>      Execute on: Query Initiator
</span></code></pre></td></tr></table></div></figure>


<p>If you want to understand the details of the query plan, observe the real-time flow of data through the plan to identify possible query bottlenecks, you can:</p>

<ol>
<li>query the <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/SystemTables/MONITOR/QUERY_PLAN_PROFILES.htm">V_MONITOR.QUERY_PLAN_PROFILES</a> system table.</li>
<li>review <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/AdministratorsGuide/Profiling/ProfilingQueryPlanProfiles.htm">Profiling Query Plans</a>.</li>
<li>use <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/Statements/PROFILE.htm">PROFILE</a> statement to view further detailed analysis of your query.</li>
</ol>


<h3>External Links</h3>

<ol>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm">Vertica documentation</a></li>
<li><a href="http://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/Functions/Aggregate/APPROXIMATE_COUNT_DISTINCT.htm">APPROXIMATE_COUNT_DISTINCT</a></li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/AdministratorsGuide/Tables/CreatingATableLikeAnother.htm">Create a Table Like Another</a></li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/SystemTables/MONITOR/QUERY_PLAN_PROFILES.htm">V_MONITOR.QUERY_PLAN_PROFILES</a> system table.</li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/AdministratorsGuide/Profiling/ProfilingQueryPlanProfiles.htm">Profiling Query Plans</a>.</li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/Statements/PROFILE.htm">PROFILE</a> statement.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Netezza CLI Tools]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/09/netezza-cli/"/>
    <updated>2015-12-09T18:34:12-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/09/netezza-cli</id>
    <content type="html"><![CDATA[<p>In addition to using third party GUI clients such as SQuirreLSQL, you can also interact with Netezza through its command line interface (CLI) tools.
These are programs that let you do useful things like importing and exporting large volumes of data, invoking Netezza from bash scripts, controlling sessions and queries, etc.
The following is a quick overview of just the <code>nzsql</code> and <code>nzload</code> commands.
For a description of all the CLI tools, see the documentation <a href="http://www-01.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.adm.doc/r_sysadm_summary_of_commands.html?lang=en">here</a>.
You can install the Netezza CLI tools directly onto your system by following the instructions <a href="http://www-01.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.adm.doc/c_sysadm_client_software_install.html">here</a>.</p>

<h3>nzsql command</h3>

<p>You can use <code>nzsql</code> in interactive terminal mode by executing the command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>nzsql -host &lt;hostname&gt; -u &lt;username&gt; -pw &lt;password&gt; -d &lt;database&gt;
</span><span class='line'>  
</span><span class='line'>Welcome to nzsql, the IBM Netezza SQL interactive terminal.
</span><span class='line'>
</span><span class='line'>Type:  \h for help with SQL commands
</span><span class='line'>       \? for help on internal slash commands
</span><span class='line'>       \g or terminate with semicolon to execute query
</span><span class='line'>       \q to quit
</span><span class='line'>
</span><span class='line'>ws(user)=&gt;</span></code></pre></td></tr></table></div></figure>


<p>which puts you in the nzsql command line interpreter.</p>

<p>From there, you can execute SQL commands:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ws(user)=&gt; select count(*) from dwh..companies;
</span><span class='line'>COUNT
</span><span class='line'>---------
</span><span class='line'>6286
</span><span class='line'>(1 row)</span></code></pre></td></tr></table></div></figure>


<p>and you can also execute &ldquo;slash&rdquo; commands.  For example, to change the database to <code>dwh</code> and describe the table <code>companies</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ws(user)=&gt; \c dwh
</span><span class='line'>You are now connected to database dwh.
</span><span class='line'>ws(user)=&gt; \d companies
</span><span class='line'>                                 View "COMPANIES"
</span><span class='line'>           Attribute           |          Type           | Modifier | Default Value 
</span><span class='line'>-------------------------------+-------------------------+----------+---------------
</span><span class='line'> COMPANY_ID                    | NUMERIC(38,0)           | NOT NULL | 
</span><span class='line'> COMPANY_NAME                  | CHARACTER VARYING(100)  |          | 
</span><span class='line'> COMPANY_STATUS                | NUMERIC(38,0)           |          | 
</span><span class='line'> STATUS_MESSAGE                | CHARACTER VARYING(2000) |          | 
</span><span class='line'> CREATE_DATE                   | DATE                    |          | 
</span><span class='line'> CREATE_VERSION                | CHARACTER VARYING(20)   |          | 
</span><span class='line'> ASSIGNED_DATE                 | DATE                    |          | 
</span><span class='line'> ASSIGNED_VERSION              | CHARACTER VARYING(20)   |          | 
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>To see all the available slash commands, type <code>\?</code> at the prompt:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ws(user)=&gt; \?
</span><span class='line'> \a              toggle between unaligned and aligned mode
</span><span class='line'> \act            show current active sessions
</span><span class='line'> \c[onnect] [dbname [user] [password]]    connect to new database (currently 'UED_QBO_WS')
</span><span class='line'> \C &lt;title&gt;      HTML table title
</span><span class='line'> \copy ...       perform SQL COPY with data stream to the client machine
</span><span class='line'> \d &lt;table&gt;      describe table (or view, index, sequence, synonym)
</span><span class='line'> \d{t|v|i|s|e|x} list tables/views/indices/sequences/temp tables/external tables
</span><span class='line'> \d{m|y}         list materialized views/synonyms
</span><span class='line'> \dS{t|v|i|s}    list system tables/views/indexes/sequences
</span><span class='line'> \dM{t|v|i|s}    list system management tables/views/indexes/sequences
</span><span class='line'> \dp &lt;name&gt;      list user permissions
</span><span class='line'> \dpu &lt;name&gt;     list permissions granted to a user
</span><span class='line'> \dpg &lt;name&gt;     list permissions granted to a group
</span><span class='line'> \dgp &lt;name&gt;     list grant permissions for a user
</span><span class='line'> \dgpu &lt;name&gt;    list grant permissions granted to a user
</span><span class='line'> \dgpg &lt;name&gt;    list grant permissions granted to a group
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>To escape from the nzsql interactive terminal mode, type <code>\q</code> at the prompt.</p>

<p>You can also use the <code>nzsql</code> command directly from the command line, by invoking it with various parameters.
See the documentation <a href="http://www-01.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.adm.doc/r_sysadm_nzsql_command.html">here</a> for all the parameters that can be used with the <code>nzsql</code> command.
As an example, to execute a single SQL statement and print the results to the terminal:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-bash-4.1$ nzsql -host myHost -u username -pw password -d ws -c 'select count(*) from companies'
</span><span class='line'>COUNT  
</span><span class='line'>---------
</span><span class='line'>9032
</span><span class='line'>(1 row)</span></code></pre></td></tr></table></div></figure>


<p>Or, to direct the output to a specific file in the local file system:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-bash-4.1$ nzsql -host myHost -u username -pw password -d ws -c 'select count(*) from companies' -o output.txt
</span><span class='line'>-bash-4.1$ cat output.txt
</span><span class='line'>COUNT  
</span><span class='line'>---------
</span><span class='line'>9032
</span><span class='line'>(1 row)</span></code></pre></td></tr></table></div></figure>


<p>And, to run a SQL script that is located in the local file system:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-bash-4.1$ cat my_script.sql
</span><span class='line'>select count(*) from companies;
</span><span class='line'>-bash-4.1$ nzsql -host myHost -u username -pw password -d ws -f my_script.sql
</span><span class='line'>COUNT
</span><span class='line'>---------
</span><span class='line'>9032
</span><span class='line'>(1 row)</span></code></pre></td></tr></table></div></figure>


<h3>nzload command</h3>

<p>The <code>nzload</code> command is used to move large volumes of data in to and out of Netezza.
This is a very broad subject, and you can find all the details <a href="http://www-01.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.load.doc/c_load_overview.html?cp=SSULQD_7.2.0%2F5&amp;lang=en">here</a>.
As a toy example, suppose you have the following data in the local filesystem:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-bash-4.1$ cat my_data.txt
</span><span class='line'>Fred, 2
</span><span class='line'>Betty, 7
</span><span class='line'>Wilma, 10
</span><span class='line'>Barney, 5</span></code></pre></td></tr></table></div></figure>


<p>You can create a Netezza to hold this data, using the <code>nzsql</code> command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-bash-4.1$ nzsql -host myHost -u username -pw password -d ws -c 'create table my_table (name varchar(80), rocks int)'</span></code></pre></td></tr></table></div></figure>


<p>And then you can populate the table using the <code>nzload</code> command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>nzload -host myHost -u username -pw password -db ws -t my_table -df my_data.txt -delim ','
</span><span class='line'>Load session of table 'MY_TABLE' completed successfully</span></code></pre></td></tr></table></div></figure>


<p>Finally, you can confirm that the table was populated using the <code>nzsql</code> command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-bash-4.1$ nzsql -host myHost -u username -pw password -d ws -c 'select * from my_table'
</span><span class='line'>  NAME  | ROCKS 
</span><span class='line'>--------+-------
</span><span class='line'> Wilma  |    10
</span><span class='line'> Betty  |     7
</span><span class='line'> Barney |     5
</span><span class='line'> Fred   |     2
</span><span class='line'>(4 rows)</span></code></pre></td></tr></table></div></figure>


<h3>External Links</h3>

<ol>
<li><a href="http://www-01.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.adm.doc/r_sysadm_summary_of_commands.html?lang=en">List of Netezza CLI tools</a></li>
<li><a href="http://www-01.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.adm.doc/c_sysadm_client_software_install.html">Installing the Netezza CLI tools</a></li>
<li><a href="http://www-01.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.adm.doc/r_sysadm_nzsql_command.html">Nzsql CLI tool</a></li>
<li><a href="http://www-01.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.load.doc/c_load_overview.html?cp=SSULQD_7.2.0%2F5&amp;lang=en">Nzload CLI tool</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Some NZSQL Tips for New Netezza Users]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/07/some-netezzas-nzsql-tips/"/>
    <updated>2015-12-07T11:11:06-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/07/some-netezzas-nzsql-tips</id>
    <content type="html"><![CDATA[<ul>
<li>By default, identifiers are treated as UPPERCASE, even if you type them as LOWERCASE. So, for example, these create statements:</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">create</span> <span class="k">table</span> <span class="n">my_table</span> <span class="p">(</span><span class="n">name</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">80</span><span class="p">),</span> <span class="n">address</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">80</span><span class="p">));</span>
</span><span class='line'><span class="k">create</span> <span class="k">table</span> <span class="n">my_table</span> <span class="p">(</span><span class="n">NaMe</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">80</span><span class="p">),</span> <span class="n">adDresS</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">80</span><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure>


<p>  are equivalent to:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">create</span> <span class="k">table</span> <span class="n">my_table</span> <span class="p">(</span><span class="n">NAME</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">80</span><span class="p">),</span> <span class="n">ADDRESS</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">80</span><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure>


<p>  The same is true for <code>SELECT</code> statements. These two SQL statements:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="n">name</span> <span class="k">from</span> <span class="n">my_table</span><span class="p">;</span>
</span><span class='line'><span class="k">select</span> <span class="n">NaMe</span> <span class="k">from</span> <span class="n">my_table</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>  are equivalent to:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="n">NAME</span> <span class="k">from</span> <span class="n">my_table</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>The best practice is that you should never care or override the above default behavior: your identifiers should be case-insensitive. Unfortunately, if you have to override the above default behavior, then you must surround the identifier with double-quotes whenever you reference it. For example, if you create a table using this statement:</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">create</span> <span class="k">table</span> <span class="n">my_table</span> <span class="p">(</span><span class="ss">&quot;Name&quot;</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">80</span><span class="p">),</span> <span class="ss">&quot;Address&quot;</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">80</span><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure>


<p>
then you must reference the identifiers by surrounding them with double-quotes. For example:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="ss">&quot;Name&quot;</span> <span class="k">from</span> <span class="n">my_table</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>The most perplexing feature for new Netezza users when reading a NZSQL script is probably the &ldquo;dot dot&rdquo; notation of database object names, i.e., the two dots in <code>my_dwh..companies</code>. It is simply the short-hand notation for database object names, <code>database-name..object-name</code>. The fully qualified form of object names in Netezza has <strong>three-level</strong> as <code>database-name.schema.object-name</code>. One example of using such notation is shown below:</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="k">count</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">from</span> <span class="p">(</span><span class="k">select</span> <span class="n">company_name</span> <span class="k">from</span> <span class="n">my_dwh</span><span class="p">..</span><span class="n">companies</span> <span class="k">where</span> <span class="n">company_name</span> <span class="k">like</span> <span class="s1">&#39;%e%&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">x</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<h4>External Links</h4>

<ol>
<li><a href="https://www-304.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.dbu.doc/c_dbuser_database_object_naming.html">Database Object Naming</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive Tutorial (Pt. 7): Partitioned Tables]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/06/programming-hive-partitioned-tables/"/>
    <updated>2015-12-06T21:09:51-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/06/programming-hive-partitioned-tables</id>
    <content type="html"><![CDATA[<!--
Chapter 4
-->


<p>Continued from the <a href="http://tdongsi.github.io/blog/2015/12/02/programming-hive-hiveql-ddl/">previous</a> <a href="http://tdongsi.github.io/blog/2015/12/05/programming-hive-ddl-table/">posts</a>.</p>

<h3>Partitioned Managed Tables</h3>

<p>In general, paritioning data means distributing data load horizontally, moving data physically closer to its most frequent users. In Hive, partitioning tables changes how Hive structures its data storage for some performance gain.</p>

<p>In &ldquo;Programming Hive&rdquo;, the authors present a hypothetical problem where one will regularly query some <code>employees</code> table by country and state, e.g., all employees in California, US or Alberta, Canada. Therefore, partitioning this table by country and state is a logical thing to do.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">employees</span> <span class="p">(</span>
</span><span class='line'>  <span class="n">name</span>         <span class="n">STRING</span><span class="p">,</span>
</span><span class='line'>  <span class="n">salary</span>       <span class="nb">FLOAT</span><span class="p">,</span>
</span><span class='line'>  <span class="n">subordinates</span> <span class="nb">ARRAY</span><span class="o">&lt;</span><span class="n">STRING</span><span class="o">&gt;</span><span class="p">,</span>
</span><span class='line'>  <span class="n">deductions</span>   <span class="k">MAP</span><span class="o">&lt;</span><span class="n">STRING</span><span class="p">,</span> <span class="nb">FLOAT</span><span class="o">&gt;</span><span class="p">,</span>
</span><span class='line'>  <span class="n">address</span>      <span class="n">STRUCT</span><span class="o">&lt;</span><span class="n">street</span><span class="p">:</span><span class="n">STRING</span><span class="p">,</span> <span class="n">city</span><span class="p">:</span><span class="n">STRING</span><span class="p">,</span> <span class="k">state</span><span class="p">:</span><span class="n">STRING</span><span class="p">,</span> <span class="n">zip</span><span class="p">:</span><span class="nb">INT</span><span class="o">&gt;</span>
</span><span class='line'><span class="p">)</span>
</span><span class='line'><span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">country</span> <span class="n">STRING</span><span class="p">,</span> <span class="k">state</span> <span class="n">STRING</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Without <code>PARTITIONED BY</code> clause, Hive will store data for these tables in a subdirectory <code>employees</code> under the directory defined by <code>hive.metastore.warehouse.dir</code> (see <a href="http://tdongsi.github.io/blog/2015/12/05/programming-hive-ddl-table/">Managed tables</a>). However, Hive will now create subdirectories inside <code>employees</code> directory for the above partitioning structure:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>...
</span><span class='line'>.../employees/country<span class="o">=</span>CA/state<span class="o">=</span>AB
</span><span class='line'>.../employees/country<span class="o">=</span>CA/state<span class="o">=</span>BC
</span><span class='line'>...
</span><span class='line'>.../employees/country<span class="o">=</span>US/state<span class="o">=</span>AL
</span><span class='line'>.../employees/country<span class="o">=</span>US/state<span class="o">=</span>AK
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>The actual directory names depends on values of <em>partition keys</em> (e.g., country and state). For very large data sets, partitioning can improve query performance, but only if the partitioning scheme reflects common range filtering (e.g., by countries or states). When we add predicates to WHERE clauses that filter on partition values, these predicates are called <em>partition filters</em> (e.g., <code>WHERE state = 'CA'</code>).</p>

<p>You can view the partitions in a table with <code>SHOW PARTITIONS</code>, as shown in examples below:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">SHOW</span> <span class="n">PARTITIONS</span> <span class="n">college</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* DESCRIBE EXTENDED also shows partition keys */</span>
</span><span class='line'><span class="k">SHOW</span> <span class="n">PARTITIONS</span> <span class="n">employees</span> <span class="n">PARTITION</span><span class="p">(</span> <span class="n">country</span><span class="o">=</span><span class="err">‘</span><span class="n">US</span><span class="err">’</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<h4>Strict mode</h4>

<p>Given a partitioned table, a query across all partitions can result in a enormous MapReduce job, especially for a huge data set. It is probably desirable to put in place a safety measure which prohibits queries without any filter on partitions. Hive has a &ldquo;strict&rdquo; mode for that.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>hive&gt; <span class="nb">set </span>hive.mapred.mode<span class="p">;</span>
</span><span class='line'>hive.mapred.mode<span class="o">=</span>nonstrict
</span><span class='line'>
</span><span class='line'>hive&gt; <span class="nb">set </span>hive.mapred.mode <span class="o">=</span> strict<span class="p">;</span>
</span><span class='line'>hive&gt; SELECT e.name FROM employees e<span class="p">;</span> /* does not work */
</span></code></pre></td></tr></table></div></figure>


<h3>Partitioned External Tables</h3>

<p>You can use partitioning with external tables. The combination gives you a way to “share” data with other tools, while still optimizing query performance. While LOCATION clause is required for non-partitioned external table to specify data location, it is not required for external partitioned tables. Instead, <code>ALTER TABLE</code> statement is used to add data in each partition separately.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">EXTERNAL</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">log_messages</span> <span class="p">(</span>
</span><span class='line'>  <span class="n">hms</span>             <span class="nb">INT</span><span class="p">,</span>
</span><span class='line'>  <span class="n">severity</span>        <span class="n">STRING</span><span class="p">,</span>
</span><span class='line'>  <span class="n">server</span>          <span class="n">STRING</span><span class="p">,</span>
</span><span class='line'>  <span class="n">process_id</span>      <span class="nb">INT</span><span class="p">,</span>
</span><span class='line'>  <span class="n">message</span>         <span class="n">STRING</span><span class="p">)</span>
</span><span class='line'><span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="p">(</span><span class="k">year</span> <span class="nb">INT</span><span class="p">,</span> <span class="k">month</span> <span class="nb">INT</span><span class="p">,</span> <span class="k">day</span> <span class="nb">INT</span><span class="p">)</span>
</span><span class='line'><span class="k">ROW</span> <span class="n">FORMAT</span> <span class="n">DELIMITED</span> <span class="n">FIELDS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">&#39;\t&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span> <span class="k">ADD</span> <span class="n">PARTITION</span><span class="p">(</span><span class="k">year</span> <span class="o">=</span> <span class="mi">2012</span><span class="p">,</span> <span class="k">month</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="k">day</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
</span><span class='line'><span class="k">LOCATION</span> <span class="s1">&#39;hdfs://master_server/data/log_messages/2012/01/02&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">DESCRIBE</span> <span class="n">EXTENDED</span> <span class="n">log_messages</span> <span class="n">PARTITION</span> <span class="p">(</span><span class="k">year</span><span class="o">=</span><span class="mi">2012</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that <code>ALTER TABLE … ADD PARTITION</code> is not limited to external tables. You can use it with managed tables, too. However, it is not recommended since you have to manually keep track of this partition and remember to delete data in case you want to completely drop the managed table.</p>

<h4>Example use case of partitioned external tables</h4>

<p>For example, each day we might use the following procedure to move data older than a month to S3:</p>

<p>1) Copy the data for the partition being moved to S3. For example, you can use the hadoop distcp command:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> hadoop distcp /data/log_messages/2011/12/02 s3n://ourbucket/logs/2011/12/02
</span></code></pre></td></tr></table></div></figure>


<p>2) Alter the table to point the partition to the S3 location:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'> <span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span> <span class="n">PARTITION</span><span class="p">(</span><span class="k">year</span> <span class="o">=</span> <span class="mi">2011</span><span class="p">,</span> <span class="k">month</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span> <span class="k">day</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
</span><span class='line'> <span class="k">SET</span> <span class="k">LOCATION</span> <span class="s1">&#39;s3n://ourbucket/logs/2011/01/02&#39;</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>3) Remove the HDFS copy of the partition using the hadoop fs -rmr command:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> hadoop fs -rmr /data/log_messages/2011/01/02
</span></code></pre></td></tr></table></div></figure>


<h3>Altering Partitioned Tables</h3>

<p>Some basic <code>ALTER TABLE</code> statements for manipulating table partitions are shown in the following examples:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="cm">/* Add partition */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span> <span class="k">ADD</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span>
</span><span class='line'><span class="n">PARTITION</span> <span class="p">(</span><span class="k">year</span> <span class="o">=</span> <span class="mi">2011</span><span class="p">,</span> <span class="k">month</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'><span class="k">LOCATION</span> <span class="err">‘</span><span class="o">/</span><span class="n">logs</span><span class="o">/</span><span class="mi">2011</span><span class="o">/</span><span class="mi">01</span><span class="err">&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* Change partition location */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span> <span class="n">PARTITION</span> <span class="p">(</span><span class="k">year</span> <span class="o">=</span> <span class="mi">2011</span><span class="p">,</span> <span class="k">month</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'><span class="k">SET</span> <span class="k">LOCATION</span> <span class="err">‘</span><span class="o">/</span><span class="n">bucket</span><span class="o">/</span><span class="n">logs</span><span class="o">/</span><span class="mi">2011</span><span class="o">/</span><span class="mi">01</span><span class="err">’</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* Drop partition */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span> <span class="k">DROP</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">PARTITION</span> <span class="p">(</span><span class="k">year</span> <span class="o">=</span> <span class="mi">2011</span><span class="p">,</span> <span class="k">month</span> <span class="o">=</span> <span class="mi">1</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* Alter storage properties of partition */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span>
</span><span class='line'><span class="n">PARTITION</span><span class="p">(</span><span class="k">year</span> <span class="o">=</span> <span class="mi">2012</span><span class="p">,</span> <span class="k">month</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="k">day</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'><span class="k">SET</span> <span class="n">FILEFORMAT</span> <span class="n">SEQUENCEFILE</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* Archive partition */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span> <span class="n">ARCHIVE</span>
</span><span class='line'><span class="n">PARTITION</span><span class="p">(</span><span class="k">year</span> <span class="o">=</span> <span class="mi">2012</span><span class="p">,</span> <span class="k">month</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="k">day</span> <span class="o">=</span> <span class="mi">1</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>The <code>ALTER TABLE ... ARCHIVE PARTITION</code> statement captures the partition files into a Hadoop archive (HAR) file. This only reduces the number of files in the filesystem, reducing the load on the NameNode, but doesn’t provide any space savings. To reverse the operation, substitute UNARCHIVE for ARCHIVE. This feature is only available for individual partitions of partitioned tables.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive Tutorial (Pt. 6): HiveQL Data Definition]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/05/programming-hive-ddl-table/"/>
    <updated>2015-12-05T20:15:56-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/05/programming-hive-ddl-table</id>
    <content type="html"><![CDATA[<p>Continued from the previous <a href="http://tdongsi.github.io/blog/2015/12/02/programming-hive-hiveql-ddl/">post</a>.</p>

<h3>Creating Tables</h3>

<p>Some basic HiveQL&rsquo;s table DDL commands are shown in the following examples:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="cm">/* NOTE: the LOCATION clause uses the default location */</span>
</span><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">college</span><span class="p">.</span><span class="n">student</span> <span class="p">(</span>
</span><span class='line'>  <span class="n">name</span> <span class="n">STRING</span> <span class="k">COMMENT</span> <span class="s1">&#39;Student name&#39;</span><span class="p">,</span>
</span><span class='line'>  <span class="n">sid</span> <span class="nb">INT</span> <span class="k">COMMENT</span> <span class="s1">&#39;Student ID&#39;</span><span class="p">,</span>
</span><span class='line'><span class="p">)</span>
</span><span class='line'><span class="k">COMMENT</span> <span class="s1">&#39;Description of the table&#39;</span> <span class="n">TBLPROPERTIES</span> <span class="p">(</span> <span class="s1">&#39;creator&#39;</span> <span class="o">=</span> <span class="s1">&#39;me&#39;</span> <span class="p">)</span>
</span><span class='line'><span class="k">LOCATION</span> <span class="s1">&#39;/user/hive/warehouse/college.db/student&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* </span>
</span><span class='line'><span class="cm"> * copy the schema of an existing table</span>
</span><span class='line'><span class="cm"> * you can specify optional LOCATION but no other can be defined</span>
</span><span class='line'><span class="cm"> */</span>
</span><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">mydb</span><span class="p">.</span><span class="n">clone</span> <span class="k">LIKE</span> <span class="n">mydb</span><span class="p">.</span><span class="n">employees</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm">* Create external table</span>
</span><span class='line'><span class="cm">* Read all data files with comma-delimited format</span>
</span><span class='line'><span class="cm">* from /data/stocks</span>
</span><span class='line'><span class="cm">* LOCATION is required for external table</span>
</span><span class='line'><span class="cm">*/</span>
</span><span class='line'><span class="k">CREATE</span> <span class="k">EXTERNAL</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">stocks</span> <span class="p">(</span>
</span><span class='line'>  <span class="n">exchange</span>        <span class="n">STRING</span><span class="p">,</span>
</span><span class='line'>  <span class="n">symbol</span>          <span class="n">STRING</span><span class="p">,</span>
</span><span class='line'>  <span class="n">volume</span>          <span class="nb">INT</span><span class="p">,</span>
</span><span class='line'>  <span class="n">price_adj_close</span> <span class="nb">FLOAT</span><span class="p">)</span>
</span><span class='line'><span class="k">ROW</span> <span class="n">FORMAT</span> <span class="n">DELIMITED</span> <span class="n">FIELDS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">&#39;,&#39;</span>
</span><span class='line'><span class="k">LOCATION</span> <span class="s1">&#39;/data/stocks&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm">* Copy external table schema.</span>
</span><span class='line'><span class="cm">*/</span>
</span><span class='line'><span class="k">CREATE</span> <span class="k">EXTERNAL</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">ext_clone</span>
</span><span class='line'><span class="k">LIKE</span> <span class="n">stocks</span>
</span><span class='line'><span class="k">LOCATION</span> <span class="s1">&#39;/path/to/data&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm">* Drop table</span>
</span><span class='line'><span class="cm">* For managed tables, the table metadata and data are deleted.</span>
</span><span class='line'><span class="cm">* For external tables, the metadata is deleted but the data is not.</span>
</span><span class='line'><span class="cm">*/</span>
</span><span class='line'><span class="k">DROP</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">college</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that in the first <code>CREATE TABLE</code> command, you can prefix a database name, e.g. <code>mydb</code>, even when it is not your current working database. As usual, the optional <code>IF NOT EXISTS</code> clause will ignore the statement if the table already exists, even when the schema does not match (no warning from Hive). The second <code>CREATE TABLE</code> command is useful to copy the schema of an existing table. The corresponding commands for <strong>external</strong> table are also shown above (note <code>EXTERNAL TABLE</code>). The concept of external table in Hive will be discussed shortly.</p>

<p>The <code>SHOW TABLES</code> command lists the tables. You use different variants of that command to find tables of interest as shown below:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>hive&gt; use college<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>Time taken: 0.048 seconds
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>/* Show list of tables in current database */
</span><span class='line'>hive&gt; show tables<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>apply
</span><span class='line'>college
</span><span class='line'>student
</span><span class='line'>Time taken: 0.031 seconds, Fetched: <span class="m">3</span> row<span class="o">(</span>s<span class="o">)</span>
</span><span class='line'>
</span><span class='line'>/* Show list of tables in the specified database */
</span><span class='line'>hive&gt; show tables in college<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>apply
</span><span class='line'>college
</span><span class='line'>student
</span><span class='line'>Time taken: 0.034 seconds, Fetched: <span class="m">3</span> row<span class="o">(</span>s<span class="o">)</span>
</span><span class='line'>
</span><span class='line'>/* use regex to search tables in current database */
</span><span class='line'>hive&gt; show tables <span class="s1">&#39;.*e.*&#39;</span><span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>college
</span><span class='line'>student
</span><span class='line'>Time taken: 0.025 seconds, Fetched: <span class="m">2</span> row<span class="o">(</span>s<span class="o">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>/* Show table properties */
</span><span class='line'>hive&gt; show tblproperties student<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>COLUMN_STATS_ACCURATE <span class="nb">true</span>
</span><span class='line'>comment   List of students
</span><span class='line'>numFiles  1
</span><span class='line'>numRows   0
</span><span class='line'>rawDataSize   0
</span><span class='line'>totalSize 213
</span><span class='line'>transient_lastDdlTime 1421796179
</span><span class='line'>Time taken: 0.28 seconds, Fetched: <span class="m">7</span> row<span class="o">(</span>s<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>You can use <code>DESCRIBE</code> command to display table information as shown below:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>hive&gt; describe extended student<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>sid                   int                     Student ID
</span><span class='line'>sname                 string                  Student name
</span><span class='line'>gpa                   float                   Student GPA
</span><span class='line'>sizehs                int                     Size of student highschool
</span><span class='line'>      
</span><span class='line'>Detailed Table Information    Table<span class="o">(</span>tableName:student, dbName:college, owner:cloudera, createTime:1421796178, lastAccessTime:0, retention:0,
</span><span class='line'>sd:StorageDescriptor<span class="o">(</span>cols:<span class="o">[</span>FieldSchema<span class="o">(</span>name:sid, <span class="nb">type</span>:int, comment:Student ID<span class="o">)</span>, FieldSchema<span class="o">(</span>name:sname, <span class="nb">type</span>:string, comment:Student name<span class="o">)</span>, ...
</span><span class='line'>Time taken: 0.119 seconds, Fetched: <span class="m">6</span> row<span class="o">(</span>s<span class="o">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>/* more readable and verbose */
</span><span class='line'>hive&gt; describe formatted student<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'><span class="c"># col_name                data_type               comment             </span>
</span><span class='line'>      
</span><span class='line'>sid                   int                     Student ID
</span><span class='line'>sname                 string                  Student name
</span><span class='line'>gpa                   float                   Student GPA
</span><span class='line'>sizehs                int                     Size of student highschool
</span><span class='line'>      
</span><span class='line'><span class="c"># Detailed Table Information       </span>
</span><span class='line'>Database:             college                 
</span><span class='line'>Owner:                cloudera                
</span><span class='line'>CreateTime:           Tue Jan <span class="m">20</span> 15:22:58 PST 2015 
</span><span class='line'>LastAccessTime:       UNKNOWN                 
</span><span class='line'>Protect Mode:         None                    
</span><span class='line'>Retention:            <span class="m">0</span>                    
</span><span class='line'>Location:             hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/student  
</span><span class='line'>Table Type:           MANAGED_TABLE           
</span><span class='line'>Table Parameters:     
</span><span class='line'>  COLUMN_STATS_ACCURATE   <span class="nb">true                </span>
</span><span class='line'><span class="nb"> </span>comment              List of students
</span><span class='line'>  numFiles                <span class="m">1</span>
</span><span class='line'>  numRows                 <span class="m">0</span>
</span><span class='line'>  rawDataSize             <span class="m">0</span>
</span><span class='line'>  totalSize               <span class="m">213</span>
</span><span class='line'>  transient_lastDdlTime   <span class="m">1421796179</span>
</span><span class='line'>      
</span><span class='line'><span class="c"># Storage Information      </span>
</span><span class='line'>SerDe Library:        org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe  
</span><span class='line'>InputFormat:          org.apache.hadoop.mapred.TextInputFormat    
</span><span class='line'>OutputFormat:         org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat  
</span><span class='line'>Compressed:           No                      
</span><span class='line'>Num Buckets:          -1                      
</span><span class='line'>Bucket Columns:       <span class="o">[]</span>                   
</span><span class='line'>Sort Columns:         <span class="o">[]</span>                   
</span><span class='line'>Storage Desc Params:      
</span><span class='line'>  field.delim             <span class="p">;</span>
</span><span class='line'>  serialization.format    <span class="p">;</span>
</span><span class='line'>Time taken: 0.108 seconds, Fetched: <span class="m">36</span> row<span class="o">(</span>s<span class="o">)</span>
</span><span class='line'>
</span><span class='line'>/* see schema <span class="k">for</span> a column */
</span><span class='line'>hive&gt; describe student.sid<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>sid                   int                     from deserializer
</span><span class='line'>Time taken: 0.315 seconds, Fetched: <span class="m">1</span> row<span class="o">(</span>s<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Managed tables vs External tables</h3>

<p><code>CREATE TABLE</code> commands (without <code>EXTERNAL</code>) create <em>managed tables</em> or <em>internal tables</em>. It is internal/managed because the life cycle of their data is managed by Hive. By default, Hive stores data for these tables in a subdirectory under the directory defined by <code>hive.metastore.warehouse.dir</code>, as illustrated below (see <a href="http://tdongsi.github.io/blog/2015/11/23/programming-hive-hive-cli/">Hive CLI</a> for <code>SET</code> and <code>dfs</code> commands). When we drop a mananged table with <code>DROP TABLE</code> command, the data in the table will be deleted.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>hive&gt; SET hive.metastore.warehouse.dir<span class="p">;</span>
</span><span class='line'>hive.metastore.warehouse.dir<span class="o">=</span>/user/hive/warehouse
</span><span class='line'>hive&gt; dfs -ls /user/hive/warehouse/college.db<span class="p">;</span>
</span><span class='line'>Found <span class="m">3</span> items
</span><span class='line'>drwxrwxrwx   - hive hive          <span class="m">0</span> 2015-01-21 11:29 /user/hive/warehouse/college.db/apply
</span><span class='line'>drwxrwxrwx   - hive hive          <span class="m">0</span> 2015-12-03 15:16 /user/hive/warehouse/college.db/college
</span><span class='line'>drwxrwxrwx   - hive hive          <span class="m">0</span> 2015-01-28 15:26 /user/hive/warehouse/college.db/student
</span></code></pre></td></tr></table></div></figure>


<p>As mentioned in <a href="http://tdongsi.github.io/blog/2015/11/26/programming-hive-data-types/">Schema on Read</a>, Hive does not have control over the underlying storage, even for <em>managed table</em>: for example, you can totally use another <code>dfs</code> command in the last example to modify files on HDFS.</p>

<p>Managed tables are not convenient for sharing data with other tools. Instead, <em>external tables</em> can be defined to point to that data, but don&rsquo;t take ownership of data. In the <code>CREATE EXTERNAL TABLE</code> command example at the beginning of this post, the data files are in HDFS at <code>/data/stocks</code> and the external table will be created and populated by reading all comma-delimited data files in that location. The <code>LOCATION</code> clause is required for external table, to tell Hive where it is located. Dropping an external table does not delete the data since Hive does not <em>own</em> the data. However, the <em>metadata</em> for that table will be deleted.</p>

<p>To tell whether if a table is managed or external, use the command <code>DESCRIBE FORMATTED</code>. In the example in the last section, we see that the table <code>college.student</code> is a managed table because of its output:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>Location:            hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/student  
</span><span class='line'>Table Type:           MANAGED_TABLE
</span></code></pre></td></tr></table></div></figure>


<p>For external tables, the output will be like <code>Table Type: EXTERNAL_TABLE</code>.</p>

<h3>Altering Tables</h3>

<p>The <code>ALTER TABLE</code> statements <em>only</em> change <em>metadata</em> of the table, but not the data in the table. It&rsquo;s up to us to ensure that any schema modifications are consistent with the actual data.</p>

<p>Some basic <code>ALTER TABLE</code> statements for renaming table and changing table columns are shown in the following examples:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="cm">/* Renaming table */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">college</span> <span class="k">RENAME</span> <span class="k">TO</span> <span class="n">university</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm"> * Change columns: rename, change its position, type, or comment.</span>
</span><span class='line'><span class="cm"> * The keyword COLUMN is optional, as well as COMMENT clause.</span>
</span><span class='line'><span class="cm"> * This command changes metadata only. </span>
</span><span class='line'><span class="cm"> * The data has to be moved to match the new columns if needed.</span>
</span><span class='line'><span class="cm"> * Use FIRST, instead of AFTER, if the column is moved to first.</span>
</span><span class='line'><span class="cm"> */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span>
</span><span class='line'><span class="n">CHANGE</span> <span class="k">COLUMN</span> <span class="n">hms</span> <span class="n">hours_minutes_seconds</span> <span class="nb">INT</span>
</span><span class='line'><span class="k">COMMENT</span> <span class="s1">&#39;New comment&#39;</span>
</span><span class='line'><span class="k">AFTER</span> <span class="n">severity</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm"> * Add columns, to the end of existing columns.</span>
</span><span class='line'><span class="cm"> * Use CHANGE COLUMN to rearrange if needed.</span>
</span><span class='line'><span class="cm"> */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span>
</span><span class='line'><span class="k">ADD</span> <span class="n">COLUMNS</span> <span class="p">(</span>
</span><span class='line'><span class="n">app_name</span> <span class="n">STRING</span> <span class="k">COMMENT</span> <span class="s1">&#39;New column 1&#39;</span><span class="p">,</span>
</span><span class='line'><span class="n">session_id</span> <span class="nb">INT</span> <span class="k">COMMENT</span> <span class="s1">&#39;New column 2&#39;</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm"> * Remove all the existing columns and replaces with new </span>
</span><span class='line'><span class="cm"> * specified columns.</span>
</span><span class='line'><span class="cm"> */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span>
</span><span class='line'><span class="k">REPLACE</span> <span class="n">COLUMNS</span> <span class="p">(</span>
</span><span class='line'><span class="n">app_name</span> <span class="n">STRING</span> <span class="k">COMMENT</span> <span class="s1">&#39;New column 1&#39;</span><span class="p">,</span>
</span><span class='line'><span class="n">session_id</span> <span class="nb">INT</span> <span class="k">COMMENT</span> <span class="s1">&#39;New column 2&#39;</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* </span>
</span><span class='line'><span class="cm"> * You can add table properties or set current properties,</span>
</span><span class='line'><span class="cm"> * but not remove them </span>
</span><span class='line'><span class="cm"> */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span>
</span><span class='line'><span class="k">SET</span> <span class="n">TBLPROPERTIES</span> <span class="p">(</span>
</span><span class='line'><span class="s1">&#39;some_key&#39;</span> <span class="o">=</span> <span class="s1">&#39;some_value&#39;</span>
</span><span class='line'><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive Tutorial (Pt. 5): HiveQL Data Definition]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/02/programming-hive-hiveql-ddl/"/>
    <updated>2015-12-02T18:32:21-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/02/programming-hive-hiveql-ddl</id>
    <content type="html"><![CDATA[<p>This post covers data definition parts of HiveQL language, mostly for creating, altering, and dropping databases and tables. Note that Hive does not support row-level inserts, updates, and deletes. However, Hive adds extensions for better performance in the context of Hadoop.</p>

<h3>Databases</h3>

<p>In Hive, the concept of a database is basically just a namespace of tables. The keyword SCHEMA can be used instead of DATABASE in all the database-related commands. If you don’t specify a database, the <code>default</code> database is used.</p>

<p>Some basic HiveQL&rsquo;s database commands is shown in the following examples:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">DATABASE</span> <span class="n">college</span><span class="p">;</span>
</span><span class='line'><span class="k">CREATE</span> <span class="k">DATABASE</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">college</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">SHOW</span> <span class="n">DATABASES</span><span class="p">;</span>
</span><span class='line'><span class="k">SHOW</span> <span class="n">DATABASES</span> <span class="k">LIKE</span> <span class="s1">&#39;h.*&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">CREATE</span> <span class="k">DATABASE</span> <span class="n">college</span>
</span><span class='line'><span class="k">LOCATION</span> <span class="s1">&#39;/my/preferred/directory&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* add comments to table */</span>
</span><span class='line'><span class="k">CREATE</span> <span class="k">DATABASE</span> <span class="n">college</span> <span class="k">COMMENT</span> <span class="s1">&#39;A college admission database&#39;</span><span class="p">;</span>
</span><span class='line'><span class="cm">/* show comments */</span>
</span><span class='line'><span class="k">DESCRIBE</span> <span class="k">DATABASE</span> <span class="n">college</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* add properties */</span>
</span><span class='line'><span class="k">CREATE</span> <span class="k">DATABASE</span> <span class="n">college</span> <span class="k">WITH</span> <span class="n">DBPROPERTIES</span> <span class="p">(</span> <span class="s1">&#39;creator&#39;</span> <span class="o">=</span> <span class="s1">&#39;CD&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span> <span class="o">=</span> <span class="s1">&#39;today&#39;</span> <span class="p">);</span>
</span><span class='line'><span class="cm">/* show properties */</span>
</span><span class='line'><span class="k">DESCRIBE</span> <span class="k">DATABASE</span> <span class="n">EXTENDED</span> <span class="n">college</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* set working database */</span>
</span><span class='line'><span class="n">USE</span> <span class="n">college</span><span class="p">;</span>
</span><span class='line'><span class="cm">/* this will show tables in this database */</span>
</span><span class='line'><span class="k">SHOW</span> <span class="n">TABLES</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">DROP</span> <span class="k">DATABASE</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">college</span><span class="p">;</span>
</span><span class='line'><span class="cm">/* Drop tables if there is any table in the database */</span>
</span><span class='line'><span class="k">DROP</span> <span class="k">DATABASE</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">college</span> <span class="k">CASCADE</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* You can set additional key-value pairs in properties.</span>
</span><span class='line'><span class="cm"> * No other metadata about the database can be changed. No way to delete a DB PROPERTY.</span>
</span><span class='line'><span class="cm"> */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">DATABASE</span> <span class="n">college</span> <span class="k">SET</span> <span class="n">DBPROPERTIES</span> <span class="p">(</span><span class="s1">&#39;editor&#39;</span> <span class="o">=</span> <span class="s1">&#39;DC&#39;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that Hive will create separate directory for each database. The exception is the <code>default</code> database, which doesn&rsquo;t have its own directory. Tables in each database will be stored in subdirectories of the database directory. The location of the database directory is specified by the property <code>hive.metastore.warehouse.dir</code>. To help us understand better, these are illustrated by the Hive CLI commands as follows:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="o">[</span>cloudera@quickstart temp<span class="o">]</span><span class="nv">$ </span>hive
</span><span class='line'>
</span><span class='line'>Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
</span><span class='line'>hive&gt; describe database default<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>default   Default Hive database   hdfs://quickstart.cloudera:8020/user/hive/warehouse public  ROLE    
</span><span class='line'>Time taken: 0.01 seconds, Fetched: <span class="m">1</span> row<span class="o">(</span>s<span class="o">)</span>
</span><span class='line'>hive&gt; describe database college<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>college       hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db  cloudera    USER    
</span><span class='line'>Time taken: 0.011 seconds, Fetched: <span class="m">1</span> row<span class="o">(</span>s<span class="o">)</span>
</span><span class='line'>
</span><span class='line'>hive&gt; SET hive.metastore.warehouse.dir<span class="p">;</span>
</span><span class='line'>hive.metastore.warehouse.dir<span class="o">=</span>/user/hive/warehouse
</span><span class='line'>
</span><span class='line'>hive&gt; dfs -ls hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db<span class="p">;</span>
</span><span class='line'>Found <span class="m">3</span> items
</span><span class='line'>drwxrwxrwx   - hive hive          <span class="m">0</span> 2015-01-21 11:29 hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/apply
</span><span class='line'>drwxrwxrwx   - hive hive          <span class="m">0</span> 2015-01-20 15:22 hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/college
</span><span class='line'>drwxrwxrwx   - hive hive          <span class="m">0</span> 2015-01-28 15:26 hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/student
</span><span class='line'>hive&gt; dfs -ls hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/student<span class="p">;</span>
</span><span class='line'>Found <span class="m">1</span> items
</span><span class='line'>-rwxrwxrwx   <span class="m">1</span> cloudera hive        <span class="m">213</span> 2015-01-20 15:22 hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/student/student.data
</span><span class='line'>hive&gt; dfs -ls hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/college<span class="p">;</span>
</span><span class='line'>Found <span class="m">1</span> items
</span><span class='line'>-rwxrwxrwx   <span class="m">1</span> cloudera hive         <span class="m">66</span> 2015-01-20 15:22 hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/college/college.data
</span></code></pre></td></tr></table></div></figure>


<p>In the output of the <code>DESCRIBE DATABASE</code> commands above, the directory location of the database is shown, with <code>hdfs</code> as URI scheme. Note that <code>hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db</code> is equivalent to <code>hdfs://user/hive/warehouse/college.db</code>, where <code>quickstart.cloudera:8020</code> is simply the master node’s DNS name and port on Cloudera Quickstart VM. The name of the database directory is always <code>database_name.db</code>, with <code>.db</code> suffix added to database name. The three tables <code>college</code>, <code>student</code>, and <code>apply</code> in the <code>college</code> database are created as sub-directories in that <code>college.db</code> directory, as shown above. When a database is dropped, its directory is also deleted. By default, Hive will not allow you to drop a database that contains tables. The second <code>DROP DATABASE</code> command with <code>CASCADE</code> will force Hive to drop the database by dropping the tables in the database first.</p>

<p>There is no command to show the current working database. When in doubt, it is safe to use the command <code>USE database_name;</code> repeatedly since there is no nesting of databases in Hive. Otherwise, you can set a property to show the current working database in Hive CLI prompt as follows:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>hive&gt; <span class="nb">set </span>hive.cli.print.current.db<span class="o">=</span><span class="nb">true</span><span class="p">;</span>
</span><span class='line'>hive <span class="o">(</span>default<span class="o">)</span>&gt; USE college<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>Time taken: 0.278 seconds
</span><span class='line'>hive <span class="o">(</span>college<span class="o">)</span>&gt;
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive Tutorial (Pt. 4): Data Types]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/26/programming-hive-data-types/"/>
    <updated>2015-11-26T18:01:37-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/26/programming-hive-data-types</id>
    <content type="html"><![CDATA[<p>This post covers different data types and file formats supported by Hive.</p>

<h3>Data Types</h3>

<p>The following primitive data types are supported:</p>

<ul>
<li>TINYINT: 1 byte signed integer</li>
<li>SMALLINT: 2 bytes</li>
<li>INT: 4 bytes</li>
<li>BIGINT: 8 bytes</li>
<li>BOOLEAN</li>
<li>FLOAT</li>
<li>DOUBLE</li>
<li>STRING: Single or doublbe quotes can be used for literals.</li>
<li>TIMESTAMP: Integer, float, or string.

<ul>
<li>Integer: For seconds from Unix epoch.</li>
<li>Float: Seconds from Unix epoch and nanoseconds.</li>
<li>String: JDBC-compliant java.sql.Timestamp format convention, i.e. YYYY-MM-DD hh:mm:ss.fffffffff</li>
</ul>
</li>
<li>BINARY: array of bytes. Used to include arbitrary bytes and prevent Hive from attempting to parse them.</li>
</ul>


<p>As you can see, Hive supports most basic primitive data types conventionally found in relational databases. Moreover, it helps to remember that these data types are implemented in Java, so their behaviors will be similar to their Java counterparts.</p>

<p>NOTE: Not metioned in the <strong>Programming Hive</strong> book, but the types <code>DECIMAL</code> and <code>DATE</code> are introduced since Hive 0.13.0. In addition, the book claimed &ldquo;Hive does not support character arrays with maximum-allowed lengths, as is common in other SQL dialects&rdquo; but <code>VARCHAR</code> type, introduced in Hive 0.12.0, does exactly that.</p>

<p>Besides primitive data types, Hive supports the following collection data types:</p>

<ul>
<li>STRUCT: Analogous to a C <code>struct</code> or POJO (Plain Old Java Object). The elements can be accessed using the DOT (.) notation.

<ul>
<li>Example: Declaration <code>struct&lt;name:string,id:int&gt;</code>. Literal <code>struct('John',1)</code>.</li>
</ul>
</li>
<li>MAP: A collection of key-value tuples. The elements can be accessed using array notation, e.g. persons[&lsquo;John&rsquo;].

<ul>
<li>Example: Declaration <code>map&lt;string,int&gt;</code>. Literal <code>map('John',1)</code>.</li>
</ul>
</li>
<li>ARRAY: Ordered sequences of the same type. The elements can be accessed using array notation, e.g. person[2].

<ul>
<li>Example: Declaration <code>array&lt;string&gt;</code>. Literal <code>array('John','Peter')</code>.</li>
</ul>
</li>
</ul>


<p>Relational databases don&rsquo;t usually support such collection types because they tend to break <strong>normal form</strong>. In Hive/Hadoop, sacrificing normal form is pretty common as it can give benefit of higher processing throughput, especially with large amount of data (tens of terarbytes).</p>

<h3>Text File Formats</h3>

<p>Hive can use comma-separated values (CSV) or tab-separated values (TSV) text file format. A Hive table declaration with all row format specified (with default values, however) looks like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">employees</span> <span class="p">(</span>
</span><span class='line'>  <span class="n">name</span>         <span class="n">STRING</span><span class="p">,</span>
</span><span class='line'>  <span class="n">salary</span>       <span class="nb">FLOAT</span><span class="p">,</span>
</span><span class='line'>  <span class="n">subordinates</span> <span class="nb">ARRAY</span><span class="o">&lt;</span><span class="n">STRING</span><span class="o">&gt;</span><span class="p">,</span>
</span><span class='line'>  <span class="n">deductions</span>   <span class="k">MAP</span><span class="o">&lt;</span><span class="n">STRING</span><span class="p">,</span> <span class="nb">FLOAT</span><span class="o">&gt;</span><span class="p">,</span>
</span><span class='line'>  <span class="n">address</span>      <span class="n">STRUCT</span><span class="o">&lt;</span><span class="n">street</span><span class="p">:</span><span class="n">STRING</span><span class="p">,</span> <span class="n">city</span><span class="p">:</span><span class="n">STRING</span><span class="p">,</span> <span class="k">state</span><span class="p">:</span><span class="n">STRING</span><span class="p">,</span> <span class="n">zip</span><span class="p">:</span><span class="nb">INT</span><span class="o">&gt;</span>
</span><span class='line'><span class="p">)</span>
</span><span class='line'><span class="k">ROW</span> <span class="n">FORMAT</span> <span class="n">DELIMITED</span>
</span><span class='line'><span class="n">FIELDS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">&#39;\001&#39;</span>
</span><span class='line'><span class="n">COLLECTION</span> <span class="n">ITEMS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">&#39;\002&#39;</span>
</span><span class='line'><span class="k">MAP</span> <span class="n">KEYS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">&#39;\003&#39;</span>
</span><span class='line'><span class="n">LINES</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">&#39;\n&#39;</span>
</span><span class='line'><span class="n">STORED</span> <span class="k">AS</span> <span class="n">TEXTFILE</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Schema on Read</h3>

<p>Different from databases, Hive has no control over the underlying storage: for example, you can modify files on HDFS that Hive will query. Hive tries its best to read the data and match the schema. If the file content does not match the schema such as non-numeric strings found when numbers expected, you may get null values.</p>

<h3>Additional References</h3>

<p>As of November 2015, the <strong>Programming Hive (2nd edition)</strong> book uses slightly a outdated Hive version 0.9.0 (Chapter 2, Installing Hive). Information in the following links are used when writing this post:</p>

<ol>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/Tutorial">https://cwiki.apache.org/confluence/display/Hive/Tutorial</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive Tutorial (Pt. 3): Runtime Modes]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/24/programming-hive-getting-started/"/>
    <updated>2015-11-24T18:24:30-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/24/programming-hive-getting-started</id>
    <content type="html"><![CDATA[<p>Following up on <a href="http://tdongsi.github.io/blog/2015/11/23/programming-hive-hive-cli/">Hive CLI</a>, this post covers some lower-level details of Hive such as Hadoop runtime modes and metastore.</p>

<h3>Runtime Modes</h3>

<p>There are different runtime modes for Hadoop. Because Hive uses Hadoop jobs for most of its work, its behavior is dependent on Hadoop runtime mode that you are using. However, even in distributed mode, Hive can decide on a per-query basis if it can perform the query using just local mode to provide better turnaround.</p>

<table>
<thead>
<tr>
<th> Local Mode </th>
<th> Distributed Mode </th>
<th> Pseudodistributed Mode </th>
</tr>
</thead>
<tbody>
<tr>
<td> Filesystem references use local filesystem. </td>
<td> Filesystem referenes use HDFS. </td>
<td> Similar to distributed mode. </td>
</tr>
<tr>
<td> MapReduce tasks in same process. </td>
<td>  MapReduce tasks in separate <br>processes, managed by JobTracker service. </td>
<td> Similar to distributed mode.</td>
</tr>
<tr>
<td> Default mode. </td>
<td> Usually configured for server clusters. </td>
<td> Like a cluster of one node.</td>
</tr>
</tbody>
</table>


<p><br></p>

<p>Pseudodistributed mode is mainly for developers working on personal machines or VM&rsquo;s when testing their applications since local mode doesn’t fully reflect the behavior of a real cluster. Changes to configuration are done by editing the <code>hive-site.xml</code> file in <code>$HIVE_HOME/conf</code> folder (e.g., <code>/usr/lib/hive/conf</code> on Cloudera VM). Create one if it doesn’t already exist.</p>

<h3>Metastore Using JDBC</h3>

<p>Hive requires only one extra component that Hadoop does not already have; the metastore component. The metastore stores metadata such as table schema and partition information that you specify when you run commands such as create table x&hellip;, or alter table y&hellip;, etc. Any JDBC-compliant database can be used for the metastore. In practice, most installations of Hive use MySQL. In <code>hive-site.xml</code> file, the metastore database configuration looks like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>  <span class="nt">&lt;property&gt;</span>
</span><span class='line'>    <span class="nt">&lt;name&gt;</span>javax.jdo.option.ConnectionURL<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>    <span class="nt">&lt;value&gt;</span>jdbc:mysql://127.0.0.1/metastore?createDatabaseIfNotExist=true<span class="nt">&lt;/value&gt;</span>
</span><span class='line'>    <span class="nt">&lt;description&gt;</span>JDBC connect string for a JDBC metastore<span class="nt">&lt;/description&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/property&gt;</span>
</span><span class='line'>
</span><span class='line'>  <span class="nt">&lt;property&gt;</span>
</span><span class='line'>    <span class="nt">&lt;name&gt;</span>javax.jdo.option.ConnectionDriverName<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>    <span class="nt">&lt;value&gt;</span>com.mysql.jdbc.Driver<span class="nt">&lt;/value&gt;</span>
</span><span class='line'>    <span class="nt">&lt;description&gt;</span>Driver class name for a JDBC metastore<span class="nt">&lt;/description&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/property&gt;</span>
</span><span class='line'>
</span><span class='line'>  <span class="nt">&lt;property&gt;</span>
</span><span class='line'>    <span class="nt">&lt;name&gt;</span>javax.jdo.option.ConnectionUserName<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>    <span class="nt">&lt;value&gt;</span>hive<span class="nt">&lt;/value&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/property&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>The information stored in metastore is typically much smaller than the data stored in Hive. Therefore, you typically don’t need a powerful dedicated database server for the metastore. However since it represents a Single Point of Failure (SPOF), it is strongly recommended that you replicate and back up this database using the best practices like any other database instances.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive Tutorial (Pt. 2): Hive CLI]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/23/programming-hive-hive-cli/"/>
    <updated>2015-11-23T19:47:23-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/23/programming-hive-hive-cli</id>
    <content type="html"><![CDATA[<p>This post covers how to get started with Hive and some basics of Hive, including its command-line interface (CLI).</p>

<h3>Starting Hive with Cloudera Quickstart VM</h3>

<p>On Cloudera Quickstart VM, the cores of its Hive distribution, including files such as <code>hive-exec*.jar</code> and <code>hive-metastore*.jar</code>, can be found in <code>/usr/lib/hive/lib</code>. The Hive executables can be found in <code>/usr/lib/hive/bin</code>. Running <code>hive</code> without any parameter will start Hive&rsquo;s CLI.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hive
</span><span class='line'>
</span><span class='line'>Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
</span><span class='line'>hive&gt; CREATE TABLE x (a INT);
</span><span class='line'>OK
</span><span class='line'>Time taken: 3.032 seconds
</span><span class='line'>hive&gt; SELECT * FROM x;
</span><span class='line'>OK
</span><span class='line'>Time taken: 0.465 seconds
</span><span class='line'>hive&gt; SELECT *        
</span><span class='line'>    &gt; FROM x;
</span><span class='line'>OK
</span><span class='line'>Time taken: 0.049 seconds
</span><span class='line'>hive&gt; DROP TABLE x;
</span><span class='line'>OK
</span><span class='line'>Time taken: 0.348 seconds
</span><span class='line'>hive&gt; exit;</span></code></pre></td></tr></table></div></figure>


<h3>Hive services</h3>

<p>The <code>hive</code> shell command is actually a wrapper to multiple Hive services, including the CLI.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hive --help
</span><span class='line'>Usage ./hive &lt;parameters&gt; --service serviceName &lt;service parameters&gt;
</span><span class='line'>Service List: beeline cli help hiveserver2 hiveserver hwi jar lineage metastore metatool orcfiledump rcfilecat schemaTool version 
</span><span class='line'>Parameters parsed:
</span><span class='line'>  --auxpath : Auxillary jars 
</span><span class='line'>  --config : Hive configuration directory
</span><span class='line'>  --service : Starts specific service/component. cli is default
</span><span class='line'>Parameters used:
</span><span class='line'>  HADOOP_HOME or HADOOP_PREFIX : Hadoop install directory
</span><span class='line'>  HIVE_OPT : Hive options
</span><span class='line'>For help on a particular service:
</span><span class='line'>  ./hive --service serviceName --help
</span><span class='line'>Debug help:  ./hive --debug --help</span></code></pre></td></tr></table></div></figure>


<p>Note the list of services following the line &ldquo;Service List&rdquo;. There are several services available, most notably <strong>cli, hwi, jar, metastore</strong>. You can use <code>--service name</code> option to invoke a service. CLI is the default service, not specifying any service in <code>hive</code> command will run CLI service, as shown in &ldquo;Starting Hive&rdquo; section above.</p>

<p>For example, to run <a href="https://cwiki.apache.org/confluence/display/Hive/HiveWebInterface">Hive Web Interface</a>, run the service <strong>hwi</strong>. On Cloudera Quickstart VM, you might encounter this error:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hive --service hwi
</span><span class='line'>ls: cannot access /usr/lib/hive/lib/hive-hwi-*.war: No such file or directory
</span><span class='line'>15/11/23 20:22:50 INFO hwi.HWIServer: HWI is starting up
</span><span class='line'>15/11/23 20:22:50 FATAL hwi.HWIServer: HWI WAR file not found at /usr/lib/hive/usr/lib/hive/lib/hive-hwi-0.8.1-cdh4.0.0.jar</span></code></pre></td></tr></table></div></figure>


<p>To fix that error, edit the config file <code>hive-site.xml</code> in the <code>config</code> folder (e.g., <code>/usr/lib/hive/conf/hive-site.xml</code> on Cloudera VM) to point to the right location of HWI&rsquo;s war file. On Cloudera Quickstart VM, the WAR file property block should look like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>...
</span><span class='line'> &lt;property&gt;
</span><span class='line'>    &lt;name&gt;hive.hwi.war.file&lt;/name&gt;
</span><span class='line'>    &lt;value&gt;/lib/hive-hwi.jar&lt;/value&gt;
</span><span class='line'>    &lt;description&gt;This is the WAR file with the jsp content for Hive Web Interface&lt;/description&gt;
</span><span class='line'>  &lt;/property&gt;
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>Running the <strong>hwi</strong> service again using <code>hive</code> command should work. In order to access the Hive Web Interface, go to <code>[Hive Server Address]</code>:9999/hwi on your web browser.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hive --service hwi
</span><span class='line'>ls: cannot access /usr/lib/hive/lib/hive-hwi-*.war: No such file or directory
</span><span class='line'>15/11/23 20:31:27 INFO hwi.HWIServer: HWI is starting up
</span><span class='line'>15/11/23 20:31:27 INFO mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
</span><span class='line'>15/11/23 20:31:27 INFO mortbay.log: jetty-6.1.26.cloudera.4
</span><span class='line'>15/11/23 20:31:27 INFO mortbay.log: Extract /usr/lib/hive/lib/hive-hwi.jar to /tmp/Jetty_0_0_0_0_9999_hive.hwi.0.13.1.cdh5.3.0.jar__hwi__.lcik1p/webapp
</span><span class='line'>15/11/23 20:31:28 INFO mortbay.log: Started SocketConnector@0.0.0.0:9999</span></code></pre></td></tr></table></div></figure>


<h3>Hive CLI</h3>

<p>Available options for Hive CLI can be displayed as follows:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hive --help --service cli
</span><span class='line'>usage: hive
</span><span class='line'> -d,--define &lt;key=value&gt;          Variable subsitution to apply to hive
</span><span class='line'>                                  commands. e.g. -d A=B or --define A=B
</span><span class='line'>    --database &lt;databasename&gt;     Specify the database to use
</span><span class='line'> -e &lt;quoted-query-string&gt;         SQL from command line
</span><span class='line'> -f &lt;filename&gt;                    SQL from files
</span><span class='line'> -H,--help                        Print help information
</span><span class='line'> -h &lt;hostname&gt;                    connecting to Hive Server on remote host
</span><span class='line'>    --hiveconf &lt;property=value&gt;   Use value for given property
</span><span class='line'>    --hivevar &lt;key=value&gt;         Variable subsitution to apply to hive
</span><span class='line'>                                  commands. e.g. --hivevar A=B
</span><span class='line'> -i &lt;filename&gt;                    Initialization SQL file
</span><span class='line'> -p &lt;port&gt;                        connecting to Hive Server on port number
</span><span class='line'> -S,--silent                      Silent mode in interactive shell
</span><span class='line'> -v,--verbose                     Verbose mode (echo executed SQL to the
</span><span class='line'>                                  console)</span></code></pre></td></tr></table></div></figure>


<h4>Hive variables and properties</h4>

<p>The <code>--define key=value</code> option is equivalent to the <code>--hivevar key=value</code> option. Both let you define custom variables in the <code>hivevar</code> namespace, separate from three other built-in namespaces, <code>hiveconf</code>, <code>system</code>, and <code>env</code>. By convention, the Hive namespaces for variables and properties are as follows:</p>

<ol>
<li>hivevar: user-defined custom variables.</li>
<li>hiveconf: Hive-specific configuration properties.</li>
<li>system: Java configuration properties.</li>
<li>env: (Read-only) environment variables by shell environment (e.g., bash).</li>
</ol>


<p>Inside Hive CLI, the command <code>SET</code> is used to display and change variables. For example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hive
</span><span class='line'>
</span><span class='line'>Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
</span><span class='line'>hive&gt; set env:HOME; &lt;-- display HOME variable in env namespace
</span><span class='line'>env:HOME=/home/cloudera
</span><span class='line'>hive&gt; set; &lt;-- display all variables
</span><span class='line'>...
</span><span class='line'>hive&gt; set -v; &lt;-- display even more variables
</span><span class='line'>...
</span><span class='line'>hive&gt; set hivevar:foo=bar; &lt;-- set foo variable in hivevar namespace to bar</span></code></pre></td></tr></table></div></figure>


<h4><code>-e query_string</code> and <code>-S</code> options</h4>

<p><code>-e</code> option allows you to execute a list of semicolon-separated queries as an input string. <code>-S</code> option for silent mode will remove non-essential output. For example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ hive -e "SELECT * FROM mytable LIMIT 3";
</span><span class='line'>OK
</span><span class='line'>name1 10
</span><span class='line'>name2 20
</span><span class='line'>name3 30
</span><span class='line'>Time taken: 4.955 seconds</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ hive -S -e "select * FROM mytable LIMIT 3"
</span><span class='line'>name1 10
</span><span class='line'>name2 20
</span><span class='line'>name3 30</span></code></pre></td></tr></table></div></figure>


<p><strong>Tip</strong>: To quickly search for the full name of a property that you only remember part of its name, pipe the Hive&rsquo;s <code>SET</code> command output to grep. For example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hive -S -e "set" | grep warehouse
</span><span class='line'>hive.metastore.warehouse.dir=/user/hive/warehouse
</span><span class='line'>hive.warehouse.subdir.inherit.perms=true</span></code></pre></td></tr></table></div></figure>


<h4><code>-f script_file</code> option</h4>

<p>This option allows you to execute one or more queries contained in a script file. If you are already within the Hive CLI, you can use the <code>SOURCE</code> command to execute a script file. For example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ cat /path/to/file/withqueries.hql
</span><span class='line'>SELECT x.* FROM src x;
</span><span class='line'>$ hive
</span><span class='line'>hive&gt; source /path/to/file/withqueries.hql;</span></code></pre></td></tr></table></div></figure>


<p></p>

<h4><code>-i filename</code> option</h4>

<p>This option lets you specify an initialization file with a list of commands for the CLI to run when it starts. The default initialization file is the file <code>$HOME/.hiverc</code> if it exists.</p>

<h4>Tips</h4>

<ul>
<li>To print column headers (disabled by default), set the hiveconf property <code>hive.cli.print.header</code> to true: <code>set hive.cli.print.header=true;</code>.</li>
<li>Hive does have command history, saved into a file <code>$HOME/.hivehistory</code>. Use the up and down arrow keys to scroll through previous commands.</li>
<li>To run HDFS commands from within Hive CLI, drop the hdfs. For example:</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hive&gt; dfs -ls input; 
</span><span class='line'>Found 1 items
</span><span class='line'>-rw-r--r--   1 cloudera cloudera         31 2015-01-15 18:04 input/wordcount.txt</span></code></pre></td></tr></table></div></figure>


<ul>
<li>To run the bash shell commands from within Hive CLI, prefix <code>!</code> before the bash commands and terminate the line with a semicolon (;). Note that interactive commands, shell pipes <code>|</code>, and file globs <code>*</code> will not work. Example:</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hive&gt; !pwd;
</span><span class='line'>hive&gt; /home/cloudera/temp</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Set the property <code>set hive.exec.mode.local.auto=true;</code> to use local mode more aggressively and gain performance in Hive queries, especially when working with small data sets.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive Tutorial (Pt. 1): Introduction]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/22/programming-hive-chapter-1/"/>
    <updated>2015-11-22T17:22:51-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/22/programming-hive-chapter-1</id>
    <content type="html"><![CDATA[<!---
"Chapter 1: Introduction" of the "Programming Hive" book.
-->


<p>This post is the first of many Hive tutorial posts. Most of these posts are based on the <strong>Programming Hive</strong> book, with some observations from my own experience with <a href="http://tdongsi.github.io/blog/2015/11/20/wordcount-sample-in-cloudera-quickstart-vm/">Cloudera Quickstart VM</a>.</p>

<p><img class="center" src="http://tdongsi.github.io/images/hive/cat.gif" title="Cover" ></p>

<h3>Introduction</h3>

<p>Hive provides a SQL dialect, called Hive Query Language (HiveQL or HQL) for querying data stored in a Hadoop cluster. SQL knowledge is widespread for a reason; it&rsquo;s an effective, reasonably intuitive model for organizing and using data. Therefore, Hive helps lower the barrier, making transition to Hadoop from traditional relational databases easier for database users such as business analysts.</p>

<p>Note that Hive is more suited for data warehouse applications, where data is relatively static and fast response time is not required. For example, a simple query such as <code>select count(*) from my_table</code> can take several seconds for a very small table (mostly due to startup overhead for MapReduce jobs). Hive is a heavily batch-oriented system: in addition to large startup overheads, it neither provides record-level update, insert, or delete nor transactions. In short, Hive is not a full database (hint: check HBase).</p>

<p>HiveQL does not conform to the ANSI SQL standard (not many do), but it is quite close to MySQL dialect.</p>

<h3>Hive within the Hadoop Ecosystem</h3>

<p>A basic understanding of Hadoop and MapReduce can help you to understand and appreciate how Hive works. Simple examples such as WordCount in my <a href="http://tdongsi.github.io/blog/2015/11/21/explaining-wordcount-example/">last post</a> can be very involving when using the Hadoop Java API. The API requires Java developers to manage many low-level details, repetitive wiring to/from Mappers and Reducers. The WordCount example&rsquo;s Java implementation can be found <a href="https://wiki.apache.org/hadoop/WordCount">here</a>.</p>

<p>Hive not only eliminates advanced, sometimes repetitive Java coding but also provides a familiar interface to those who know SQL. Hive lets you complete a lot of work with relatively little effort. For example, the same WordCount example in HiveQL can be as simple as:</p>

<figure class='code'><figcaption><span>WordCount example in HiveQL</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">docs</span> <span class="p">(</span><span class="n">line</span> <span class="n">STRING</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* Load text files into TABLE docs: each line as a row */</span>
</span><span class='line'><span class="k">LOAD</span> <span class="k">DATA</span> <span class="n">INPATH</span> <span class="s1">&#39;wordcount.txt&#39;</span> <span class="n">OVERWRITE</span> <span class="k">INTO</span> <span class="k">TABLE</span> <span class="n">docs</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">word_counts</span> <span class="k">AS</span>
</span><span class='line'><span class="k">SELECT</span> <span class="n">word</span><span class="p">,</span> <span class="k">count</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">AS</span> <span class="k">count</span>
</span><span class='line'><span class="k">FROM</span>
</span><span class='line'>   <span class="c1">-- explode will return rows of tokens</span>
</span><span class='line'>  <span class="p">(</span><span class="k">SELECT</span> <span class="n">explode</span><span class="p">(</span><span class="n">split</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="s1">&#39;\s&#39;</span><span class="p">))</span> <span class="k">AS</span> <span class="n">word</span>
</span><span class='line'>   <span class="k">FROM</span> <span class="n">docs</span><span class="p">)</span> <span class="n">w</span>
</span><span class='line'><span class="k">GROUP</span> <span class="k">BY</span> <span class="n">word</span>
</span><span class='line'><span class="k">ORDER</span> <span class="k">BY</span> <span class="n">word</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>




<!--
In the remaining sections of Chapter 1, the authors also discuss various related Hadoop projects such as Pig, Hue, HBase, Spark, Storm, Kafka, etc.
-->

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Overview of MapReduce: Explaining WordCount Example]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/21/explaining-wordcount-example/"/>
    <updated>2015-11-21T02:37:20-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/21/explaining-wordcount-example</id>
    <content type="html"><![CDATA[<p>MapReduce is a programming framework that decomposes large data processing jobs into individual tasks that can be executed in parallel across a cluster of servers. The name MapReduce comes from the fact that there are two fundamental data transformation operations: <em>map</em> and <em>reduce</em>. These MapReduce operations would be more clear if we walk through a simple example, such as WordCount in my last <a href="http://tdongsi.github.io/blog/2015/11/20/wordcount-sample-in-cloudera-quickstart-vm/">post</a>. The process flow of WordCount example is shown below:</p>

<!---
(from [here](https://www.safaribooksonline.com/library/view/programming-hive/9781449326944/ch01.html)):

![Process Flow of WordCount Example](https://www.safaribooksonline.com/library/view/programming-hive/9781449326944/httpatomoreillycomsourceoreillyimages1321235.png)
-->


<p><img class="center" src="http://tdongsi.github.io/images/hive/wordcount.png" title="Process Flow of WordCount Example" ></p>

<p>The fundamental data structure for input and output in MapReduce is the key-value pair. When starting the WordCount example, the Mapper processes the input documents line by line, with the key being the character offset into the document and the value being the line of text.</p>

<p>A <strong>map</strong> operation converts input key-values pairs from one form to another. In WordCount, the key (character offset) is discarded but it may not be always the case. The value (the line of text) is normalized (e.g., converted to lower case) and tokenized into words, using some technique such as splitting on whitespace. In this way, “HADOOP” and “Hadoop” will be counted as the same word. For each word in the line, the Mapper outputs a key-value pair, with the word as the key and the number 1 as the value.</p>

<p>Next is the <strong>shuffling</strong> phase. Hadoop sorts the key-value pairs by key and it “shuffles” all pairs with the same key to the same Reducer. In the WordCount example, each Reducer may get some range of keys, i.e. a group of words/tokens.</p>

<p>A <strong>reduce</strong> operation converts the collection for each key in input key-value pairs to another smaller collection (or a value when the collection has a single element). In WordCount, the input key is one of the words found and the value will be a collection of all the counts for that word. The Reducers add all the counts in the value collection and the final output are key-value pairs consisting of each word and the count for that word.</p>

<p>The three phases of processing in WordCount example with their input and output key-value pairs are summarized in the table below. Note that the input and output key-value pairs can be very different for each phase, not only in value but also in type.</p>

<table>
<thead>
<tr>
<th> </th>
<th> Mapper </th>
<th> Shuffling </th>
<th> Reducer </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>Input</strong> </td>
<td> <code>(offset, text_line)</code> </td>
<td> Multiple <code>(token,1)</code> </td>
<td> <code>(token,[1,1,1,...])</code> </td>
</tr>
<tr>
<td> <strong>Processing</strong> </td>
<td> Discard the key <code>offset</code>. <br> Normalize and tokenize <code>text_line</code>.</td>
<td> Move <code>(token,1)</code>with same <code>token</code> to same Reducer </td>
<td> Sum all elements in collection </td>
</tr>
<tr>
<td> <strong>Output</strong> </td>
<td> Multiple <code>(token,1)</code> </td>
<td> Sorted <code>(token,[1,1,1,...])</code> </td>
<td> <code>(token, count)</code> </td>
</tr>
</tbody>
</table>


<p><br></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[WordCount Example in Cloudera Quickstart VM]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/20/wordcount-sample-in-cloudera-quickstart-vm/"/>
    <updated>2015-11-20T11:47:51-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/20/wordcount-sample-in-cloudera-quickstart-vm</id>
    <content type="html"><![CDATA[<p><a href="https://wiki.apache.org/hadoop/WordCount">WordCount</a> is the Hadoop equivalent of “Hello World” example program. When you first start learning a new language or framework, you would want to run and look into some &ldquo;Hello World&rdquo; example to get a feel of the new development environment. Your first few programs in those new languages or frameworks are probably extended from those basic &ldquo;Hello World&rdquo; examples.</p>

<p>Most Hadoop tutorials are quite overwhelming in text, but provide little guide on practical hands-on experiments (such as <a href="https://developer.yahoo.com/hadoop/tutorial/">this</a>). Although they are good and thorough tutorials, many new Hadoop users may be lost midway after walls of texts.</p>

<p>The purpose of this post is to help new users dive into Hadoop more easily. After reading this, you should be able to:</p>

<ol>
<li>Get started with a simple, local Hadoop sandbox for hands-on experiments.</li>
<li>Perform some simple tasks in HDFS.</li>
<li>Run the most basic example program WordCount, using your own input data.</li>
</ol>


<h3>Get your Hadoop sandbox</h3>

<p>Nowadays, many companies provide Hadoop sandboxes for learning purpose, such as Cloudera, <a href="http://hortonworks.com/products/hortonworks-sandbox/">Hortonworks</a>. In this post, I used <a href="http://www.cloudera.com/content/www/en-us/documentation/enterprise/5-2-x/topics/cloudera_quickstart_vm.html">Cloudera Quickstart VM</a>. Download the VM and start it up in VirtualBox or VMWare Fusion.</p>

<h3>Working with HDFS</h3>

<p>Before running WordCount example, we need to create some input text file, then move it to HDFS. First, create an input test file in your local file system.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ echo “This is a hadoop tutorial test" &gt; wordcount.txt</span></code></pre></td></tr></table></div></figure>


<p>Next, we need to move this file into HDFS. The following commands are the most basic HDFS commands to manage files in HDFS. In order of appearance below, we create a folder, copy the input file from local filesystem to HDFS, and list the content on HDFS.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hdfs dfs -mkdir /user/cloudera/input
</span><span class='line'>[cloudera@quickstart temp]$ hdfs dfs -put /home/cloudera/temp/wordcount.txt /user/cloudera/input
</span><span class='line'>[cloudera@quickstart temp]$ hdfs dfs -ls /user/cloudera/input
</span><span class='line'>Found 1 items
</span><span class='line'>-rw-r--r--   1 cloudera cloudera         31 2015-01-15 18:04 /user/cloudera/input/wordcount.txt</span></code></pre></td></tr></table></div></figure>


<p>It should be noted that for a fresh Cloudera VM, there is a &ldquo;/user&rdquo; folder in HDFS but not in the local filesystem. This example illustrates that local file system and HDFS are separate, and the Linux&rsquo;s &ldquo;ls&rdquo; and HDFS&rsquo;s &ldquo;ls&rdquo; interact with those independently.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ ls /user
</span><span class='line'>
</span><span class='line'>ls: cannot access /user: No such file or directory
</span><span class='line'>[cloudera@quickstart temp]$ hdfs dfs -ls /user
</span><span class='line'>Found 5 items
</span><span class='line'>drwxr-xr-x   - cloudera cloudera          0 2014-12-18 07:08 /user/cloudera
</span><span class='line'>drwxr-xr-x   - mapred   hadoop            0 2014-12-18 07:08 /user/history
</span><span class='line'>drwxrwxrwx   - hive     hive              0 2014-12-18 07:08 /user/hive
</span><span class='line'>drwxrwxrwx   - oozie    oozie             0 2014-12-18 07:09 /user/oozie
</span><span class='line'>drwxr-xr-x   - spark    spark             0 2014-12-18 07:09 /user/spark</span></code></pre></td></tr></table></div></figure>


<p>To see the content of a file on HDFS, use cat subcommand:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hdfs dfs -cat /user/cloudera/input/wordcount.txt
</span><span class='line'>this is a hadoop tutorial test</span></code></pre></td></tr></table></div></figure>


<p>For large files, if you want to view just the first or last parts, there is no -more or -tail subcommand. Instead, pipe the output of the -cat subcommand through your local shell’s more, or tail. For example: <code>hdfs dfs -cat wc-out/* | more</code>.</p>

<p>For more HDFS commands, check out links in References section below.</p>

<h3>Running the WordCount example</h3>

<p>Next, we want to run some MapReduce example, such as WordCount. The WordCount example is commonly used to illustrate how MapReduce works. The example returns a list of all the words that appear in a text file and the count of how many times each word appears. The output should show each word found and its count, line by line.</p>

<p>We need to locate the example programs on the sandbox VM. On Cloudera Quickstart VM, they are packaged in this jar file &ldquo;hadoop-mapreduce-examples.jar&rdquo;. Running that jar file without any argument will give you a list of available examples.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ ls -ltr /usr/lib/hadoop-mapreduce/
</span><span class='line'>lrwxrwxrwx 1 root root      44 Dec 18 07:01 hadoop-mapreduce-examples.jar -&gt; hadoop-mapreduce-examples-2.5.0-cdh5.3.0.jar
</span><span class='line'>
</span><span class='line'>[cloudera@quickstart temp]$ hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar
</span><span class='line'>Valid program names are:
</span><span class='line'>  aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files.
</span><span class='line'>  aggregatewordhist: An Aggregate based map/reduce program that computes the histogram of the words in the input files.
</span><span class='line'>  bbp: A map/reduce program that uses Bailey-Borwein-Plouffe to compute exact digits of Pi.
</span><span class='line'>  dbcount: An example job that count the pageview counts from a database.
</span><span class='line'>  distbbp: A map/reduce program that uses a BBP-type formula to compute exact bits of Pi.
</span><span class='line'>  grep: A map/reduce program that counts the matches of a regex in the input.
</span><span class='line'>  join: A job that effects a join over sorted, equally partitioned datasets
</span><span class='line'>  multifilewc: A job that counts words from several files.
</span><span class='line'>  pentomino: A map/reduce tile laying program to find solutions to pentomino problems.
</span><span class='line'>  pi: A map/reduce program that estimates Pi using a quasi-Monte Carlo method.
</span><span class='line'>  randomtextwriter: A map/reduce program that writes 10GB of random textual data per node.
</span><span class='line'>  randomwriter: A map/reduce program that writes 10GB of random data per node.
</span><span class='line'>  secondarysort: An example defining a secondary sort to the reduce.
</span><span class='line'>  sort: A map/reduce program that sorts the data written by the random writer.
</span><span class='line'>  sudoku: A sudoku solver.
</span><span class='line'>  teragen: Generate data for the terasort
</span><span class='line'>  terasort: Run the terasort
</span><span class='line'>  teravalidate: Checking results of terasort
</span><span class='line'>  wordcount: A map/reduce program that counts the words in the input files.
</span><span class='line'>  wordmean: A map/reduce program that counts the average length of the words in the input files.
</span><span class='line'>  wordmedian: A map/reduce program that counts the median length of the words in the input files.
</span><span class='line'>  wordstandarddeviation: A map/reduce program that counts the standard deviation of the length of the words in the input files.</span></code></pre></td></tr></table></div></figure>


<p>To run the WordCount example using the input file that we just moved to HDFS, use the following command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar wordcount 
</span><span class='line'>/user/cloudera/input/wordcount.txt /user/cloudera/output
</span><span class='line'>
</span><span class='line'>15/11/15 18:14:45 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
</span><span class='line'>15/11/15 18:14:46 INFO input.FileInputFormat: Total input paths to process : 1
</span><span class='line'>15/11/15 18:14:46 INFO mapreduce.JobSubmitter: number of splits:1
</span><span class='line'>15/11/15 18:14:46 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1421372394109_0001
</span><span class='line'>15/11/15 18:14:46 INFO impl.YarnClientImpl: Submitted application application_1421372394109_0001
</span><span class='line'>15/11/15 18:14:46 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1421372394109_0001/
</span><span class='line'>15/11/15 18:14:46 INFO mapreduce.Job: Running job: job_1421372394109_0001
</span><span class='line'>15/11/15 18:14:55 INFO mapreduce.Job: Job job_1421372394109_0001 running in uber mode : false
</span><span class='line'>15/11/15 18:14:55 INFO mapreduce.Job:  map 0% reduce 0%
</span><span class='line'>15/11/15 18:15:01 INFO mapreduce.Job:  map 100% reduce 0%
</span><span class='line'>15/11/15 18:15:07 INFO mapreduce.Job:  map 100% reduce 100%
</span><span class='line'>15/11/15 18:15:08 INFO mapreduce.Job: Job job_1421372394109_0001 completed successfully</span></code></pre></td></tr></table></div></figure>


<p>The output folder is specified as &ldquo;/user/cloudera/output&rdquo; in the above command. Finally, check the output of WordCount example in the output folder.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hdfs dfs -ls /user/cloudera/output
</span><span class='line'>
</span><span class='line'>Found 2 items
</span><span class='line'>-rw-r--r--   1 cloudera cloudera          0 2015-11-15 18:15 /user/cloudera/output/_SUCCESS
</span><span class='line'>-rw-r--r--   1 cloudera cloudera         43 2015-11-15 18:15 /user/cloudera/output/part-r-00000
</span><span class='line'>[cloudera@quickstart temp]$ hdfs dfs -cat /user/cloudera/output/part-r-00000
</span><span class='line'>a     1
</span><span class='line'>hadoop     1
</span><span class='line'>is     1
</span><span class='line'>test     1
</span><span class='line'>this     1
</span><span class='line'>tutorial     1</span></code></pre></td></tr></table></div></figure>


<p>Congratulations!! You just finished the first step of the journey into Hadoop.</p>

<h3>Additional links</h3>

<ol>
<li><a href="http://hortonworks.com/hadoop-tutorial/using-commandline-manage-files-hdfs/">http://hortonworks.com/hadoop-tutorial/using-commandline-manage-files-hdfs/</a></li>
<li><a href="http://wiki.apache.org/hadoop/WordCount">http://wiki.apache.org/hadoop/WordCount</a></li>
<li><a href="https://developer.yahoo.com/hadoop/tutorial/">https://developer.yahoo.com/hadoop/tutorial/</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[An Old Email]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/19/an-old-email/"/>
    <updated>2015-11-19T00:41:40-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/19/an-old-email</id>
    <content type="html"><![CDATA[<p>I found this email below (names redacted) in an old document folder. It is probably one of the most memorable emails I have ever written. It gave me many significant lessons and insight, especially when I&rsquo;m relatively early in my job/career:</p>

<ol>
<li>Code that is currently correct may not be robust to changes. Watch out for changes, which are frequent in any software project.</li>
<li>A small change in implementation approach can significantly improve testability of your code.</li>
<li>Developers and test engineers should NOT be siloed into different departments in any company. They should work closely together, as programmers having different roles (develop vs. test) in a project (hint: Agile). An analogy is forwards/defenders in a soccer match: they are all soccer players, with different roles.

<ul>
<li>Organizational boundaries only dampen open collaboration only if people let them (or abuse them). Send emails, or walk to the other building if needed, to work closely with your project team members.</li>
</ul>
</li>
</ol>


<hr />

<p>Hi LeadDeveloper,</p>

<p>I noticed the following problem with enum classes in Project_X. I know that it’s a long email, please bear with me.</p>

<p>For example, the enum class AttributeVisibility is defined as follows:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">public</span> <span class="kd">enum</span> <span class="n">AttributeVisibility</span> <span class="o">{</span>
</span><span class='line'>  <span class="n">PublicVisibility</span><span class="o">(</span><span class="mi">1</span><span class="o">),</span>
</span><span class='line'>  <span class="n">PrivateVisibility</span><span class="o">(</span><span class="mi">2</span><span class="o">),</span>
</span><span class='line'>  <span class="n">ProtectedVisibility</span><span class="o">(</span><span class="mi">4</span><span class="o">);</span> <span class="c1">// Values to match ASM Opcodes</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">private</span> <span class="kt">int</span> <span class="n">value</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">private</span> <span class="nf">AttributeVisibility</span><span class="o">(</span><span class="kt">int</span> <span class="n">v</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="n">value</span> <span class="o">=</span> <span class="n">v</span><span class="o">;</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">public</span> <span class="kt">int</span> <span class="nf">getValue</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">return</span> <span class="n">value</span><span class="o">;</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">public</span> <span class="kd">static</span> <span class="n">AttributeVisibility</span> <span class="nf">getAttributeVisibility</span><span class="o">(</span><span class="kt">int</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">switch</span> <span class="o">(</span><span class="n">value</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">case</span> <span class="mi">1</span><span class="o">:</span>
</span><span class='line'>          <span class="k">return</span> <span class="n">AttributeVisibility</span><span class="o">.</span><span class="na">PublicVisibility</span><span class="o">;</span>
</span><span class='line'>      <span class="k">case</span> <span class="mi">4</span><span class="o">:</span>
</span><span class='line'>          <span class="k">return</span> <span class="n">AttributeVisibility</span><span class="o">.</span><span class="na">ProtectedVisibility</span><span class="o">;</span>
</span><span class='line'>      <span class="k">case</span> <span class="mi">2</span><span class="o">:</span>
</span><span class='line'>          <span class="k">return</span> <span class="n">AttributeVisibility</span><span class="o">.</span><span class="na">PrivateVisibility</span><span class="o">;</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>      <span class="k">throw</span> <span class="k">new</span> <span class="nf">RuntimeException</span><span class="o">(</span><span class="s">&quot;Unable to determine AttributeVisibility&quot;</span><span class="o">);</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Similar to many other enum classes in Project_X, the public static method getAttributeVisibility() in this class uses switch statements to convert an integer to enum data type.</p>

<p>There is nothing wrong with those classes now, but using switch statements is NOT a good practice, as explained below.</p>

<p><em>(STOP: I would encourage blog readers to stop for a few minutes and think why. NOT in the original email)</em></p>

<p>In the event of (1) we want to add a new instance, for example, PackageVisibility with value 8 into it, and (2) the developer is unaware of/forgets to update the getAttributeVisibility() method. The case for the new instance PackageVisibility is not added into the switch statement, and the getAttributeVisibility() method is now broken when the input is 8 and PackageVisibility instance is expected to return. One should never rule out that those events (1), (2) ever happen (i.e., they WILL happen) as the project Project_X is evolving.</p>

<p>I believe the better way to do it is to use a map instead of a switch statement (after all, what can express a mapping better than a map?):</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">public</span> <span class="kd">enum</span> <span class="n">AttributePreferred</span> <span class="o">{</span>
</span><span class='line'>  <span class="n">PublicVisibility</span><span class="o">(</span><span class="mi">1</span><span class="o">),</span>
</span><span class='line'>  <span class="n">PrivateVisibility</span><span class="o">(</span><span class="mi">2</span><span class="o">),</span>
</span><span class='line'>  <span class="n">ProtectedVisibility</span><span class="o">(</span><span class="mi">4</span><span class="o">);</span> <span class="c1">// Values to match ASM Opcodes</span>
</span><span class='line'>  <span class="c1">// PackageVisibility(8);</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">private</span> <span class="kd">static</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">AttributePreferred</span><span class="o">&gt;</span> <span class="n">intToEnum</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashMap</span><span class="o">&lt;&gt;();</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">static</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">for</span> <span class="o">(</span><span class="n">AttributePreferred</span> <span class="n">member</span> <span class="o">:</span> <span class="n">AttributePreferred</span><span class="o">.</span><span class="na">values</span><span class="o">())</span> <span class="o">{</span>
</span><span class='line'>          <span class="n">intToEnum</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">member</span><span class="o">.</span><span class="na">getValue</span><span class="o">(),</span> <span class="n">member</span><span class="o">);</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">private</span> <span class="kt">int</span> <span class="n">value</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">private</span> <span class="nf">AttributePreferred</span><span class="o">(</span><span class="kt">int</span> <span class="n">v</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="n">value</span> <span class="o">=</span> <span class="n">v</span><span class="o">;</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">public</span> <span class="kt">int</span> <span class="nf">getValue</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">return</span> <span class="n">value</span><span class="o">;</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">public</span> <span class="kd">static</span> <span class="n">AttributePreferred</span> <span class="nf">getAttributeVisibility</span><span class="o">(</span><span class="kt">int</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="n">AttributePreferred</span> <span class="n">obj</span> <span class="o">=</span> <span class="n">intToEnum</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">value</span><span class="o">);</span>
</span><span class='line'>      <span class="k">if</span> <span class="o">(</span><span class="n">obj</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span>
</span><span class='line'>          <span class="k">throw</span> <span class="k">new</span> <span class="nf">RuntimeException</span><span class="o">(</span>
</span><span class='line'>                  <span class="s">&quot;Unable to determine AttributeVisibility&quot;</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>      <span class="k">return</span> <span class="n">obj</span><span class="o">;</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Please note the static initialization block and the updated getAttributeVisibility method. In some enum classes that do not have the private value field such as DiskFormat, the intention may be concisely expressed by the ordinal() method in the static initialization block:</p>

<figure class='code'><figcaption><span>DO NOT do this</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">static</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">for</span> <span class="o">(</span><span class="n">DiskFormat</span> <span class="n">member</span> <span class="o">:</span> <span class="n">DiskFormat</span><span class="o">.</span><span class="na">values</span><span class="o">())</span> <span class="o">{</span>
</span><span class='line'>      <span class="n">intToEnum</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">member</span><span class="o">.</span><span class="na">ordinal</span><span class="o">(),</span> <span class="n">member</span><span class="o">);</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>However, using ordinal() method is strongly advised <strong>against</strong> (as indicated in JDK documentation <a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Enum.html">http://docs.oracle.com/javase/7/docs/api/java/lang/Enum.html</a>). Instead, I would recommend that such enum class uses a private value field to specify a fixed integer value for each instance, similar to the class AttributeVisibility above.</p>

<p>As a test engineer, I do have my stake to demand this change. Writing a unit test for such public method like getAttributeVisibility() is pointless, since it would not be better or more efficient than visually verifying it (see &ldquo;silly&rdquo; test below).</p>

<figure class='code'><figcaption><span>Silly unit test</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="c1">// How silly is this test?</span>
</span><span class='line'><span class="nd">@Test</span>
</span><span class='line'><span class="kd">public</span> <span class="kt">void</span> <span class="nf">test</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>  <span class="n">assertEquals</span><span class="o">(</span><span class="n">AttributeVisibility</span><span class="o">.</span><span class="na">PublicVisibility</span><span class="o">,</span><span class="n">AttributeVisibility</span><span class="o">.</span><span class="na">getAttributeVisibility</span><span class="o">(</span><span class="mi">1</span><span class="o">));</span>
</span><span class='line'>  <span class="n">assertEquals</span><span class="o">(</span><span class="n">AttributeVisibility</span><span class="o">.</span><span class="na">ProtectedVisibility</span><span class="o">,</span><span class="n">AttributeVisibility</span><span class="o">.</span><span class="na">getAttributeVisibility</span><span class="o">(</span><span class="mi">4</span><span class="o">));</span>
</span><span class='line'>  <span class="n">assertEquals</span><span class="o">(</span><span class="n">AttributeVisibility</span><span class="o">.</span><span class="na">PrivateVisibility</span><span class="o">,</span><span class="n">AttributeVisibility</span><span class="o">.</span><span class="na">getAttributeVisibility</span><span class="o">(</span><span class="mi">2</span><span class="o">));</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Even worse, that test won&rsquo;t help in the case that events (1)-(2) happen. In fact, when a developer fails to update the switch statement (event 2), it is not more likely or feasible that a test engineer will be able to visually verify it. It means that those enum classes may be broken any time due to changes. The only way to add confidence in those enum classes is to use the preferred implementation as explained above.</p>

<p>In summary, testers will be helpless if a bug is introduced into one of the Project_X enum classes if the safer alternative is not used instead of switch statements.</p>

<p>Best regards,</p>

<p>Cuong</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Unicode in Perl]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/18/unicode-in-perl/"/>
    <updated>2015-11-18T15:40:20-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/18/unicode-in-perl</id>
    <content type="html"><![CDATA[<p>For automation in Perl, Unicode can be tricky, especially when you want your automated jobs/tests to work across platforms (Windows and *nix). If you have a choice, another scripting language like Python may be better off in dealing with Unicode texts. If you don&rsquo;t have a choice and must use Perl (specifically Perl 5) like I used to, some of these tips may help get you started.</p>

<p>The most common code snippet that I used in my Perl codes when dealing with Unicode texts is this Unicode preamble:</p>

<figure class='code'><figcaption><span>Unicode preamble</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='perl'><span class='line'><span class="c1">#!/usr/bin/env perl</span>
</span><span class='line'><span class="k">use</span> <span class="n">strict</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="c1">##############################################################</span>
</span><span class='line'><span class="c1">#### Unicode preamble</span>
</span><span class='line'><span class="k">use</span> <span class="n">utf8</span><span class="p">;</span>      <span class="c1"># so literals and identifiers in Perl scripts can be in UTF-8</span>
</span><span class='line'><span class="k">use</span> <span class="n">warnings</span><span class="p">;</span>  <span class="c1"># on by default</span>
</span><span class='line'><span class="k">use</span> <span class="n">warnings</span>  <span class="sx">qw(FATAL utf8)</span><span class="p">;</span>    <span class="c1"># fatalize encoding glitches</span>
</span><span class='line'><span class="k">use</span> <span class="nb">open</span>      <span class="sx">qw(:std :utf8)</span><span class="p">;</span>    <span class="c1"># undeclared streams in UTF-8</span>
</span><span class='line'><span class="k">use</span> <span class="n">charnames</span> <span class="sx">qw(:full :short)</span><span class="p">;</span>  <span class="c1"># unneeded in v5.16</span>
</span><span class='line'>
</span><span class='line'><span class="c1">##############################################################</span>
</span><span class='line'>
</span><span class='line'><span class="k">my</span> <span class="nv">$name</span> <span class="o">=</span> <span class="s">&#39;你好世界&#39;</span><span class="p">;</span>
</span><span class='line'><span class="k">my</span> <span class="nv">$checkPrint</span> <span class="o">=</span> <span class="s">&quot;Print Unicode variable: $name \n&quot;</span><span class="p">;</span>
</span><span class='line'><span class="k">print</span> <span class="nv">$checkPrint</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>The first two lines are standard and should be included in any Perl script. The rest are specifically for dealing with UTF-8 (the most commonly used encoding of Unicode). Another useful code snippet is for printing Unicode codepoints (Quiz: what is the difference between a codepoint and its encoding?):</p>

<figure class='code'><figcaption><span>Print Unicode codepoints</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='perl'><span class='line'><span class="k">my</span> <span class="nv">$unicode_helloworld</span> <span class="o">=</span> <span class="s">&quot;\x{4F60}\x{597D}\x{4E16}\x{754C}&quot;</span><span class="p">;</span>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;Unicode codepoints: $unicode_helloworld\n&quot;</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>More recipes for working with Unicode in Perl 5 can be found in References below.</p>

<p>One dilemma you might be facing when your Perl codes run in Windows is to choose which encoding for your script files: ANSI or UTF-8. In my own experience:</p>

<ul>
<li>If the script file encoding is ANSI, I usually have better luck in &ldquo;What you see is what you get&rdquo; department: for example, files created in filesystem have the filenames with same Unicode characters, such as Japanese/Chinese characters, in Perl scripts. The downside of ANSI encoding is when I try to do regex matching of those Japanese/Chinese characters, I get &ldquo;malformed regex&rdquo; error.</li>
<li>If the script file encoding is UTF-8, the files created in filesystem usually have different Japanese/Chinese characters from those in Perl scripts. However, Japanese/Chinese characters in other places such as log files are matching with ones in Perl scripts. There is no &ldquo;malformed regex&rdquo; error when doing regex matching. However, that correctly formed regex matching may be useless if you need to do matching for output from filesystem such as &ldquo;ls&rdquo; command&rsquo;s output.</li>
</ul>


<!---
Overall, I used ANSI encoding for my Perl scripts as my automation project at that time has to run on Windows/Linux/Mac and interacts regularly with filesystem.
-->


<p>References:</p>

<ol>
<li><a href="http://perldoc.perl.org/perluniintro.html">http://perldoc.perl.org/perluniintro.html</a></li>
<li><a href="https://en.wikibooks.org/wiki/Perl_Programming/Unicode_UTF-8">https://en.wikibooks.org/wiki/Perl_Programming/Unicode_UTF-8</a></li>
<li><a href="http://www.perl.com/pub/2012/04/perlunicook-standard-preamble.html">http://www.perl.com/pub/2012/04/perlunicook-standard-preamble.html</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pushing Local Jar File Into Your Local Maven (M2) Repository]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/17/pushing-local-jar-file-into-your-local-maven-m2-repository/"/>
    <updated>2015-11-17T16:46:49-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/17/pushing-local-jar-file-into-your-local-maven-m2-repository</id>
    <content type="html"><![CDATA[<h4>Problem:</h4>

<p>I want to use Vertica JDBC driver in my Eclipse Maven project. I have the jar file from the vendor (i.e., downloaded from HP-Vertica support website) but, obviously, that file is not in Maven central repository. My Maven build will not work without that dependency.</p>

<p>This post will also apply if you are behind a firewall and/or do not have external access for some reason.</p>

<h4>Solution:</h4>

<ul>
<li>Download the jar file (e.g., the Vertica JDBC jar file).</li>
<li>At the same directory as the jar file, run the following command to install the jar to the local Maven repository (running in a different directory seems not work).</li>
</ul>


<figure class='code'><figcaption><span>General Maven command</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>mvn install:install-file -DgroupId<span class="o">=</span>&lt;GROUP_ID&gt; -DartifactId<span class="o">=</span>&lt;ARTIFACT_ID&gt; -Dversion<span class="o">=</span>&lt;VERSION&gt; -Dpackaging<span class="o">=</span>jar -Dfile<span class="o">=</span>&lt;LOCAL_PATH_FOR_JAR&gt; -DgeneratePom<span class="o">=</span><span class="nb">true</span>
</span></code></pre></td></tr></table></div></figure>


<p>Example:</p>

<figure class='code'><figcaption><span>Example Maven command for Vertica JDBC</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>mvn install:install-file -DgroupId<span class="o">=</span>vertica -DartifactId<span class="o">=</span>vertica-jdbc -Dversion<span class="o">=</span>7.0.1 -Dpackaging<span class="o">=</span>jar -Dfile<span class="o">=</span>~/Downloads/vertica/vertica-jdbc-7.0.1.jar -DgeneratePom<span class="o">=</span><span class="nb">true</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Now when you run your maven goals, it will not look for this particular jar file in any external repository such as Maven Central Repository since Maven checks and perceives that it is already in your local repository (your ~/.m2 directory).</li>
</ul>


<p>If you want your Eclipse to start using this jar from your local repository:</p>

<ul>
<li>In Eclipse Luna on a Mac/Windows, go to Navigate > Show View > Other > Maven > Maven Repository.</li>
<li>Open Local Repositories > Local Repository.</li>
<li>Right click for the context menu > Rebuild Index.</li>
</ul>


<p>Now it should show up in “Add…” dialog in pom.xml edit.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Automated Performance Logging and Plotting for Cassandra]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/14/automated-performance-logging-and-plotting-for-cassandra/"/>
    <updated>2015-11-14T19:57:43-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/14/automated-performance-logging-and-plotting-for-cassandra</id>
    <content type="html"><![CDATA[<p>In this <a href="https://github.com/tdongsi/python/tree/master/PerformanceLog">mini-project</a>, I created a Python script (PerformanceLog.py) to record JMX values from a running Cassandra instance, using JMXTerm (<a href="http://wiki.cyclopsgroup.org/jmxterm/">http://wiki.cyclopsgroup.org/jmxterm/</a>), and do the following:</p>

<ul>
<li>Put the records into a Cassandra table.</li>
<li>Plot the results.</li>
</ul>


<p>The project is based on a Cassandra interview question found on Glassdoor.</p>

<p>Currently, the first version only works with Windows version of Cassandra (using DataStax Community installer). Developed and tested in Python 2.7.</p>

<h2>Input/Output</h2>

<p><strong>Input</strong></p>

<p>When running the script from command line, the following arguments must be provided:</p>

<ul>
<li>installDir INSTALLDIR:  Path to installation directory.</li>
<li>host HOST: URL string for Cassandra instance. Only localhost tested.</li>
<li>jmxTerm JMXTERM: Path to jmxterm jar file.</li>
<li>osString OSSTRING: String that represents the current OS. Windows: win. Mac: mac. Unix/Linux: linux.</li>
</ul>


<p>Example:</p>

<blockquote><p>python PerformanceLog.py -installDir C:\datastax -host localhost -jmxTerm lib\jmxterm.jar -osString win</p></blockquote>

<p><strong>Output</strong></p>

<ul>
<li>CSV file with each field for each JMX metric.</li>
</ul>


<p>Example:</p>

<blockquote><p>  SSTableCount,DataSize,c95thPercentile</p>

<p>  0,0,0.0</p>

<p>  7,31306299,9337.784849999995</p>

<p>  7,31306299,9262.307649999999</p>

<p>  &hellip;</p></blockquote>

<ul>
<li><p>Records in a Cassandra table</p></li>
<li><p>Performance plot as PNG file (automatically generated from CSV output file)</p></li>
</ul>


<p>Example:</p>

<p><img src="https://dl.dropbox.com/s/0vy2u8b7hb7djjv/jmxMetrics.png" title="Performance Plot" alt="alt text" /></p>

<h2>Python modules</h2>

<ol>
<li>PerformanceLog.py: Main module to run the automated tasks. Please use &ldquo;python PerformanceLog -h&rdquo; for the required arguments. Example call for Windows is in the doc string.</li>
<li>MyLogger.py: Logging support module</li>
<li>CassandraRecord.py: Support module to record metrics into a Cassandra table.</li>
<li>Plotter.py: Support module to plot metrics into plots and save into PNG file.</li>
</ol>


<h3>Automated tasks by the modules</h3>

<ol>
<li>Check if Cassandra is Running</li>
<li>Record certain JMX Metrics</li>
<li>Runs the external tool Cassandra Stress</li>
<li>Once the stress session has completed, stop recording JMX Metrics</li>
<li>Record the metrics back into a Cassandra Table</li>
<li>Graph the results (create these graphs at the end of the run).</li>
</ol>


<h2>External Python libraries required</h2>

<h4>For CassandraRecord.py</h4>

<p>This module requires Datastax&rsquo;s Python driver: <a href="http://datastax.github.io/python-driver/installation.html">http://datastax.github.io/python-driver/installation.html</a></p>

<h4>For Plotter.py</h4>

<p>This Python module used Matplotlib library. Please install the following Python libraries: matplotlib, numpy, dateutil, pytz, pyparsing, six (optionally: pillow, pycairo, tornado, wxpython, pyside, pyqt, ghostscript, miktex, ffmpeg, mencoder, avconv, or imagemagick).</p>

<p>Installation of these Python libraries are straight-forward on Linux and Win32. On Win64, please find their installers here: <a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/">http://www.lfd.uci.edu/~gohlke/pythonlibs/</a></p>

<h2>Other files</h2>

<p>The following output files are produced. For consistency check, they are left behind.
In the final version of the script, they may be cleaned up accordingly.</p>

<ul>
<li>tempout: Output from JmxTerm session</li>
<li>jmxMetrics.csv: The cvs file that records the interested JMX metrics.</li>
<li>CassandraTest.log: The log file for the script.</li>
</ul>

]]></content>
  </entry>
  
</feed>
