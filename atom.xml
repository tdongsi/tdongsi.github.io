<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Personal Programming Notes]]></title>
  <link href="http://tdongsi.github.io/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/"/>
  <updated>2016-02-14T00:48:29-08:00</updated>
  <id>http://tdongsi.github.io/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Vertica: Performance Optimization Notes]]></title>
    <link href="http://tdongsi.github.io/blog/2016/02/13/vertica-post-6/"/>
    <updated>2016-02-13T23:52:44-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/02/13/vertica-post-6</id>
    <content type="html"><![CDATA[<p>Most of these optimization notes in this post are learnt through interaction with <a href="http://www.nexius.com/software-and-business-intelligence/">Nexius</a> consultants.
Also see <a href="http://tdongsi.github.io/blog/2015/12/16/vertica-tip-best-practices/">Veritca Best Practices</a>.</p>

<h3><code>NOT IN</code> is better than <code>NOT EXISTS</code></h3>

<p>When we want to insert a row into a dimension table AND check for duplicates at the same time, we usually do this in DML scripts:</p>

<figure class='code'><figcaption><span>BAD</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">SELECT</span> <span class="s1">&#39;United States&#39;</span><span class="p">,</span> <span class="s1">&#39;English&#39;</span>
</span><span class='line'><span class="k">WHERE</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="p">(</span><span class="k">SELECT</span> <span class="s1">&#39;x&#39;</span> <span class="k">FROM</span> <span class="n">dim_country</span> <span class="k">WHERE</span> <span class="n">country_name</span> <span class="o">=</span> <span class="s1">&#39;United States&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>However, for all such inserts, we were recently informed that it is better <strong>in Vertica</strong> to do <code>NOT IN</code> instead of <code>NOT EXISTS</code>.
So, for example above:</p>

<figure class='code'><figcaption><span>GOOD</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">SELECT</span> <span class="s1">&#39;United States&#39;</span><span class="p">,</span> <span class="s1">&#39;English&#39;</span>
</span><span class='line'><span class="k">WHERE</span> <span class="s1">&#39;United States&#39;</span> <span class="k">NOT</span> <span class="k">IN</span> <span class="p">(</span><span class="k">select</span> <span class="n">country_name</span> <span class="k">from</span> <span class="n">dim_country</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Avoid using <code>LEFT JOIN</code> to check existence</h3>

<p>Let&rsquo;s say you have an ETL that regularly inserts new data into an existing dimension table.</p>

<figure class='code'><figcaption><span>BAD</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">dim_country</span>
</span><span class='line'><span class="p">(</span>
</span><span class='line'>    <span class="n">country_id</span><span class="p">,</span>
</span><span class='line'>    <span class="n">country_name</span><span class="p">,</span>
</span><span class='line'>    <span class="n">country_language</span><span class="p">,</span>
</span><span class='line'><span class="p">)</span>
</span><span class='line'><span class="k">SELECT</span> <span class="n">ssp</span><span class="p">.</span><span class="n">country_id</span><span class="p">,</span>
</span><span class='line'>    <span class="n">ssp</span><span class="p">.</span><span class="n">country_name</span><span class="p">,</span>
</span><span class='line'>    <span class="n">ssp</span><span class="p">.</span><span class="n">country_language</span><span class="p">,</span>
</span><span class='line'><span class="k">FROM</span> <span class="n">staging_table</span> <span class="n">ssp</span>
</span><span class='line'><span class="k">LEFT</span> <span class="k">JOIN</span> <span class="n">dim_country</span> <span class="n">dc</span> <span class="k">on</span> <span class="n">dc</span><span class="p">.</span><span class="n">country_id</span><span class="o">=</span><span class="n">ssp</span><span class="p">.</span><span class="n">country_id</span>
</span><span class='line'><span class="k">WHERE</span> <span class="n">dc</span><span class="p">.</span><span class="n">country_id</span> <span class="k">is</span> <span class="k">NULL</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>We are sometimes doing <code>LEFT JOIN</code> like this only to determine whether or not an entry already exists in the table.
It would be faster to instead use a <code>WHERE</code> clause to check if an entry exists.
Although it might sound counter-intuitive, but reducing <code>JOIN</code> operations like this has been regularly recommended.</p>

<figure class='code'><figcaption><span>GOOD</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">dim_country</span>
</span><span class='line'><span class="p">(</span>
</span><span class='line'>    <span class="n">country_id</span><span class="p">,</span>
</span><span class='line'>    <span class="n">country_name</span><span class="p">,</span>
</span><span class='line'>    <span class="n">country_language</span><span class="p">,</span>
</span><span class='line'><span class="p">)</span>
</span><span class='line'><span class="k">SELECT</span> <span class="n">ssp</span><span class="p">.</span><span class="n">country_id</span><span class="p">,</span>
</span><span class='line'>    <span class="n">ssp</span><span class="p">.</span><span class="n">country_name</span><span class="p">,</span>
</span><span class='line'>    <span class="n">ssp</span><span class="p">.</span><span class="n">country_language</span><span class="p">,</span>
</span><span class='line'><span class="k">FROM</span> <span class="n">staging_table</span> <span class="n">ssp</span>
</span><span class='line'><span class="k">WHERE</span> <span class="n">ssp</span><span class="p">.</span><span class="n">country_id</span> <span class="k">NOT</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="n">country_id</span> <span class="k">FROM</span> <span class="n">dim_country</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Avoid function calls in <code>WHERE</code> and <code>JOIN</code> clauses</h3>

<p>For this performance tip, we make a slight change the ETL example in the last section above where <code>country_id</code> column is removed. In this case, we can use a normalized <code>country_name</code> as the ID to check for existing entries in the table:</p>

<figure class='code'><figcaption><span>BAD</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">dim_country</span>
</span><span class='line'><span class="p">(</span>
</span><span class='line'>    <span class="n">country_name</span><span class="p">,</span>
</span><span class='line'>    <span class="n">country_language</span><span class="p">,</span>
</span><span class='line'><span class="p">)</span> <span class="k">SELECT</span> <span class="n">ssp</span><span class="p">.</span><span class="n">country_name</span><span class="p">,</span>
</span><span class='line'>    <span class="n">ssp</span><span class="p">.</span><span class="n">country_language</span><span class="p">,</span>
</span><span class='line'><span class="k">FROM</span> <span class="n">staging_table</span> <span class="n">ssp</span>
</span><span class='line'><span class="k">LEFT</span> <span class="k">JOIN</span> <span class="n">dim_country</span> <span class="n">dc</span> <span class="k">on</span> <span class="k">lower</span><span class="p">(</span><span class="n">dc</span><span class="p">.</span><span class="n">country_name</span><span class="p">)</span><span class="o">=</span><span class="k">lower</span><span class="p">(</span><span class="n">ssp</span><span class="p">.</span><span class="n">country_name</span><span class="p">)</span>
</span><span class='line'><span class="k">WHERE</span> <span class="n">dc</span><span class="p">.</span><span class="n">country_name</span> <span class="k">is</span> <span class="k">NULL</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>In this example, we normalize <code>country_name</code> to lower case. Note that <code>WHERE</code> clause should be used instead of <code>LEFT JOIN</code> as discussed above.</p>

<figure class='code'><figcaption><span>BETTER, but still BAD</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">dim_country</span>
</span><span class='line'><span class="p">(</span>
</span><span class='line'>    <span class="n">country_name</span><span class="p">,</span>
</span><span class='line'>    <span class="n">country_language</span><span class="p">,</span>
</span><span class='line'><span class="p">)</span> <span class="k">SELECT</span> <span class="n">ssp</span><span class="p">.</span><span class="n">country_name</span><span class="p">,</span>
</span><span class='line'>    <span class="n">ssp</span><span class="p">.</span><span class="n">country_language</span><span class="p">,</span>
</span><span class='line'><span class="k">FROM</span> <span class="n">staging_table</span> <span class="n">ssp</span>
</span><span class='line'><span class="k">WHERE</span> <span class="k">lower</span><span class="p">(</span><span class="n">ssp</span><span class="p">.</span><span class="n">country_name</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="k">lower</span><span class="p">(</span><span class="n">country_name</span><span class="p">)</span> <span class="k">FROM</span> <span class="n">dim_country</span><span class="p">);;</span>
</span></code></pre></td></tr></table></div></figure>


<p>However, such change still has bad performance because, in general, function calls in <code>WHERE</code> and <code>JOIN</code> clauses should be avoided in Vertica.
In both examples above, calling functions like <code>LOWER</code> in <code>WHERE</code> and <code>JOIN</code> clauses will affect the performance of the ETLs.</p>

<p>The solution for the above example is that since we control what goes into dimension tables, we can ensure that columns like <code>country_name</code> are always stored in lower-case.
Then, we can do the same when creating the temporary table such as <code>staging_table</code> that we are comparing to check for existence.</p>

<h3>Use  <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/Functions/VerticaFunctions/ANALYZE_STATISTICS.htm">ANALYZE_STATISTICS</a></h3>

<p>Make sure to run <code>ANALYZE_STATISTICS</code> after all data loads.
Using this function, tables are analyzed for best performance in subsequent queries ran against it.
Without information from <code>ANALYZE_STATISTICS</code>, the query optimizer assumes uniform distribution of data values and equal storage usage for all projections.</p>

<p>Note that <code>ANALYZE_STATISTICS</code> is only supported on <em>local</em> temporary tables, but not on <em>global</em> temporary tables.
In addition, when you add ANALYZE_STATISTICS function calls into your ETL scripts, errors might be thrown when a second <code>ANALYZE_STATISTICS</code> call is made while the first is still running.
Those errors can be ignored but they must be caught accordingly to separate with other Vertica error messages.</p>

<h3>Avoid creating temporary tables using <code>SELECT</code></h3>

<p>Instead of creating temporary tables using <code>SELECT</code>, it is recommended:</p>

<ol>
<li>Create the temporary table first without a projection.</li>
<li>Create a super projection with the correct column encodings and <code>ORDER BY</code> clause</li>
<li>Populate it using <code>INSERT /*+ direct */ INTO</code>. Note the <code>/*+ direct */</code> hint to write data directly to disk, bypassing memory.</li>
</ol>


<p>For example, in a Vertica ETL script that runs daily, we usually create a temporary table to retrieve the latest records from the source table like this:</p>

<figure class='code'><figcaption><span>BAD</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">TEMPORARY</span> <span class="k">TABLE</span> <span class="n">customer_last_temp</span>
</span><span class='line'><span class="k">ON</span> <span class="k">COMMIT</span> <span class="k">PRESERVE</span> <span class="k">ROWS</span>
</span><span class='line'><span class="k">AS</span><span class="p">(</span>
</span><span class='line'>  <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="p">(</span>
</span><span class='line'>    <span class="k">select</span> <span class="o">*</span><span class="p">,</span>
</span><span class='line'>    <span class="n">row_number</span><span class="p">()</span> <span class="n">OVER</span> <span class="p">(</span><span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">customer_id</span> <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">last_modify_date</span> <span class="k">DESC</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rank</span>
</span><span class='line'>    <span class="k">from</span>  <span class="n">stg_customer</span> <span class="n">rpt</span>
</span><span class='line'>  <span class="p">)</span> <span class="n">t1</span> <span class="k">where</span> <span class="n">t1</span><span class="p">.</span><span class="n">rank</span> <span class="o">=</span><span class="mi">1</span>
</span><span class='line'><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>In this example, <code>last_modify_date</code> is the <a href="https://en.wikipedia.org/wiki/Change_data_capture">CDC</a> column and <code>customer_id</code> is the primary key column.
Although this SQL statement is simple and easy to understand, it is really slow for a large and growing <code>stg_customer</code> table that contains updates to all customers on multiple dates, with millions of <em>new</em> customer entries each day.
Instead, the recommended coding pattern is to create a temporary table first without a projection:</p>

<figure class='code'><figcaption><span>Create a temporary table without projection</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">LOCAL</span> <span class="k">TEMPORARY</span> <span class="k">TABLE</span> <span class="n">customer_last_temp</span>  <span class="p">(</span>
</span><span class='line'>        <span class="n">customer_id</span>                    <span class="nb">int</span><span class="p">,</span>
</span><span class='line'>        <span class="n">subscribe_date</span>                 <span class="k">timestamp</span><span class="p">,</span>
</span><span class='line'>        <span class="n">cancel_date</span>                    <span class="k">timestamp</span><span class="p">,</span>
</span><span class='line'>        <span class="n">last_modify_date</span>               <span class="k">timestamp</span><span class="p">,</span>
</span><span class='line'><span class="p">)</span>
</span><span class='line'><span class="k">ON</span> <span class="k">COMMIT</span> <span class="k">PRESERVE</span> <span class="k">ROWS</span> <span class="k">NO</span> <span class="n">PROJECTION</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>It is also recommended that the column names are explicitly specified, so that only required columns are created in the temporary table.
A <code>LOCAL</code> temporary table is created, instead of <code>GLOBAL</code>, so that we can use <code>ANALYZE_STATISTICS</code> functions as discussed above.
Next, create a super projection with the correct column encodings and <code>ORDER BY</code> clause:</p>

<figure class='code'><figcaption><span>Create a super projection</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="n">PROJECTION</span> <span class="n">customer_last_temp_super</span> <span class="p">(</span>
</span><span class='line'>      <span class="n">customer_id</span> <span class="k">ENCODING</span> <span class="n">DELTARANGE_COMP</span>
</span><span class='line'>    <span class="p">,</span> <span class="n">subscribe_date</span> <span class="k">ENCODING</span> <span class="n">GCDDELTA</span>
</span><span class='line'>    <span class="p">,</span> <span class="n">cancel_date</span> <span class="k">ENCODING</span> <span class="n">BLOCKDICT_COMP</span>
</span><span class='line'>    <span class="p">,</span> <span class="n">last_modify_date</span> <span class="k">ENCODING</span> <span class="n">BLOCKDICT_COMP</span>
</span><span class='line'><span class="p">)</span>
</span><span class='line'><span class="k">AS</span>
</span><span class='line'><span class="k">SELECT</span> <span class="n">customer_id</span>
</span><span class='line'>     <span class="p">,</span> <span class="n">subscribe_date</span>
</span><span class='line'>     <span class="p">,</span> <span class="n">cancel_date</span>
</span><span class='line'>     <span class="p">,</span> <span class="n">last_modify_date</span>
</span><span class='line'>  <span class="k">FROM</span> <span class="n">customer_last_temp</span>
</span><span class='line'> <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">customer_id</span>
</span><span class='line'><span class="n">SEGMENTED</span> <span class="k">BY</span> <span class="n">HASH</span> <span class="p">(</span><span class="n">customer_id</span><span class="p">)</span> <span class="k">ALL</span> <span class="n">NODES</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Finally, insert &ldquo;directly&rdquo; into the temporary table:</p>

<figure class='code'><figcaption><span>Populate the table</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">INSERT</span> <span class="cm">/*+ direct */</span> <span class="k">INTO</span> <span class="n">customer_last_temp</span> <span class="p">(</span>
</span><span class='line'>      <span class="n">customer_id</span>
</span><span class='line'>    <span class="p">,</span> <span class="n">subscribe_date</span>
</span><span class='line'>    <span class="p">,</span> <span class="n">cancel_date</span>
</span><span class='line'>    <span class="p">,</span> <span class="n">last_modify_date</span>
</span><span class='line'><span class="p">)</span>
</span><span class='line'><span class="k">WITH</span> <span class="n">t1</span> <span class="k">AS</span> <span class="p">(</span>
</span><span class='line'>    <span class="k">SELECT</span> <span class="n">company_id</span>
</span><span class='line'>         <span class="p">,</span> <span class="n">subscribe_date</span>
</span><span class='line'>         <span class="p">,</span> <span class="n">cancel_date</span>
</span><span class='line'>         <span class="p">,</span> <span class="n">last_modify_date</span>
</span><span class='line'>         <span class="p">,</span> <span class="n">ROW_NUMBER</span><span class="p">()</span> <span class="n">OVER</span> <span class="p">(</span><span class="n">PARTITION</span> <span class="k">BY</span> <span class="n">customer_id</span>
</span><span class='line'>                                  <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">last_modify_date</span> <span class="k">DESC</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rank</span>
</span><span class='line'>      <span class="k">FROM</span> <span class="n">stg_customer</span> <span class="k">AS</span> <span class="n">rpt</span>
</span><span class='line'><span class="p">)</span>
</span><span class='line'><span class="k">SELECT</span> <span class="n">company_id</span>
</span><span class='line'>     <span class="p">,</span> <span class="n">subscribe_date</span>
</span><span class='line'>     <span class="p">,</span> <span class="n">cancel_date</span>
</span><span class='line'>     <span class="p">,</span> <span class="n">last_modify_date</span>
</span><span class='line'><span class="k">FROM</span> <span class="n">t1</span>
</span><span class='line'><span class="k">WHERE</span> <span class="n">t1</span><span class="p">.</span><span class="n">rank</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>The <code>WITH</code> clause is just a more readable way to write the sub-query in the original SQL statement.
In addition, the wildcard <code>*</code> in the original SQL query is also avoided, in case the table <code>stg_customer</code> is a very wide table.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mocking Current Date and Time in Python]]></title>
    <link href="http://tdongsi.github.io/blog/2016/01/27/python-post-1/"/>
    <updated>2016-01-27T17:36:53-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/01/27/python-post-1</id>
    <content type="html"><![CDATA[<h3>Calendar types</h3>

<p>There are surprisingly many types of calendar. Some of them are:</p>

<ol>
<li><strong>Regular Calendar</strong>: regular solar calendar date range as we know.

<ul>
<li>Example: January 01, 2006 to December 31, 2006.</li>
</ul>
</li>
<li><a href="https://en.wikipedia.org/wiki/Lunar_calendar"><strong>Lunar Calendar</strong></a>: based on cycles of the lunar phases.

<ul>
<li>Example: January 29, 2006 to February 17, 2007.</li>
<li>A lunar year is defined as 12 lunations, which is about 354 days.</li>
<li>In every two or three years, a <a href="https://en.wikipedia.org/wiki/Lunisolar_calendar">thirteenth-month</a> (intercalary month or leap month) is added to bring the calendar year into synchronisation with the solar year.</li>
</ul>
</li>
<li><strong>Fiscal Calendar</strong>: a companyâ€™s selected calendar date range for required SEC financial statement filing.

<ul>
<li>Example: August 01, 2005 to July 31, 2006 is my company&rsquo;s fiscal year 2006.</li>
</ul>
</li>
<li><strong>Tax Calendar</strong>: A number sequence representing weeks in a Tax year which begins right after the US Tax Day.

<ul>
<li>Example: April 16, 2005 to April 15, 2006.</li>
</ul>
</li>
<li><strong>Retail Calendar</strong>: also known as <a href="https://en.wikipedia.org/wiki/4%E2%80%934%E2%80%935_calendar">4-4-5 Calendar</a> or 544 calendar. 544 describes the number of weeks for a given quarter. Each quarter begins with a 5 week &ldquo;month&rdquo;, followed by 2 four week &ldquo;months&rdquo;.

<ul>
<li>Example: July 31, 2005 to July 29, 2006.</li>
<li>Why? This calendar ensures all 4 quarters in a calendar year are equal. This allows comparing weekly data (e.g., retail sales) to the prior year without correcting for times when regular calendar weeks break across months or quarters.</li>
<li>How? It usually uses the same end month as the fiscal calendar and each retail week consists of Sunday through Saturday.

<ul>
<li>The retail year end is defined as &ldquo;the last Saturday of the month at the fiscal year end&rdquo;.</li>
<li>If August 1st is Sunday, it is retail calendar&rsquo;s starting date. The Saturday July 31st is the last Saturday and end of the last retail year.</li>
<li>If August 1st is Monday, then Saturday July 30th is end of the last retail year, and July 31st is the start of the current retail year.</li>
</ul>
</li>
</ul>
</li>
<li><strong>ISO calendar</strong>: provided in Python <code>datetime</code> module.

<ul>
<li>Example: January 02, 2006 to December 31, 2006.</li>
<li>The first week of an ISO year is the first (Gregorian/regular) calendar week of a year containing a Thursday.</li>
<li>Each week starts at Monday and ends at Sunday.</li>
</ul>
</li>
</ol>


<p>Out of the above calendar types, retail calendar seems to have more complex rules. However, this calendar type is frequently used in industries like retail and manufacturing for ease of planning around it.</p>

<h3>Mocking current time in Python</h3>

<p>Due to retail calendar&rsquo;s desirable characteristics, we may have code that work with retail calendars in commercial applications eventually.
I ended up working with a utility Python module for retail calendar with functions which return values based on current time/date.
For example, a utility function to check if a given date is in the current 544 year works like this:</p>

<figure class='code'><figcaption><span>Original version</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">is_current_year_544</span><span class="p">(</span><span class="n">given_date</span><span class="p">):</span>
</span><span class='line'>    <span class="n">my_today</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="o">.</span><span class="n">today</span><span class="p">()</span>
</span><span class='line'>    <span class="k">if</span> <span class="n">year_start_544</span><span class="p">(</span><span class="n">my_today</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">given_date</span> <span class="o">&lt;=</span> <span class="n">year_end_544</span><span class="p">(</span><span class="n">my_today</span><span class="p">):</span>
</span><span class='line'>        <span class="k">return</span> <span class="s">&quot;Y&quot;</span>
</span><span class='line'>    <span class="k">else</span><span class="p">:</span>
</span><span class='line'>        <span class="k">return</span> <span class="s">&quot;N&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Some utility functions in that module are even more complicated than this example function.
For those, I think calling <code>today</code> or <code>now</code> inside those functions is a bad design.
They are essentially another <em>variable</em> in those functions (i.e., when do you run?), and it is better to expose that variable as an input parameter.
In addition, being able to specify what &ldquo;today&rdquo; or &ldquo;now&rdquo; value is will make automated unit testing easier.
For example, I want to know how my Python programs work if it runs on a particular date, such as end of retail year July 29, 2006.
A probably better, more testable function would be something like this.</p>

<figure class='code'><figcaption><span>More desirable</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">is_current_year_544</span><span class="p">(</span><span class="n">given_date</span><span class="p">,</span> <span class="n">run_date</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="o">.</span><span class="n">today</span><span class="p">()):</span>
</span><span class='line'>    <span class="k">if</span> <span class="n">year_start_544</span><span class="p">(</span><span class="n">run_date</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">given_date</span> <span class="o">&lt;=</span> <span class="n">year_end_544</span><span class="p">(</span><span class="n">run_date</span><span class="p">):</span>
</span><span class='line'>        <span class="k">return</span> <span class="s">&quot;Y&quot;</span>
</span><span class='line'>    <span class="k">else</span><span class="p">:</span>
</span><span class='line'>        <span class="k">return</span> <span class="s">&quot;N&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p>However, in reality, you sometimes have to live with the original utility Python module.
Then, the workaround for unit testing it is to &ldquo;mock&rdquo; current date and time, i.e., overriding those returned by <code>today</code> and <code>now</code> methods with some specific values.
In Python, it can be done by using some mocking framework, such as illustrated <a href="http://www.voidspace.org.uk/python/mock/examples.html#partial-mocking">here</a>.
Fortunately, my life was made even easier with <a href="https://github.com/spulec/freezegun"><code>freezegun</code> library</a>.
To install <code>freezegun</code> on Mac OSX, simply run</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pip install freezegun</span></code></pre></td></tr></table></div></figure>


<p>Using this <code>freezegun</code> library, I can easily specify my &ldquo;current date&rdquo; as &ldquo;July 29, 2006&rdquo; by adding the following decorator with some string &ldquo;2006-07-29&rdquo; for that date.</p>

<figure class='code'><figcaption><span>Unit test with mocking</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="nd">@freeze_time</span><span class="p">(</span><span class="s">&quot;2006-07-29&quot;</span><span class="p">)</span>
</span><span class='line'><span class="k">def</span> <span class="nf">test_year544_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;</span>
</span><span class='line'><span class="sd">    Mock today() at 2006-07-29</span>
</span><span class='line'><span class="sd">    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class="bp">self</span><span class="o">.</span><span class="n">_verify_544_methods</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>For full usage of <code>freezegun</code>, refer to its <a href="https://github.com/spulec/freezegun">quickstart guide</a>.
It should be noted that <code>freezegun</code> can mock <code>datetime</code> calls from other modules and it works great for testing with <code>datetime</code> calls.
However, you might encounter some occasional failures in your unit tests when working with <code>time</code> module.
From my personal experience, in those cases, note that time zones must be accounted for when mocking with <code>time</code> module by specifying <code>tz_offset</code> in the decorator <code>freeze_time</code>.</p>

<h3>External Links</h3>

<ul>
<li><a href="https://github.com/spulec/freezegun">freeze_gun</a></li>
<li><a href="https://en.wikipedia.org/wiki/4%E2%80%934%E2%80%935_calendar">Retail Calendar</a></li>
<li><a href="http://www.staff.science.uu.nl/~gent0113/calendar/isocalendar.htm">ISO Calendar</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS: Setting Up Multi-Factor Authentication (MFA)]]></title>
    <link href="http://tdongsi.github.io/blog/2016/01/22/aws-developing-and-deploying-apps/"/>
    <updated>2016-01-22T18:37:23-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/01/22/aws-developing-and-deploying-apps</id>
    <content type="html"><![CDATA[<p>This process is simple and most people should use MFA when developing a serious AWS application. Follow the following steps to enable MFA for AWS:</p>

<ul>
<li>Launch the AWS Console with your AWS Account. From the AWS Console, select &ldquo;Identity &amp; Access Management&rdquo;.</li>
</ul>


<p><img class="center" src="http://tdongsi.github.io/images/aws/mfa/step1_iam.png" width="350" height="200" title="Screenshot" ></p>

<ul>
<li>Select &ldquo;Users&rdquo; tab on the left side.</li>
</ul>


<p><img class="center" src="http://tdongsi.github.io/images/aws/mfa/step2_users.png" width="447" height="460" title="Screenshot" ></p>

<ul>
<li>Click on your username from the list of users.</li>
</ul>


<p><img class="center" src="http://tdongsi.github.io/images/aws/mfa/step3_you.png" width="555" height="256" title="Screenshot" ></p>

<ul>
<li>Make sure that &ldquo;Security Credentials&rdquo; tab is selected. Scrolling down to the bottom, under &ldquo;Sign-in Credentials&rdquo; section, select &ldquo;Manage MFA Device&rdquo;.</li>
</ul>


<p><img class="center" src="http://tdongsi.github.io/images/aws/mfa/step4_signin.png" width="603" height="314" title="Screenshot" ></p>

<ul>
<li>In the pop-up window, you are allowed to choose a virtual MFA device or a physical MFA device. The most convenient option is a virtual MFA device which only requires you to have a smartphone with some AWS MFA-compatible application. The list of AWS MFA applications are listed in <a href="http://aws.amazon.com/iam/details/mfa/">here</a>.</li>
</ul>


<p><img class="center" src="http://tdongsi.github.io/images/aws/mfa/step5_device.png" title="Screenshot" ></p>

<ul>
<li>In my case, I use <a href="https://play.google.com/store/apps/details?id=com.google.android.apps.authenticator2&amp;hl=en">Google Authenticator</a>. After installing the app, simply add an account and select &ldquo;Scan a barcode&rdquo;.</li>
</ul>


<p><img class="center" src="http://tdongsi.github.io/images/aws/mfa/step6_app.png" width="300" height="258" title="Screenshot" ></p>

<ul>
<li>Follow the prompts on AWS MFA webpages to arrive at the following page with QR code. You will then enter the first 6 digit PIN from Google Authenticator into Code 1 box. Wait for it to change and then add the second code into Code 2 box.</li>
</ul>


<p><img class="center" src="http://tdongsi.github.io/images/aws/mfa/step7_setup.png" width="495" height="444" title="Screenshot" ></p>

<ul>
<li>You are now all set for MFA. All future accesss will require you to enter the MFA code from the Google Authenticator on your Android/iPhone during login.</li>
</ul>


<p><img class="center" src="http://tdongsi.github.io/images/aws/mfa/step8_mfa.png" width="300" height="185" title="Screenshot" ></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS: Developing With Amazon S3]]></title>
    <link href="http://tdongsi.github.io/blog/2016/01/18/aws-developing-with-amazon-s3/"/>
    <updated>2016-01-18T17:13:28-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/01/18/aws-developing-with-amazon-s3</id>
    <content type="html"><![CDATA[<p>Amazon Simple Storage Service or S3 is a simple, scalable web services to store and retrieve data.
This post talks about basic concepts of buckets and objects in S3, basic and advanced operations on objects in S3, and standard development considerations when working with S3 using SDK.</p>

<h3>S3 Buckets and Objects</h3>

<p>Files of any kind such as text, video, photo are stored as objects in S3 <em>buckets</em>.
The bucket name must be globally unique across Amazon S3. It is your responsibility to ensure uniqueness of the bucket name.
A bucket can be <em>versioning-enabled</em>, it will store every version of every object in the bucket.</p>

<p>Each <em>object</em> in S3 is identified by a unique key. The object key is used for upload and retrieval. Alphanumeric characters and <code>!-_.*'/</code> are allowed in a key name.</p>

<p>Bucket naming tips:</p>

<ul>
<li>To ensure uniqueness, you might prefix the bucket name with the name of your organization.</li>
<li>Avoid using a period in the bucket name. Buckets that have a period in the bucket name can cause certificate exception when accessing with HTTPS-based URLs.</li>
</ul>


<p>Object key naming tips:</p>

<ul>
<li>Use prefixes and <code>/</code> (or other delimiters) to logically group your objects. For example, <code>prog/java/arrays.html</code>. There is no hierarchy of objects (e.g., folder) or nested buckets in S3.

<ul>
<li>However, the Amazon S3 console supports the <a href="http://docs.aws.amazon.com/AmazonS3/latest/UG/FolderOperations.html">folder concept</a> for convenience and usability. Amazon S3 does this by using key name prefixes for objects.</li>
</ul>
</li>
<li>For performance and scalability, consider using hash as the outermost prefix, in addition to other logical grouping prefixes. See &ldquo;Programming Considerations&rdquo; section below.</li>
</ul>


<h3>Operations on Objects</h3>

<p>Basic operations on S3 objects and buckets are:</p>

<ul>
<li>Put: upload or copy object, up to 5 GB. You can use multi-part upload API for larger objects up to 5 TB.</li>
<li>Get: Retrieve a whole object or part of an object.</li>
<li><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/ListingKeysHierarchy.html">List Keys</a>: List object keys by prefix and delimiter.</li>
<li>Delete: Delete one or more objects.

<ul>
<li>If versioning is not enabled, an object is permanently deleted by specifying its key.</li>
<li>If versioning is enabled, you delete an object by specifying a key and version ID. You must delete all versions of an object to remove it.</li>
<li>If versioning is enabled and version is not specified, S3 adds a delete marker to current version of the object. Trying to retrieve an object with a delete marker will returns a &ldquo;404 Not Found&rdquo; error by S3.</li>
</ul>
</li>
<li>Restore: Restore an object archived on Amazon Glacier.</li>
</ul>


<h4>Other operations in S3</h4>

<p>Advanced operations that you should know when situations arise.</p>

<p><strong>Scenario 1</strong>: You want to let users upload files to your buckets for some time duration.
<strong>Solution 1</strong>: You should never share your AWS credentials to let users upload files to your buckets.
Instead, generate a <strong>pre-signed URL</strong> with your security credentials, bucket name, object key, HTTP method (PUT or GET), and expiration date and time.
You share this pre-signed URL to users who will use this to access your S3 buckets.</p>

<p><strong>Scenario 2</strong>: Encryption and strict data security is required.
<strong>Solution 2</strong>: You can enable:</p>

<ul>
<li>Securing data in transit.

<ul>
<li>SSL-encrypted data transfer by using HTTPS</li>
<li><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingClientSideEncryption.html">Client-side encryption</a></li>
</ul>
</li>
<li>Securing data at rest on AWS server.

<ul>
<li><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html">Server-side encryption</a></li>
</ul>
</li>
</ul>


<p><strong>Scenario 3</strong>: You want your web applications that are loaded in one domain to interact with S3 resources in a different domain.
<strong>Solution 3</strong>: Check out <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html">CORS</a>.</p>

<h3>Programming considerations</h3>

<ul>
<li>According to <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/request-rate-perf-considerations.html">this guideline</a>, <strong>avoid</strong> using some sequential prefix (e.g., timestamp or alphabetical sequence) for your objects' key names. Instead, prefix the key name with its hash and, optionally, store the original key name in the object&rsquo;s metadata. See examples in the link for more information.</li>
<li>If your application uses fixed buckets, avoid unnecessary requests by checking the existence of buckets. Instead, handle <a href="http://docs.aws.amazon.com/AmazonS3/latest/API/ErrorResponses.html">NoSuchBucket errors</a> when buckets do not exist.</li>
<li>Set the object metadata before uploading an object. Otherwise, you will have extra requests to do copy operation to update metadata.</li>
<li>Cache bucket and key names if possible.</li>
<li>Set bucket region closest to latency-sensitive users.</li>
<li>Compress objects to reduce the size of data transferred and storage used.</li>
<li>Use an exponential back-off algorithm to retry after failed connection attempts. See <a href="http://docs.aws.amazon.com/general/latest/gr/api-retries.html">here</a>.</li>
<li>Enable application logging. For example, <a href="http://docs.aws.amazon.com/AWSSdkDocsJava/latest/DeveloperGuide/java-dg-logging.html">in Java</a>.</li>
<li>Enable <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html">server access logging</a>.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS: Getting Started on Mac OSX]]></title>
    <link href="http://tdongsi.github.io/blog/2016/01/17/aws-set-up-aws-credentials-on-mac-osx/"/>
    <updated>2016-01-17T20:57:35-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/01/17/aws-set-up-aws-credentials-on-mac-osx</id>
    <content type="html"><![CDATA[<p>First, you need to set up your AWS credentials on your Mac by creating the following files at the following specific locations:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MTVL1288aeea2-82:~ cdongsi$ mkdir ~/.aws
</span><span class='line'>MTVL1288aeea2-82:~ cdongsi$ touch ~/.aws/credentials
</span><span class='line'>MTVL1288aeea2-82:~ cdongsi$ touch ~/.aws/config</span></code></pre></td></tr></table></div></figure>


<p>In Windows, the locations of those files will be <code>C:\Users\USERNAME\.aws\credentials</code> and <code>C:\Users\USERNAME\.aws\config</code>, respectively.
You <em>must</em> fill in your AWS access credentials (Access Key ID and Secret Access Key) into the file <code>credentials</code>. Optionally, you can set the default region in the <code>config</code> file.
The content of the files will look like the following:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MTVL1288aeea2-82:~ cdongsi$ cat ~/.aws/credentials
</span><span class='line'>[default]
</span><span class='line'>aws_access_key_id = your_access_key_id
</span><span class='line'>aws_secret_access_key = your_secret_access_key
</span><span class='line'>
</span><span class='line'>MTVL1288aeea2-82:~ cdongsi$ cat ~/.aws/config
</span><span class='line'>[default]
</span><span class='line'>region=us-west-2</span></code></pre></td></tr></table></div></figure>


<h3>HelloAws using Java</h3>

<p>Now, you can install AWS Toolkit for Eclipse from <a href="http://aws.amazon.com/eclipse/">this link</a>. Follow the instruction in that page to install AWS Toolkit.</p>

<p>After AWS Toolkit is installed, you are ready to run the first <code>HelloAws</code> Java application. In Eclipse, create a AWS Console application.</p>

<ol>
<li>Click the new orange button on Eclipse taskbar named &ldquo;AWS Toolkit for Eclipse&rdquo;.</li>
<li>Click the link named &ldquo;Create a New AWS Java Project&rdquo;.</li>
<li>Fill in &ldquo;Project name&rdquo; as &ldquo;HelloAws&rdquo;. Check &ldquo;AWS Console Application&rdquo; from &ldquo;AWS SDK for Java Samples&rdquo; panel.</li>
</ol>


<p>Note that the sample generated has the following instruction in its main class. If you haven&rsquo;t do it, follow the steps above to set up your AWS access credentials.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">AwsConsoleApp</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="cm">/*</span>
</span><span class='line'><span class="cm">     * Before running the code:</span>
</span><span class='line'><span class="cm">     *      Fill in your AWS access credentials in the provided credentials</span>
</span><span class='line'><span class="cm">     *      file template, and be sure to move the file to the default location</span>
</span><span class='line'><span class="cm">     *      (/Users/cdongsi/.aws/credentials) where the sample code will load the</span>
</span><span class='line'><span class="cm">     *      credentials from.</span>
</span><span class='line'><span class="cm">     *      https://console.aws.amazon.com/iam/home?#security_credential</span>
</span><span class='line'><span class="cm">     *</span>
</span><span class='line'><span class="cm">     * WARNING:</span>
</span><span class='line'><span class="cm">     *      To avoid accidental leakage of your credentials, DO NOT keep</span>
</span><span class='line'><span class="cm">     *      the credentials file in your source directory.</span>
</span><span class='line'><span class="cm">     */</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">static</span> <span class="n">AmazonEC2</span>      <span class="n">ec2</span><span class="o">;</span>
</span><span class='line'>    <span class="kd">static</span> <span class="n">AmazonS3</span>       <span class="n">s3</span><span class="o">;</span>
</span><span class='line'>    <span class="kd">static</span> <span class="n">AmazonSimpleDB</span> <span class="n">sdb</span><span class="o">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>If your AWS credentials are ready, simply run the sample AWS console code as &ldquo;Java Application&rdquo;. The output will look something like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>===========================================
</span><span class='line'>Welcome to the AWS Java SDK!
</span><span class='line'>===========================================
</span><span class='line'>You have access to 4 Availability Zones.
</span><span class='line'>You have 0 Amazon EC2 instance(s) running.
</span><span class='line'>You have 0 Amazon SimpleDB domain(s)containing a total of 0 items.
</span><span class='line'>You have 0 Amazon S3 bucket(s), containing 0 objects with a total size of 0 bytes.</span></code></pre></td></tr></table></div></figure>


<h3>HelloAws using Python</h3>

<p>To install <a href="http://aws.amazon.com/sdk-for-python/">AWS SDK for Python</a>, run the following the command as instructed in that page:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pip install boto3
</span></code></pre></td></tr></table></div></figure>


<p>In my case, I used a slightly different command to avoid permission errors on Mac OSX:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pip install boto3 --user</span></code></pre></td></tr></table></div></figure>


<p>I use PyCharm/IntelliJ as IDE for Python and, apparently, there is no Python sample for it. In PyCharm, you can use the following Python script as your <code>HelloAws</code> program:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">boto3</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">botocore.exceptions</span> <span class="kn">import</span> <span class="n">ClientError</span><span class="p">,</span><span class="n">NoCredentialsError</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">sys</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">getS3BucketNumber</span><span class="p">():</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">try</span><span class="p">:</span>
</span><span class='line'>        <span class="n">s3</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">resource</span><span class="p">(</span><span class="s">&#39;s3&#39;</span><span class="p">)</span>
</span><span class='line'>        <span class="n">buckets</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="k">except</span> <span class="n">NoCredentialsError</span><span class="p">:</span>
</span><span class='line'>        <span class="k">print</span> <span class="s">&quot;No AWS Credentials&quot;</span>
</span><span class='line'>        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">try</span><span class="p">:</span>
</span><span class='line'>        <span class="n">bucket_num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">s3</span><span class="o">.</span><span class="n">buckets</span><span class="o">.</span><span class="n">all</span><span class="p">()))</span>
</span><span class='line'>        <span class="k">print</span> <span class="s">&quot;Number of buckets: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bucket_num</span><span class="p">)</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">bucket_num</span>
</span><span class='line'>    <span class="k">except</span> <span class="n">ClientError</span> <span class="k">as</span> <span class="n">ex</span><span class="p">:</span>
</span><span class='line'>        <span class="k">print</span><span class="p">(</span><span class="n">ex</span><span class="p">)</span>
</span><span class='line'>        <span class="k">return</span> <span class="mi">0</span>
</span><span class='line'>
</span><span class='line'><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&#39;__main__&#39;</span><span class="p">:</span>
</span><span class='line'>    <span class="n">getS3BucketNumber</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that it is based on the <a href="https://github.com/boto/boto3#quick-start">Quick start on Github</a>. In PyCharm, running the above Python should print the following output:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Number of buckets: 0</span></code></pre></td></tr></table></div></figure>


<h3>Quick note on Python API vs. Java API</h3>

<p>Note that Boto3 SDK for Python support <a href="http://boto3.readthedocs.org/en/latest/guide/resources.html">&ldquo;Resource API&rdquo;</a>.
As opposed to &ldquo;Service Client API&rdquo; like AWS SDK for Java, Resource API provides a higher level interface to the service and it is easier to understand and simpler to use.</p>

<p>For example, the generated example for AWS&rsquo;s Java SDK uses a Service Client API. It uses a class AmazonS3Client that controls the requests you make to the S3 service.
Meanwhile, the Boto3 SDK for Python has classes representing the conceptual resources (e.g., s3.Bucket) that you interact with when using the S3 service.
This is a higher level abstraction compared to a client class like AmazonS3Client making low-level calls to the service API.</p>

<h3>External Links</h3>

<ul>
<li>Python

<ul>
<li><a href="https://boto3.readthedocs.org/en/latest/guide/index.html">Developer Guide</a></li>
<li><a href="https://boto3.readthedocs.org/en/latest/reference/core/index.html">API Documentation</a></li>
</ul>
</li>
<li>Java

<ul>
<li><a href="http://docs.aws.amazon.com/AWSSdkDocsJava/latest/DeveloperGuide/welcome.html">Developer Guide</a></li>
<li><a href="http://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/index.html">API Documentation</a></li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS: Overview of Services]]></title>
    <link href="http://tdongsi.github.io/blog/2016/01/14/aws-building-the-foundation/"/>
    <updated>2016-01-14T18:36:45-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/01/14/aws-building-the-foundation</id>
    <content type="html"><![CDATA[<p>Amazon Web Services (AWS) is a collection of web services that deliver computing resources (hardware and software) to end-users over the Internet.
Not all AWS are equal but for AWS beginners, we usually don&rsquo;t know which are more important and which are secondary, supporting services.
Personally, I am initially overwhelmed by the number of services offered as well as large amount of documentation associated with each service.</p>

<p>This post documents my understanding on some key AWS services and concepts. In this post, AWS concepts and services can be divided into layers. Those layers, from bottom up, are:</p>

<ul>
<li>AWS Infrastructure: Physical data centers and physical network connections.</li>
<li>Infrastructure Services (IaaS).</li>
<li>Platform Services (PaaS).</li>
</ul>


<h3>AWS Global Infrastructure</h3>

<p>AWS are available in many locations world-wide. These locations are divided into <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html">regions and Availability Zones</a>.
As of January 2016, there are 11 regions, each <strong>region</strong> contains two or more Availability Zones.
Your resources, such as EC2 instances, reside in the region of your choice.
AWS regions are isolated from each other and you usually cannot access resources in another region.
Furthermore, some newer services may be available in some regions while not in others.</p>

<p>Each <strong>Availability Zone</strong> (AZ) is basically a separate physical data center, and provides low latency connectivity to all other AZs in the same region.
Although you cannot access resources in another region, but you can seamlessly manage resources in different AZs within the same region.
It is recommended that you provision your resources across multiple AZs to achieve redundancy. When a single AZ has a problem, your resources will be still available in other AZs.
For example, S3 stores your data in multiple AZs within your region of choice.</p>

<p><strong>Edge locations</strong> serve requests for CloudFront and Route 53 services. CloudFront is a content delivery network
(CDN), while Route 53 is a DNS service.
Requests going to either one of these services will be automatically routed to the nearest edge location (out of 53 available edge locations, as of Jan 2016). This allows for low latency no matter where the end user is located.</p>

<h3>Infrastructure Services</h3>

<p>AWS offerings are divided into two large groups: Infrastructure and Platform, which are further divided into different categories.
In addition to plain explanation to each service, I added its typical non-cloud, closest equivalent applications or technologies in &ldquo;Use it like&rdquo; column next to &ldquo;AWS name&rdquo; column.
Note that they are just analogies, purely for illustration purposes.
The official service names are in bold (e.g., EC2 and S3), while their respective full names (e.g., Elastic Compute Cloud and Simple Storage Service, respectively) are in brackets.</p>

<p>The grouping of Amazon Web Services as below is purely for review purpose (and remembering their numerous acronyms and names) since these services rarely work alone or are limited to a small group of services.
For example, EC2 instances are usually deployed in some Auto Scaling Groups, all of these groups are in some VPC, accepting traffic from some ELBs.
In a more sophisticated example, you can have some web application running on EC2 instances which store application data in Amazon DynamoDB which, in turn, store its index in some Amazon S3 buckets.
This Amazon DynamoDB have some database &ldquo;triggers&rdquo; implemented with AWS Lambda. These services can be monitored for performance using CloudWatch and access-controlled by IAM.
These examples show that how these AWS offerings can be inter-dependent and inter-connected in practice.</p>

<h4>Compute</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>Amazon EC2</strong> <br/>(Elastic Compute Cloud) </td>
<td> Application server </td>
<td> Remote, virtual server instances. <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html">What is EC2</a> <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html">Instance types</a> <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Tags.html">Tags</a> <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html">Key Pairs</a> <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-vpc.html">EC2 and VPC</a> <br/><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instances-and-amis.html">AMI</a></td>
</tr>
<tr>
<td> <strong>Amazon ELB</strong> <br/>(Elastic Load Balancing) </td>
<td>  </td>
<td> Incoming traffic load balancing. <br/><a href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/how-elb-works.html">ELB</a> <br/><a href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/how-elb-works.html">ELB Terms and Concepts</a></td>
</tr>
<tr>
<td> <strong>AWS Lambda</strong> </td>
<td>  </td>
<td> Like a cluster of one node.</td>
</tr>
<tr>
<td> <strong>Amazon EC2 <br/>Container Service</strong> </td>
<td> </td>
<td> Deployment Service </td>
</tr>
<tr>
<td> <strong>Auto Scaling</strong> </td>
<td> </td>
<td> Scaling <br/><a href="http://docs.aws.amazon.com/AutoScaling/latest/DeveloperGuide/how-as-works.html">Auto Scaling Group</a></td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Networking</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <a href="http://aws.amazon.com/vpc/"><strong>VPC</strong></a> <br>(Virtual Private Cloud) </td>
<td> VLAN </td>
<td> Virtual networking environment. <br/>Interaction with EC2 instances as if you are in the same existing network. </td>
</tr>
<tr>
<td> <strong>Amazon Route 53</strong> </td>
<td> DNS server </td>
<td> DNS service. </td>
</tr>
<tr>
<td> <strong>AWS Direct Connect</strong> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td> <strong>Amazon CloudFront</strong> </td>
<td> CDN </td>
<td> Content delivery service. <br/>Working like a cache for frequently accessed web pages or images to reduce latency. </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Storage</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <a href="http://aws.amazon.com/s3/"><strong>Amazon S3</strong></a> <br/>(Simple Storage Service) </td>
<td> FTP server. </td>
<td> Object store. Not a file system like EBS. <br/> More on <a href="http://stackoverflow.com/questions/2288402/should-i-persist-images-on-ebs-or-s3">S3 vs. EBS</a>.</td>
</tr>
<tr>
<td> <strong>Amazon EBS</strong> <br/>(Elastic Block Storage) </td>
<td> Hard drive to EC2. </td>
<td> Block storage. You can choose file system to format. <br/>You need a EC2 instance attach to it. </td>
</tr>
<tr>
<td> <a href="http://aws.amazon.com/glacier/"><strong>Glacier</strong></a> </td>
<td> <a href="https://en.wikipedia.org/wiki/Memory_hierarchy">Tape backup</a>. </td>
<td> Cold storage for archives, i.e., infrequently accessed files. <br/>It takes much longer to access Glacier files than S3.</td>
</tr>
<tr>
<td> <strong>Elastic File System</strong> </td>
<td> File system. </td>
<td> Currently in Preview. <br/>EBS cannot be connected to multiple EC2 instances. <br/>One Elastic File System instance can be connected to multiple EC2 instances. <br/> More on <a href="http://stackoverflow.com/questions/29575877/aws-efs-vs-ebs-vs-s3-differences-when-to-use">EFS vs. EBS vs. S3</a>.</td>
</tr>
</tbody>
</table>


<p><br/></p>

<!-- 
EBS means you need to manage a volume + machines to attach it to. You need to add space as it's filling up and perform backups (not saying you shouldn't back up your S3 data, just that it's not as critical).

It also makes it harder to scale: when you want to add additional machines, you either need to pull off the images to a separate machine or clone the images across all. This also means you're adding a bottleneck: you'll have to manage your own upload process that will either upload to all machines or have a single machine managing it.

S3 is mostly recommended for static files: like a FTP service. You might want to use EBS if you have a private application that requires private read/write access to some storage.
-->


<h4>Administration &amp; Security</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <a href="http://aws.amazon.com/iam/"><strong>AWS IAM</strong></a></td>
<td> </td>
<td> Manage users, keys, and certificates. <br/>You can set up additional users and new AWS keys, modify policies. <br/>Follow <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html">Best Practices</a></td>
</tr>
<tr>
<td> <strong>CloudWatch</strong> </td>
<td> </td>
<td> Monitoring metrics and performance. </td>
</tr>
<tr>
<td> <strong>CloudTrail</strong> </td>
<td> </td>
<td> Logging calls to services. </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Applications</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>WorkSpaces</strong> </td>
<td> VirtualBox <br/>Remote Desktop </td>
<td> Desktop as a Service. <br/> Cloud-based desktop service with installed common applications. </td>
</tr>
<tr>
<td> <strong>WorkDocs</strong> </td>
<td> </td>
<td> </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h3>Platform Services</h3>

<h4>Databases</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <a href="https://aws.amazon.com/rds/"><strong>RDS</strong></a> <br/>(Relational Database Service) </td>
<td> MySQL, PostgreSQL, etc. <br/>Relational databases. </td>
<td> Managed relational databases in the cloud. <br/>Amazon Aurora, Oracle, Microsoft SQL Server, PostgreSQL, MySQL and MariaDB.</td>
</tr>
<tr>
<td> <a href="https://aws.amazon.com/elasticache/"><strong>ElastiCache</strong></a></td>
<td> Memcached </td>
<td> For information retrieval from memory-based cache nodes instead of slower disk-based databases. <br/>It supports Memcached and Redis caching engine. </td>
</tr>
<tr>
<td> <a href="https://aws.amazon.com/dynamodb/"><strong>DynamoDB</strong></a> </td>
<td> MongoDB </td>
<td> NoSQL database service. </td>
</tr>
<tr>
<td> <a href="https://aws.amazon.com/redshift/"><strong>Redshift</strong></a> </td>
<td> OLAP system </td>
<td> Data warehouse service. </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Analytics</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>Kinesis</strong> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td> <strong>EMR</strong> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td> <strong>Data Pipeline</strong> </td>
<td> </td>
<td> </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>App Services</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>Cloud Search</strong> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td> <strong>SES</strong> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td> <strong>SWF</strong> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td> <strong>Elastic Transcoder</strong> </td>
<td> </td>
<td> </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Deployment &amp; Management</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>Code Commit</strong> </td>
<td> Git </td>
<td> Source control service.</td>
</tr>
<tr>
<td> <strong>Code Deploy</strong> </td>
<td> </td>
<td> Code deployment service. </td>
</tr>
<tr>
<td> <strong>CloudFormation</strong> </td>
<td> Chef </td>
<td> Infrastructure as Code. <br/>Provisioning using source-controlled codes.</td>
</tr>
<tr>
<td> <strong>Elastic Beanstalk</strong> </td>
<td> </td>
<td> </td>
</tr>
</tbody>
</table>


<p><br/></p>

<h4>Mobile Services</h4>

<table>
<thead>
<tr>
<th> AWS name </th>
<th> Use it like </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>SNS</strong> </td>
<td> </td>
<td> Notifications. </td>
</tr>
<tr>
<td> <strong>Cognito</strong> </td>
<td> </td>
<td> Mobile authentication and data syncing. </td>
</tr>
<tr>
<td> <strong>Mobile Analytics</strong> </td>
<td> </td>
<td> Measure and analyze mobile application usage data. </td>
</tr>
</tbody>
</table>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Virtual Machine for ETL Testing]]></title>
    <link href="http://tdongsi.github.io/blog/2016/01/10/find-and-replace-a-string-in-multiple-files/"/>
    <updated>2016-01-10T23:49:15-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/01/10/find-and-replace-a-string-in-multiple-files</id>
    <content type="html"><![CDATA[<h3>Vertica Virtual Machine as sandbox test environment</h3>

<p>When developing data-warehouse solutions in Vertica, you want to set up some test environment.
Ideally, you should have separate schema for each developer.
However, it is usually NOT possible in my experience: developers and test engineers have to share very few schemas in development environment.
The explanation that I usually get is that having a schema for each developer will not scale in database maintenance and administration, and there are likely some limits in Vertica&rsquo;s commercial license.
If that is the case, I recommend that we look into using Vertica Community Edition on <strong>Virtual Machines (VMs)</strong> for sandbox test environment, as a cheap alternative.</p>

<p>Are VMs really necessary in data-warehouse testing? When testing Extract-Transform-Load (ETL) processes, I find that many of test cases require regular set-up and tear-down, adding mock records to represent corner cases, and/or running ETLs multiple times to simulate daily runs of those processes.
Regular tear-down requires dropping multiple tables regularly, which requires much greater care and drains much mental energy when working with others' data and tables.
Similarly, adding mock records into some commonly shared tables might affect others when they assume the data is production-like.
Running ETL scripts regularly, which could be computationally intensive, on a shared Vertica cluster might affect the performance or get affected by others' processes.</p>

<p>In short, for these tests, I cannot use the common schema that is shared with others since it might interfere others and/or destroy valuable common data.
Using a Vertica VM as the sandbox test environment helps us minimize interference to and from others' data and activities.</p>

<h3>Single-node VM and KSAFE clause</h3>

<p>I have been using a <strong>single-node</strong> Vertica VM to run tests for sometime. And it works wonderfully for testing purpose, especially when you want to isolate issues, for example, a corner case. The Vertica VM can be downloaded from HP Vertica&rsquo;s support website (NOTE: As of 2016 Jan 1st, the Vertica 7.1 VM is taken down while the Vertica 7.2 VM is not available).</p>

<p>The only minor problem is when we add <code>KSAFE 1</code> in our DDL scripts (i.e., <code>CREATE TABLE</code> statements) for production purposes which gives error on single-node VM when running DDL scripts to set up schema.
The reason is that Vertica database with 1 or 2 hosts cannot be <em>k-safe</em> (i.e., it may lose data if it crashes) and three-node cluster is the minimum requirement to have <code>KSAFE 1</code> in <code>CREATE TABLE</code> statements to work.</p>

<p>Even then, the workaround for running those DDL scripts in tests is easy enough if all DDL scripts are all located in a single folder. The idea is that since <code>KSAFE 1</code> does not affect ETL processes' transform logics, we can remove those KSAFE clauses to set up the test schema and go ahead with our ETL testing. Specifically, in my project, my workflow for ETL testing with <strong>Git</strong> is as follows:</p>

<ul>
<li>Branch the latest code (<code>develop</code> branch) into a temporary branch (e.g., <code>local/develop</code> branch).</li>
<li>Find and remove <code>KSAFE 1</code> in all DDL files (see subsection below).</li>
<li>While still in <code>local/develop</code> branch, commit all these changes in a <strong>single</strong> commit with some unique description (e.g., &ldquo;KSAFE REMOVAL&rdquo;).</li>
<li>Add unit and functional tests to ETL scripts in this branch.</li>
<li>After tests are properly developed and checked-in, reverse the &ldquo;KSAFE REMOVAL&rdquo; commit above.

<ul>
<li>In SourceTree, it could be done by a simple right-click on that commit and selecting &ldquo;Reverse Commit&rdquo;.</li>
</ul>
</li>
<li>Merge <code>local/develop</code> branch into <code>develop</code> branch. You will now have your tests with the latest codes in <code>develop</code> branch.</li>
</ul>


<h4>Find and replace a string in multiple files</h4>

<p>There are times and times again that you find that you have to replace every single occurrences of some string in multiple files with another string. Finding and removing <code>KSAFE 1</code> like the above workflow is an example where &ldquo;removing string&rdquo; is a special case of &ldquo;replacing string&rdquo; with nothing. This operation can be quickly done by the following bash command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>grep -rl match_string your_dir/ | xargs sed -i 's/old_string/new_string/g'</span></code></pre></td></tr></table></div></figure>


<p>If you are familiar with bash scripting, the above command is straight forward. This quick explanation is for anyone who does not understand the command:</p>

<ul>
<li><code>grep</code> command finds all files in <code>your_dir</code> directory that contain <code>match_string</code>. <code>-l</code> option makes sure it will return a list of files</li>
<li><code>sed</code> command then execute the replacement regex on all those files. A regex tip: the forward slash <code>/</code> delimiter could be another delimiter (e.g., <code>#</code>). This might be useful if you need to search HTML files.</li>
</ul>


<p>Example: In my case, all the DDL scripts are in multiple sub-directories under <code>tables</code> directory. To find and remove all <code>KSAFE 1</code> occurrences, the command is:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>grep -rl 'KSAFE 1' tables | xargs sed -i 's/KSAFE 1//g'</span></code></pre></td></tr></table></div></figure>


<p>This will search for the string <code>KSAFE 1</code> in all files in the <code>tables</code> directory and replace <code>KSAFE 1</code> with nothing <code>''</code> for each occurrence of the string in each file.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vertica Tip: Find Empty Tables]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/18/vertica-tip-find-empty-tables-in-a-schema/"/>
    <updated>2015-12-18T21:39:56-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/18/vertica-tip-find-empty-tables-in-a-schema</id>
    <content type="html"><![CDATA[<p>This post is a reminder of using Vertica&rsquo;s system tables for administrating and monitoring our own tables. One common house-cleaning operation when developing/testing in Vertica is to find and drop tables that are empty (truncated) and never used again.</p>

<p>You might ask why the tables are not dropped directly when I truncated the table in the first place. The answer is that all those tables have some specific designs on projection segmentation and partition, and those information will be lost if I drop the tables. These tables are frequently populated with data and cleared for testing purposes, and truncating and inserting with <code>direct</code> <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/Statements/INSERT.htm">hint</a> will give a significant performance boost (see <a href="http://tdongsi.github.io/blog/2015/12/16/vertica-tip-best-practices/">Best practices</a>).</p>

<h3>v_monitor schema and COLUMN_STORAGE system table</h3>

<p>The <a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/SystemTables/MONITOR/COLUMN_STORAGE.htm">COLUMN_STORAGE system table</a> in <code>v_monitor</code> schema returns the &ldquo;amount of disk storage used by each column of each projection on each node&rdquo;. Therefore, to get the size of each table, you only need to aggregate the <code>used_byte</code> data, grouped by schema name and table name.</p>

<figure class='code'><figcaption><span>Query to list tables' sizes in a schema</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="n">anchor_table_schema</span><span class="p">,</span> <span class="n">anchor_table_name</span><span class="p">,</span> <span class="k">sum</span><span class="p">(</span><span class="n">used_bytes</span><span class="p">)</span>
</span><span class='line'><span class="k">FROM</span> <span class="n">v_monitor</span><span class="p">.</span><span class="n">column_storage</span>
</span><span class='line'><span class="k">where</span> <span class="n">anchor_table_schema</span> <span class="o">=</span> <span class="s1">&#39;some_schema&#39;</span>
</span><span class='line'><span class="k">group</span> <span class="k">by</span> <span class="n">anchor_table_schema</span><span class="p">,</span> <span class="n">anchor_table_name</span>
</span></code></pre></td></tr></table></div></figure>


<p>According to <a href="http://vertica.tips/2014/01/25/table-size/">here</a>, the number from the above query is the <em>compressed</em> size of the Vertica tables. To get the <em>raw</em> size of the tables, which probably only matters for license limit, perform a <em>license audit</em>, and query the system table <code>license_audits</code> in <code>v_catalog</code> schema. However, the most important takeaway is that empty tables will not appear in this <code>COLUMN_STORAGE</code> system table.</p>

<h3>v_catalog schema and TABLES system table</h3>

<p>The <a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/SystemTables/CATALOG/TABLES.htm">TABLES system table</a> is probably more well-known. It contains all the information about all the tables in all the schemas. For example, to list all the tables in some schema:</p>

<figure class='code'><figcaption><span>Query to list all tables in a schema</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="n">table_schema</span><span class="p">,</span> <span class="k">table_name</span> <span class="k">from</span> <span class="n">tables</span>
</span><span class='line'><span class="k">where</span> <span class="n">table_schema</span> <span class="o">=</span> <span class="s1">&#39;some_schema&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Another useful system table in <code>v_catalog</code> schema is <code>USER_FUNCTIONS</code> which lists all user-defined functions and their function signatures in the database.</p>

<h3>Find all the empty (truncated) tables</h3>

<p>Having all the tables in <code>v_catalog.tables</code> table and only non-empty tables in <code>v_monitor.column_storage</code> table, finding empty tables is pretty straight-forward in SQL:</p>

<figure class='code'><figcaption><span>Query to find empty tables in a schema</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="k">table_name</span>
</span><span class='line'><span class="k">from</span> <span class="n">v_catalog</span><span class="p">.</span><span class="n">tables</span>
</span><span class='line'><span class="k">where</span> <span class="n">table_schema</span> <span class="o">=</span> <span class="s1">&#39;some_schema&#39;</span>
</span><span class='line'><span class="k">EXCEPT</span>
</span><span class='line'><span class="k">select</span> <span class="n">anchor_table_name</span>
</span><span class='line'><span class="k">from</span> <span class="n">v_monitor</span><span class="p">.</span><span class="n">column_storage</span>
</span><span class='line'><span class="k">where</span> <span class="n">anchor_table_schema</span> <span class="o">=</span> <span class="s1">&#39;some_schema&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<h3>External Links</h3>

<ol>
<li><a href="http://vertica.tips/2014/01/25/table-size/">Finding table&rsquo;s compressed size</a></li>
<li><a href="http://vertica.tips/2014/01/24/license-audit-utilization-raw-size/">Vertica License audit</a></li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/SystemTables/MONITOR/COLUMN_STORAGE.htm">COLUMN_STORAGE system table</a></li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/SystemTables/CATALOG/TABLES.htm">TABLES system table</a></li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/SystemTables/CATALOG/USER_FUNCTIONS.htm">USER_FUNCTIONS system table</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vertica Tip: Using Vsql CLI]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/17/vertica-tip-using-vsql/"/>
    <updated>2015-12-17T22:54:07-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/17/vertica-tip-using-vsql</id>
    <content type="html"><![CDATA[<h3>Using vsql</h3>

<p>You can connect to Vertica database with username and password. When doing this, note that the password might be seen in the command history.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vsql -h internal.vertica.net -p 5433 -d VMart -U vertica_user -w password </span></code></pre></td></tr></table></div></figure>


<p>Or you can connect to Vertica with Kerberos authentication.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vsql -h internal.vertica.net -p 5433 -d VMart -k KerberosServiceName -K KerberosHostName</span></code></pre></td></tr></table></div></figure>


<p>Note that from time to time, you could run into Kerberos GSI failure because the ticket expired. This is how you can renew and extend the ticket: run the following command to refresh Kerberos cache for the headless account <code>vertica_user</code>.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kinit -kt /home/path/to/vertica_user.keytab vertica_user@CORP.INTERNAL.NET</span></code></pre></td></tr></table></div></figure>


<p>You can also run a single SQL command from command line with <code>-c</code> option or, alternatively, a SQL script file with multiple commands with <code>-f</code> option.
These options can be very useful to automate in shell/python scripts.
Note that you can also parameterize your scripts by using <code>-v</code> option to assign variables inside your SQL scripts.</p>

<h3>Vsql meta commands</h3>

<p>Here is list of commonly used vsql <a href="http://my.vertica.com/docs/7.0.x/HTML/index.htm#Authoring/ProgrammersGuide/vsql/Meta-Commands.htm">meta commands</a>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>dbadmin=&gt; \dt â€” (list of all tables)
</span><span class='line'>dbadmin=&gt; \dt user* â€” (list of tables starting with user)
</span><span class='line'>dbadmin=&gt; \d tablename â€” (describe table)
</span><span class='line'>dbadmin=&gt; \dv â€” (list of all views)</span></code></pre></td></tr></table></div></figure>


<p>Here are the vsql commands to export a file:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>dbadmin=&gt; \o sample_users_lists.csv
</span><span class='line'>dbadmin=&gt; \f|
</span><span class='line'>dbadmin=&gt; select * from my_dwh.users limit 20;
</span><span class='line'>dbadmin=&gt; \o
</span><span class='line'>dbadmin=&gt; \q</span></code></pre></td></tr></table></div></figure>


<h3>External links</h3>

<ol>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/ConnectingToHPVertica/vsql/CommandLineOptions.htm">Command line options</a></li>
<li><a href="http://my.vertica.com/docs/7.0.x/HTML/index.htm#Authoring/ProgrammersGuide/vsql/Meta-Commands.htm">Meta Commands</a></li>
<li><a href="http://my.vertica.com/docs/7.0.x/HTML/index.htm#Authoring/ProgrammersGuide/vsql/Meta-Commands/TheDPATTERNMeta-commands.htm">Meta Commands: \d[Pattern]</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vertica Tip: Best Practices]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/16/vertica-tip-best-practices/"/>
    <updated>2015-12-16T23:12:06-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/16/vertica-tip-best-practices</id>
    <content type="html"><![CDATA[<p>This post lists some tips and tricks that I learnt when working with Vertica database.</p>

<h3>General Tips and Tricks</h3>

<h4>CREATE (INSERT)</h4>

<ul>
<li><p>If you want to write data directly to disk and bypass memory, then you should include <code>/*+ direct */</code> as a &ldquo;hint&rdquo; in your <code>INSERT</code> statement. This is especially helpful when you are loading data from big files into Vertica. If you don&rsquo;t use <code>/*+ direct */</code>, then <code>INSERT</code> statement first uses memory, which may be more useful when you want to optimally do inserts and run queries.</p></li>
<li><p>ALWAYS include <code>COMMIT</code> in your SQL statements when you are creating or updating Vertica schemas, because there is NO auto commit in Vertica.</p></li>
<li><p>If you are copying a table, <strong>DO NOT</strong> use <code>CREATE TABLE copy AS SELECT * FROM source</code>. This will give you a copy table with default projections and storage policy. Instead, you should use <code>CREATE TABLE</code> statement with the <a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/AdministratorsGuide/Tables/CreatingATableLikeAnother.htm"><code>LIKE existing_table</code> clause</a> and use <code>INSERT /*+ direct */</code> statement. Creating a table with <code>LIKE</code> option replicates the table definition and storage policy associated with the source table, which can make a significant difference in data loading performance. Note that the <code>LIKE</code> clause does not work if the existing source table is a temporary table.</p></li>
</ul>


<figure class='code'><figcaption><span>DO NOT do this</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">create</span> <span class="k">table</span> <span class="n">to_schema</span><span class="p">.</span><span class="n">to_table_name</span>
</span><span class='line'><span class="k">as</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">from_schema</span><span class="p">.</span><span class="n">from_table_name</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>DO this</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">to_schema</span><span class="p">.</span><span class="n">to_table_name</span> <span class="k">LIKE</span> <span class="n">from_schema</span><span class="p">.</span><span class="n">from_table_name</span> <span class="k">INCLUDING</span> <span class="n">PROJECTIONS</span><span class="p">;</span>
</span><span class='line'><span class="k">INSERT</span> <span class="cm">/*+ direct */</span> <span class="k">INTO</span> <span class="n">to_schema</span><span class="p">.</span><span class="n">to_table_name</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">from</span> <span class="n">from_schema</span><span class="p">.</span><span class="n">from_table_name</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Before making a copy of a table, be sure to consider alternatives in order to execute optimal queries: create views, rewrite queries, use sub-queries, limit queries to only a subset of data for analysis.</li>
</ul>


<h4>READ</h4>

<ul>
<li><p>Avoid joining large tables (e.g., > 50M records). Run a <code>count(*)</code> on tables before joining and use <code>MERGE JOIN</code> to optimally join tables. When you use smaller subsets of data, the Vertica Optimizer will pick the <code>MERGE JOIN</code> algorithm instead of the <code>HASH JOIN</code> one, which is less optimal.</p></li>
<li><p>When an approximate value will be enough, Vertica offers an alternative to <code>COUNT(DISTINCT)</code>: <code>APPROXIMATE_COUNT_DISTINCT</code>. This function is recommended when you have a large data set and you do not require an exact count of distinct values: e.g., sanity checks that verify the tables are populated. According to <a href="http://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/AnalyzingData/Optimizations/OptimizingCOUNTDISTINCTByCalculatingApproximateCounts.htm">this documentation</a>, you can get much better performance than <code>COUNT(DISTINCT)</code>. <a href="http://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/Functions/Aggregate/APPROXIMATE_COUNT_DISTINCT.htm">Here</a> is an example of the <code>APPROXIMATE_COUNT_DISTINCT</code> syntax that you should use.</p></li>
</ul>


<h4>UPDATE &amp; DELETE</h4>

<ul>
<li><p>Deletes and updates take exclusive locks on the table. Hence, only one <code>DELETE</code> or <code>UPDATE</code> transaction on that table can be in progress at a time and only when no <code>INSERTs</code> are in progress. Deletes and updates on different tables can be run concurrently.</p></li>
<li><p>Try to avoid <code>DELETE</code> or <code>UPDATE</code> as much as you can, especially on shared Vertica databases. Instead, it may work better to move the data you want to update to a new temporary table, work on that copy, drop the original table, and rename the temporary table with the original table name. For example:</p></li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="n">temp_table</span> <span class="k">LIKE</span> <span class="n">src_table</span> <span class="k">INCLUDING</span> <span class="n">PROJECTIONS</span><span class="p">;</span>
</span><span class='line'><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">temp_table</span> <span class="p">(</span><span class="k">SELECT</span> <span class="k">statement</span> <span class="n">based</span> <span class="k">on</span> <span class="n">the</span> <span class="n">updated</span> <span class="k">data</span> <span class="k">or</span> <span class="n">the</span> <span class="n">needed</span> <span class="k">rows</span><span class="p">);</span>
</span><span class='line'><span class="k">DROP</span> <span class="k">TABLE</span> <span class="n">src_table</span><span class="p">;</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">temp_table</span> <span class="k">RENAME</span> <span class="k">TO</span> <span class="n">src_table</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Delete from tables marks rows with delete vectors and stores them so data can be rolled back to a previous epoch. The data must be eventually purged before the database can reclaim disk space.</li>
</ul>


<h3>Query plan</h3>

<p>A query plan is a sequence of step-like paths that the HP Vertica cost-based query optimizer selects to access or alter information in your HP Vertica database. You can get information about query plans by prefixing the SQL query with the <code>EXPLAIN</code> command.</p>

<figure class='code'><figcaption><span>EXPLAIN statement</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">EXPLAIN</span> <span class="k">SELECT</span> <span class="n">customer_name</span><span class="p">,</span> <span class="n">customer_state</span> <span class="k">FROM</span> <span class="n">customer_dimension</span>
</span><span class='line'><span class="k">WHERE</span> <span class="n">customer_state</span> <span class="k">in</span> <span class="p">(</span><span class="s1">&#39;MA&#39;</span><span class="p">,</span><span class="s1">&#39;NH&#39;</span><span class="p">)</span> <span class="k">AND</span> <span class="n">customer_gender</span> <span class="o">=</span> <span class="s1">&#39;Male&#39;</span>
</span><span class='line'><span class="k">ORDER</span> <span class="k">BY</span> <span class="n">customer_name</span> <span class="k">LIMIT</span> <span class="mi">10</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>The output from a query plan is presented in a tree-like structure, where each step path represents a single operation in the database that the optimizer uses for its execution strategy. The following example output is based on the previous query:</p>

<figure class='code'><figcaption><span>Query Plan description</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>EXPLAIN SELECT
</span><span class='line'>customer_name,
</span><span class='line'>customer_state
</span><span class='line'>FROM customer_dimension
</span><span class='line'>WHERE customer_state in <span class="o">(</span><span class="s1">&#39;MA&#39;</span>,<span class="s1">&#39;NH&#39;</span><span class="o">)</span>
</span><span class='line'>AND <span class="nv">customer_gender</span> <span class="o">=</span> <span class="s1">&#39;Male&#39;</span>
</span><span class='line'>ORDER BY customer_name
</span><span class='line'>LIMIT 10<span class="p">;</span>
</span><span class='line'>Access Path:
</span><span class='line'>+-SELECT  LIMIT <span class="m">10</span> <span class="o">[</span>Cost: 370, Rows: 10<span class="o">]</span> <span class="o">(</span>PATH ID: 0<span class="o">)</span>
</span><span class='line'><span class="p">|</span>  Output Only: <span class="m">10</span> tuples
</span><span class='line'><span class="p">|</span>  Execute on: Query Initiator
</span><span class='line'><span class="p">|</span> +---&gt; SORT <span class="o">[</span>Cost: 370, Rows: 544<span class="o">]</span> <span class="o">(</span>PATH ID: 1<span class="o">)</span>
</span><span class='line'><span class="p">|</span> <span class="p">|</span>      Order: customer_dimension.customer_name ASC
</span><span class='line'><span class="p">|</span> <span class="p">|</span>      Output Only: <span class="m">10</span> tuples
</span><span class='line'><span class="p">|</span> <span class="p">|</span>      Execute on: Query Initiator
</span><span class='line'><span class="p">|</span> <span class="p">|</span> +---&gt; STORAGE ACCESS <span class="k">for</span> customer_dimension <span class="o">[</span>Cost: 331, Rows: 544<span class="o">]</span> <span class="o">(</span>PATH ID: 2<span class="o">)</span>
</span><span class='line'><span class="p">|</span> <span class="p">|</span> <span class="p">|</span>      Projection: public.customer_dimension_DBD_1_rep_vmartdb_design_vmartdb_design_node0001
</span><span class='line'><span class="p">|</span> <span class="p">|</span> <span class="p">|</span>      Materialize: customer_dimension.customer_state, customer_dimension.customer_name
</span><span class='line'><span class="p">|</span> <span class="p">|</span> <span class="p">|</span>      Filter: <span class="o">(</span>customer_dimension.customer_gender <span class="o">=</span> <span class="s1">&#39;Male&#39;</span><span class="o">)</span>
</span><span class='line'><span class="p">|</span> <span class="p">|</span> <span class="p">|</span>      Filter: <span class="o">(</span>customer_dimension.customer_state <span class="o">=</span> ANY <span class="o">(</span>ARRAY<span class="o">[</span><span class="s1">&#39;MA&#39;</span>, <span class="s1">&#39;NH&#39;</span><span class="o">]))</span>
</span><span class='line'><span class="p">|</span> <span class="p">|</span> <span class="p">|</span>      Execute on: Query Initiator
</span></code></pre></td></tr></table></div></figure>


<p>If you want to understand the details of the query plan, observe the real-time flow of data through the plan to identify possible query bottlenecks, you can:</p>

<ol>
<li>query the <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/SystemTables/MONITOR/QUERY_PLAN_PROFILES.htm">V_MONITOR.QUERY_PLAN_PROFILES</a> system table.</li>
<li>review <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/AdministratorsGuide/Profiling/ProfilingQueryPlanProfiles.htm">Profiling Query Plans</a>.</li>
<li>use <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/Statements/PROFILE.htm">PROFILE</a> statement to view further detailed analysis of your query.</li>
</ol>


<h3>External Links</h3>

<ol>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm">Vertica documentation</a></li>
<li><a href="http://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/Functions/Aggregate/APPROXIMATE_COUNT_DISTINCT.htm">APPROXIMATE_COUNT_DISTINCT</a></li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/AdministratorsGuide/Tables/CreatingATableLikeAnother.htm">Create a Table Like Another</a></li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/SystemTables/MONITOR/QUERY_PLAN_PROFILES.htm">V_MONITOR.QUERY_PLAN_PROFILES</a> system table.</li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/AdministratorsGuide/Profiling/ProfilingQueryPlanProfiles.htm">Profiling Query Plans</a>.</li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/Statements/PROFILE.htm">PROFILE</a> statement.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Netezza CLI Tools]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/09/netezza-cli/"/>
    <updated>2015-12-09T18:34:12-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/09/netezza-cli</id>
    <content type="html"><![CDATA[<p>In addition to using third party GUI clients such as SQuirreLSQL, you can also interact with Netezza through its command line interface (CLI) tools.
These are programs that let you do useful things like importing and exporting large volumes of data, invoking Netezza from bash scripts, controlling sessions and queries, etc.
The following is a quick overview of just the <code>nzsql</code> and <code>nzload</code> commands.
For a description of all the CLI tools, see the documentation <a href="http://www-01.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.adm.doc/r_sysadm_summary_of_commands.html?lang=en">here</a>.
You can install the Netezza CLI tools directly onto your system by following the instructions <a href="http://www-01.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.adm.doc/c_sysadm_client_software_install.html">here</a>.</p>

<h3>nzsql command</h3>

<p>You can use <code>nzsql</code> in interactive terminal mode by executing the command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>nzsql -host &lt;hostname&gt; -u &lt;username&gt; -pw &lt;password&gt; -d &lt;database&gt;
</span><span class='line'>  
</span><span class='line'>Welcome to nzsql, the IBM Netezza SQL interactive terminal.
</span><span class='line'>
</span><span class='line'>Type:  \h for help with SQL commands
</span><span class='line'>       \? for help on internal slash commands
</span><span class='line'>       \g or terminate with semicolon to execute query
</span><span class='line'>       \q to quit
</span><span class='line'>
</span><span class='line'>ws(user)=&gt;</span></code></pre></td></tr></table></div></figure>


<p>which puts you in the nzsql command line interpreter.</p>

<p>From there, you can execute SQL commands:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ws(user)=&gt; select count(*) from dwh..companies;
</span><span class='line'>COUNT
</span><span class='line'>---------
</span><span class='line'>6286
</span><span class='line'>(1 row)</span></code></pre></td></tr></table></div></figure>


<p>and you can also execute &ldquo;slash&rdquo; commands.  For example, to change the database to <code>dwh</code> and describe the table <code>companies</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ws(user)=&gt; \c dwh
</span><span class='line'>You are now connected to database dwh.
</span><span class='line'>ws(user)=&gt; \d companies
</span><span class='line'>                                 View "COMPANIES"
</span><span class='line'>           Attribute           |          Type           | Modifier | Default Value 
</span><span class='line'>-------------------------------+-------------------------+----------+---------------
</span><span class='line'> COMPANY_ID                    | NUMERIC(38,0)           | NOT NULL | 
</span><span class='line'> COMPANY_NAME                  | CHARACTER VARYING(100)  |          | 
</span><span class='line'> COMPANY_STATUS                | NUMERIC(38,0)           |          | 
</span><span class='line'> STATUS_MESSAGE                | CHARACTER VARYING(2000) |          | 
</span><span class='line'> CREATE_DATE                   | DATE                    |          | 
</span><span class='line'> CREATE_VERSION                | CHARACTER VARYING(20)   |          | 
</span><span class='line'> ASSIGNED_DATE                 | DATE                    |          | 
</span><span class='line'> ASSIGNED_VERSION              | CHARACTER VARYING(20)   |          | 
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>To see all the available slash commands, type <code>\?</code> at the prompt:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ws(user)=&gt; \?
</span><span class='line'> \a              toggle between unaligned and aligned mode
</span><span class='line'> \act            show current active sessions
</span><span class='line'> \c[onnect] [dbname [user] [password]]    connect to new database (currently 'UED_QBO_WS')
</span><span class='line'> \C &lt;title&gt;      HTML table title
</span><span class='line'> \copy ...       perform SQL COPY with data stream to the client machine
</span><span class='line'> \d &lt;table&gt;      describe table (or view, index, sequence, synonym)
</span><span class='line'> \d{t|v|i|s|e|x} list tables/views/indices/sequences/temp tables/external tables
</span><span class='line'> \d{m|y}         list materialized views/synonyms
</span><span class='line'> \dS{t|v|i|s}    list system tables/views/indexes/sequences
</span><span class='line'> \dM{t|v|i|s}    list system management tables/views/indexes/sequences
</span><span class='line'> \dp &lt;name&gt;      list user permissions
</span><span class='line'> \dpu &lt;name&gt;     list permissions granted to a user
</span><span class='line'> \dpg &lt;name&gt;     list permissions granted to a group
</span><span class='line'> \dgp &lt;name&gt;     list grant permissions for a user
</span><span class='line'> \dgpu &lt;name&gt;    list grant permissions granted to a user
</span><span class='line'> \dgpg &lt;name&gt;    list grant permissions granted to a group
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>To escape from the nzsql interactive terminal mode, type <code>\q</code> at the prompt.</p>

<p>You can also use the <code>nzsql</code> command directly from the command line, by invoking it with various parameters.
See the documentation <a href="http://www-01.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.adm.doc/r_sysadm_nzsql_command.html">here</a> for all the parameters that can be used with the <code>nzsql</code> command.
As an example, to execute a single SQL statement and print the results to the terminal:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-bash-4.1$ nzsql -host myHost -u username -pw password -d ws -c 'select count(*) from companies'
</span><span class='line'>COUNT  
</span><span class='line'>---------
</span><span class='line'>9032
</span><span class='line'>(1 row)</span></code></pre></td></tr></table></div></figure>


<p>Or, to direct the output to a specific file in the local file system:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-bash-4.1$ nzsql -host myHost -u username -pw password -d ws -c 'select count(*) from companies' -o output.txt
</span><span class='line'>-bash-4.1$ cat output.txt
</span><span class='line'>COUNT  
</span><span class='line'>---------
</span><span class='line'>9032
</span><span class='line'>(1 row)</span></code></pre></td></tr></table></div></figure>


<p>And, to run a SQL script that is located in the local file system:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-bash-4.1$ cat my_script.sql
</span><span class='line'>select count(*) from companies;
</span><span class='line'>-bash-4.1$ nzsql -host myHost -u username -pw password -d ws -f my_script.sql
</span><span class='line'>COUNT
</span><span class='line'>---------
</span><span class='line'>9032
</span><span class='line'>(1 row)</span></code></pre></td></tr></table></div></figure>


<h3>nzload command</h3>

<p>The <code>nzload</code> command is used to move large volumes of data in to and out of Netezza.
This is a very broad subject, and you can find all the details <a href="http://www-01.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.load.doc/c_load_overview.html?cp=SSULQD_7.2.0%2F5&amp;lang=en">here</a>.
As a toy example, suppose you have the following data in the local filesystem:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-bash-4.1$ cat my_data.txt
</span><span class='line'>Fred, 2
</span><span class='line'>Betty, 7
</span><span class='line'>Wilma, 10
</span><span class='line'>Barney, 5</span></code></pre></td></tr></table></div></figure>


<p>You can create a Netezza to hold this data, using the <code>nzsql</code> command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-bash-4.1$ nzsql -host myHost -u username -pw password -d ws -c 'create table my_table (name varchar(80), rocks int)'</span></code></pre></td></tr></table></div></figure>


<p>And then you can populate the table using the <code>nzload</code> command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>nzload -host myHost -u username -pw password -db ws -t my_table -df my_data.txt -delim ','
</span><span class='line'>Load session of table 'MY_TABLE' completed successfully</span></code></pre></td></tr></table></div></figure>


<p>Finally, you can confirm that the table was populated using the <code>nzsql</code> command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-bash-4.1$ nzsql -host myHost -u username -pw password -d ws -c 'select * from my_table'
</span><span class='line'>  NAME  | ROCKS 
</span><span class='line'>--------+-------
</span><span class='line'> Wilma  |    10
</span><span class='line'> Betty  |     7
</span><span class='line'> Barney |     5
</span><span class='line'> Fred   |     2
</span><span class='line'>(4 rows)</span></code></pre></td></tr></table></div></figure>


<h3>External Links</h3>

<ol>
<li><a href="http://www-01.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.adm.doc/r_sysadm_summary_of_commands.html?lang=en">List of Netezza CLI tools</a></li>
<li><a href="http://www-01.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.adm.doc/c_sysadm_client_software_install.html">Installing the Netezza CLI tools</a></li>
<li><a href="http://www-01.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.adm.doc/r_sysadm_nzsql_command.html">Nzsql CLI tool</a></li>
<li><a href="http://www-01.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.load.doc/c_load_overview.html?cp=SSULQD_7.2.0%2F5&amp;lang=en">Nzload CLI tool</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Some NZSQL Tips for New Netezza Users]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/07/some-netezzas-nzsql-tips/"/>
    <updated>2015-12-07T11:11:06-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/07/some-netezzas-nzsql-tips</id>
    <content type="html"><![CDATA[<ul>
<li>By default, identifiers are treated as UPPERCASE, even if you type them as LOWERCASE. So, for example, these create statements:</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">create</span> <span class="k">table</span> <span class="n">my_table</span> <span class="p">(</span><span class="n">name</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">80</span><span class="p">),</span> <span class="n">address</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">80</span><span class="p">));</span>
</span><span class='line'><span class="k">create</span> <span class="k">table</span> <span class="n">my_table</span> <span class="p">(</span><span class="n">NaMe</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">80</span><span class="p">),</span> <span class="n">adDresS</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">80</span><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure>


<p>  are equivalent to:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">create</span> <span class="k">table</span> <span class="n">my_table</span> <span class="p">(</span><span class="n">NAME</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">80</span><span class="p">),</span> <span class="n">ADDRESS</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">80</span><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure>


<p>  The same is true for <code>SELECT</code> statements. These two SQL statements:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="n">name</span> <span class="k">from</span> <span class="n">my_table</span><span class="p">;</span>
</span><span class='line'><span class="k">select</span> <span class="n">NaMe</span> <span class="k">from</span> <span class="n">my_table</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>  are equivalent to:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="n">NAME</span> <span class="k">from</span> <span class="n">my_table</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>The best practice is that you should never care or override the above default behavior: your identifiers should be case-insensitive. Unfortunately, if you have to override the above default behavior, then you must surround the identifier with double-quotes whenever you reference it. For example, if you create a table using this statement:</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">create</span> <span class="k">table</span> <span class="n">my_table</span> <span class="p">(</span><span class="ss">&quot;Name&quot;</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">80</span><span class="p">),</span> <span class="ss">&quot;Address&quot;</span> <span class="nb">varchar</span><span class="p">(</span><span class="mi">80</span><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure>


<p>
then you must reference the identifiers by surrounding them with double-quotes. For example:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="ss">&quot;Name&quot;</span> <span class="k">from</span> <span class="n">my_table</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>The most perplexing feature for new Netezza users when reading a NZSQL script is probably the &ldquo;dot dot&rdquo; notation of database object names, i.e., the two dots in <code>my_dwh..companies</code>. It is simply the short-hand notation for database object names, <code>database-name..object-name</code>. The fully qualified form of object names in Netezza has <strong>three-level</strong> as <code>database-name.schema.object-name</code>. One example of using such notation is shown below:</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">select</span> <span class="k">count</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">from</span> <span class="p">(</span><span class="k">select</span> <span class="n">company_name</span> <span class="k">from</span> <span class="n">my_dwh</span><span class="p">..</span><span class="n">companies</span> <span class="k">where</span> <span class="n">company_name</span> <span class="k">like</span> <span class="s1">&#39;%e%&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">x</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<h4>External Links</h4>

<ol>
<li><a href="https://www-304.ibm.com/support/knowledgecenter/SSULQD_7.2.0/com.ibm.nz.dbu.doc/c_dbuser_database_object_naming.html">Database Object Naming</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive Tutorial (Pt. 7): Partitioned Tables]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/06/programming-hive-partitioned-tables/"/>
    <updated>2015-12-06T21:09:51-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/06/programming-hive-partitioned-tables</id>
    <content type="html"><![CDATA[<!--
Chapter 4
-->


<p>Continued from the <a href="http://tdongsi.github.io/blog/2015/12/02/programming-hive-hiveql-ddl/">previous</a> <a href="http://tdongsi.github.io/blog/2015/12/05/programming-hive-ddl-table/">posts</a>.</p>

<h3>Partitioned Managed Tables</h3>

<p>In general, partitioning data means distributing data load horizontally, moving data physically closer to its most frequent users. In Hive, partitioning tables changes how Hive structures its data storage for some performance gain.</p>

<p>In &ldquo;Programming Hive&rdquo;, the authors present a hypothetical problem where one will regularly query some <code>employees</code> table by country and state, e.g., all employees in California, US or Alberta, Canada. Therefore, partitioning this table by country and state is a logical thing to do.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">employees</span> <span class="p">(</span>
</span><span class='line'>  <span class="n">name</span>         <span class="n">STRING</span><span class="p">,</span>
</span><span class='line'>  <span class="n">salary</span>       <span class="nb">FLOAT</span><span class="p">,</span>
</span><span class='line'>  <span class="n">subordinates</span> <span class="nb">ARRAY</span><span class="o">&lt;</span><span class="n">STRING</span><span class="o">&gt;</span><span class="p">,</span>
</span><span class='line'>  <span class="n">deductions</span>   <span class="k">MAP</span><span class="o">&lt;</span><span class="n">STRING</span><span class="p">,</span> <span class="nb">FLOAT</span><span class="o">&gt;</span><span class="p">,</span>
</span><span class='line'>  <span class="n">address</span>      <span class="n">STRUCT</span><span class="o">&lt;</span><span class="n">street</span><span class="p">:</span><span class="n">STRING</span><span class="p">,</span> <span class="n">city</span><span class="p">:</span><span class="n">STRING</span><span class="p">,</span> <span class="k">state</span><span class="p">:</span><span class="n">STRING</span><span class="p">,</span> <span class="n">zip</span><span class="p">:</span><span class="nb">INT</span><span class="o">&gt;</span>
</span><span class='line'><span class="p">)</span>
</span><span class='line'><span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">country</span> <span class="n">STRING</span><span class="p">,</span> <span class="k">state</span> <span class="n">STRING</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Without <code>PARTITIONED BY</code> clause, Hive will store data for these tables in a subdirectory <code>employees</code> under the directory defined by <code>hive.metastore.warehouse.dir</code> (see <a href="http://tdongsi.github.io/blog/2015/12/05/programming-hive-ddl-table/">Managed tables</a>). However, Hive will now create subdirectories inside <code>employees</code> directory for the above partitioning structure:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>...
</span><span class='line'>.../employees/country<span class="o">=</span>CA/state<span class="o">=</span>AB
</span><span class='line'>.../employees/country<span class="o">=</span>CA/state<span class="o">=</span>BC
</span><span class='line'>...
</span><span class='line'>.../employees/country<span class="o">=</span>US/state<span class="o">=</span>AL
</span><span class='line'>.../employees/country<span class="o">=</span>US/state<span class="o">=</span>AK
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>The actual directory names depends on values of <em>partition keys</em> (e.g., country and state). For very large data sets, partitioning can improve query performance, but only if the partitioning scheme reflects common range filtering (e.g., by countries or states). When we add predicates to WHERE clauses that filter on partition values, these predicates are called <em>partition filters</em> (e.g., <code>WHERE state = 'CA'</code>).</p>

<p>You can view the partitions in a table with <code>SHOW PARTITIONS</code>, as shown in examples below:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">SHOW</span> <span class="n">PARTITIONS</span> <span class="n">college</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* DESCRIBE EXTENDED also shows partition keys */</span>
</span><span class='line'><span class="k">SHOW</span> <span class="n">PARTITIONS</span> <span class="n">employees</span> <span class="n">PARTITION</span><span class="p">(</span> <span class="n">country</span><span class="o">=</span><span class="err">â€˜</span><span class="n">US</span><span class="err">â€™</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<h4>Strict mode</h4>

<p>Given a partitioned table, a query across all partitions can result in a enormous MapReduce job, especially for a huge data set. It is probably desirable to put in place a safety measure which prohibits queries without any filter on partitions. Hive has a &ldquo;strict&rdquo; mode for that.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>hive&gt; <span class="nb">set </span>hive.mapred.mode<span class="p">;</span>
</span><span class='line'>hive.mapred.mode<span class="o">=</span>nonstrict
</span><span class='line'>
</span><span class='line'>hive&gt; <span class="nb">set </span>hive.mapred.mode <span class="o">=</span> strict<span class="p">;</span>
</span><span class='line'>hive&gt; SELECT e.name FROM employees e<span class="p">;</span> /* does not work */
</span></code></pre></td></tr></table></div></figure>


<h3>Partitioned External Tables</h3>

<p>You can use partitioning with external tables. The combination gives you a way to â€œshareâ€ data with other tools, while still optimizing query performance. While LOCATION clause is required for non-partitioned external table to specify data location, it is not required for external partitioned tables. Instead, <code>ALTER TABLE</code> statement is used to add data in each partition separately.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">EXTERNAL</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">log_messages</span> <span class="p">(</span>
</span><span class='line'>  <span class="n">hms</span>             <span class="nb">INT</span><span class="p">,</span>
</span><span class='line'>  <span class="n">severity</span>        <span class="n">STRING</span><span class="p">,</span>
</span><span class='line'>  <span class="n">server</span>          <span class="n">STRING</span><span class="p">,</span>
</span><span class='line'>  <span class="n">process_id</span>      <span class="nb">INT</span><span class="p">,</span>
</span><span class='line'>  <span class="n">message</span>         <span class="n">STRING</span><span class="p">)</span>
</span><span class='line'><span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="p">(</span><span class="k">year</span> <span class="nb">INT</span><span class="p">,</span> <span class="k">month</span> <span class="nb">INT</span><span class="p">,</span> <span class="k">day</span> <span class="nb">INT</span><span class="p">)</span>
</span><span class='line'><span class="k">ROW</span> <span class="n">FORMAT</span> <span class="n">DELIMITED</span> <span class="n">FIELDS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">&#39;\t&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span> <span class="k">ADD</span> <span class="n">PARTITION</span><span class="p">(</span><span class="k">year</span> <span class="o">=</span> <span class="mi">2012</span><span class="p">,</span> <span class="k">month</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="k">day</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
</span><span class='line'><span class="k">LOCATION</span> <span class="s1">&#39;hdfs://master_server/data/log_messages/2012/01/02&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">DESCRIBE</span> <span class="n">EXTENDED</span> <span class="n">log_messages</span> <span class="n">PARTITION</span> <span class="p">(</span><span class="k">year</span><span class="o">=</span><span class="mi">2012</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that <code>ALTER TABLE â€¦ ADD PARTITION</code> is not limited to external tables. You can use it with managed tables, too. However, it is not recommended since you have to manually keep track of this partition and remember to delete data in case you want to completely drop the managed table.</p>

<h4>Example use case of partitioned external tables</h4>

<p>For example, each day we might use the following procedure to move data older than a month to S3:</p>

<p>1) Copy the data for the partition being moved to S3. For example, you can use the hadoop distcp command:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> hadoop distcp /data/log_messages/2011/12/02 s3n://ourbucket/logs/2011/12/02
</span></code></pre></td></tr></table></div></figure>


<p>2) Alter the table to point the partition to the S3 location:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'> <span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span> <span class="n">PARTITION</span><span class="p">(</span><span class="k">year</span> <span class="o">=</span> <span class="mi">2011</span><span class="p">,</span> <span class="k">month</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span> <span class="k">day</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
</span><span class='line'> <span class="k">SET</span> <span class="k">LOCATION</span> <span class="s1">&#39;s3n://ourbucket/logs/2011/01/02&#39;</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>3) Remove the HDFS copy of the partition using the hadoop fs -rmr command:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> hadoop fs -rmr /data/log_messages/2011/01/02
</span></code></pre></td></tr></table></div></figure>


<h3>Altering Partitioned Tables</h3>

<p>Some basic <code>ALTER TABLE</code> statements for manipulating table partitions are shown in the following examples:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="cm">/* Add partition */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span> <span class="k">ADD</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span>
</span><span class='line'><span class="n">PARTITION</span> <span class="p">(</span><span class="k">year</span> <span class="o">=</span> <span class="mi">2011</span><span class="p">,</span> <span class="k">month</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'><span class="k">LOCATION</span> <span class="err">â€˜</span><span class="o">/</span><span class="n">logs</span><span class="o">/</span><span class="mi">2011</span><span class="o">/</span><span class="mi">01</span><span class="err">&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* Change partition location */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span> <span class="n">PARTITION</span> <span class="p">(</span><span class="k">year</span> <span class="o">=</span> <span class="mi">2011</span><span class="p">,</span> <span class="k">month</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'><span class="k">SET</span> <span class="k">LOCATION</span> <span class="err">â€˜</span><span class="o">/</span><span class="n">bucket</span><span class="o">/</span><span class="n">logs</span><span class="o">/</span><span class="mi">2011</span><span class="o">/</span><span class="mi">01</span><span class="err">â€™</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* Drop partition */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span> <span class="k">DROP</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">PARTITION</span> <span class="p">(</span><span class="k">year</span> <span class="o">=</span> <span class="mi">2011</span><span class="p">,</span> <span class="k">month</span> <span class="o">=</span> <span class="mi">1</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* Alter storage properties of partition */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span>
</span><span class='line'><span class="n">PARTITION</span><span class="p">(</span><span class="k">year</span> <span class="o">=</span> <span class="mi">2012</span><span class="p">,</span> <span class="k">month</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="k">day</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'><span class="k">SET</span> <span class="n">FILEFORMAT</span> <span class="n">SEQUENCEFILE</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* Archive partition */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span> <span class="n">ARCHIVE</span>
</span><span class='line'><span class="n">PARTITION</span><span class="p">(</span><span class="k">year</span> <span class="o">=</span> <span class="mi">2012</span><span class="p">,</span> <span class="k">month</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="k">day</span> <span class="o">=</span> <span class="mi">1</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>The <code>ALTER TABLE ... ARCHIVE PARTITION</code> statement captures the partition files into a Hadoop archive (HAR) file. This only reduces the number of files in the filesystem, reducing the load on the NameNode, but doesnâ€™t provide any space savings. To reverse the operation, substitute UNARCHIVE for ARCHIVE. This feature is only available for individual partitions of partitioned tables.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive Tutorial (Pt. 6): HiveQL Data Definition]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/05/programming-hive-ddl-table/"/>
    <updated>2015-12-05T20:15:56-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/05/programming-hive-ddl-table</id>
    <content type="html"><![CDATA[<p>Continued from the previous <a href="http://tdongsi.github.io/blog/2015/12/02/programming-hive-hiveql-ddl/">post</a>.</p>

<h3>Creating Tables</h3>

<p>Some basic HiveQL&rsquo;s table DDL commands are shown in the following examples:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="cm">/* NOTE: the LOCATION clause uses the default location */</span>
</span><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">college</span><span class="p">.</span><span class="n">student</span> <span class="p">(</span>
</span><span class='line'>  <span class="n">name</span> <span class="n">STRING</span> <span class="k">COMMENT</span> <span class="s1">&#39;Student name&#39;</span><span class="p">,</span>
</span><span class='line'>  <span class="n">sid</span> <span class="nb">INT</span> <span class="k">COMMENT</span> <span class="s1">&#39;Student ID&#39;</span><span class="p">,</span>
</span><span class='line'><span class="p">)</span>
</span><span class='line'><span class="k">COMMENT</span> <span class="s1">&#39;Description of the table&#39;</span> <span class="n">TBLPROPERTIES</span> <span class="p">(</span> <span class="s1">&#39;creator&#39;</span> <span class="o">=</span> <span class="s1">&#39;me&#39;</span> <span class="p">)</span>
</span><span class='line'><span class="k">LOCATION</span> <span class="s1">&#39;/user/hive/warehouse/college.db/student&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* </span>
</span><span class='line'><span class="cm"> * copy the schema of an existing table</span>
</span><span class='line'><span class="cm"> * you can specify optional LOCATION but no other can be defined</span>
</span><span class='line'><span class="cm"> */</span>
</span><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">mydb</span><span class="p">.</span><span class="n">clone</span> <span class="k">LIKE</span> <span class="n">mydb</span><span class="p">.</span><span class="n">employees</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm">* Create external table</span>
</span><span class='line'><span class="cm">* Read all data files with comma-delimited format</span>
</span><span class='line'><span class="cm">* from /data/stocks</span>
</span><span class='line'><span class="cm">* LOCATION is required for external table</span>
</span><span class='line'><span class="cm">*/</span>
</span><span class='line'><span class="k">CREATE</span> <span class="k">EXTERNAL</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">stocks</span> <span class="p">(</span>
</span><span class='line'>  <span class="n">exchange</span>        <span class="n">STRING</span><span class="p">,</span>
</span><span class='line'>  <span class="n">symbol</span>          <span class="n">STRING</span><span class="p">,</span>
</span><span class='line'>  <span class="n">volume</span>          <span class="nb">INT</span><span class="p">,</span>
</span><span class='line'>  <span class="n">price_adj_close</span> <span class="nb">FLOAT</span><span class="p">)</span>
</span><span class='line'><span class="k">ROW</span> <span class="n">FORMAT</span> <span class="n">DELIMITED</span> <span class="n">FIELDS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">&#39;,&#39;</span>
</span><span class='line'><span class="k">LOCATION</span> <span class="s1">&#39;/data/stocks&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm">* Copy external table schema.</span>
</span><span class='line'><span class="cm">*/</span>
</span><span class='line'><span class="k">CREATE</span> <span class="k">EXTERNAL</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">ext_clone</span>
</span><span class='line'><span class="k">LIKE</span> <span class="n">stocks</span>
</span><span class='line'><span class="k">LOCATION</span> <span class="s1">&#39;/path/to/data&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm">* Drop table</span>
</span><span class='line'><span class="cm">* For managed tables, the table metadata and data are deleted.</span>
</span><span class='line'><span class="cm">* For external tables, the metadata is deleted but the data is not.</span>
</span><span class='line'><span class="cm">*/</span>
</span><span class='line'><span class="k">DROP</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">college</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that in the first <code>CREATE TABLE</code> command, you can prefix a database name, e.g. <code>mydb</code>, even when it is not your current working database. As usual, the optional <code>IF NOT EXISTS</code> clause will ignore the statement if the table already exists, even when the schema does not match (no warning from Hive). The second <code>CREATE TABLE</code> command is useful to copy the schema of an existing table. The corresponding commands for <strong>external</strong> table are also shown above (note <code>EXTERNAL TABLE</code>). The concept of external table in Hive will be discussed shortly.</p>

<p>The <code>SHOW TABLES</code> command lists the tables. You use different variants of that command to find tables of interest as shown below:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>hive&gt; use college<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>Time taken: 0.048 seconds
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>/* Show list of tables in current database */
</span><span class='line'>hive&gt; show tables<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>apply
</span><span class='line'>college
</span><span class='line'>student
</span><span class='line'>Time taken: 0.031 seconds, Fetched: <span class="m">3</span> row<span class="o">(</span>s<span class="o">)</span>
</span><span class='line'>
</span><span class='line'>/* Show list of tables in the specified database */
</span><span class='line'>hive&gt; show tables in college<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>apply
</span><span class='line'>college
</span><span class='line'>student
</span><span class='line'>Time taken: 0.034 seconds, Fetched: <span class="m">3</span> row<span class="o">(</span>s<span class="o">)</span>
</span><span class='line'>
</span><span class='line'>/* use regex to search tables in current database */
</span><span class='line'>hive&gt; show tables <span class="s1">&#39;.*e.*&#39;</span><span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>college
</span><span class='line'>student
</span><span class='line'>Time taken: 0.025 seconds, Fetched: <span class="m">2</span> row<span class="o">(</span>s<span class="o">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>/* Show table properties */
</span><span class='line'>hive&gt; show tblproperties student<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>COLUMN_STATS_ACCURATE <span class="nb">true</span>
</span><span class='line'>comment   List of students
</span><span class='line'>numFiles  1
</span><span class='line'>numRows   0
</span><span class='line'>rawDataSize   0
</span><span class='line'>totalSize 213
</span><span class='line'>transient_lastDdlTime 1421796179
</span><span class='line'>Time taken: 0.28 seconds, Fetched: <span class="m">7</span> row<span class="o">(</span>s<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>You can use <code>DESCRIBE</code> command to display table information as shown below:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>hive&gt; describe extended student<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>sid                   int                     Student ID
</span><span class='line'>sname                 string                  Student name
</span><span class='line'>gpa                   float                   Student GPA
</span><span class='line'>sizehs                int                     Size of student highschool
</span><span class='line'>      
</span><span class='line'>Detailed Table Information    Table<span class="o">(</span>tableName:student, dbName:college, owner:cloudera, createTime:1421796178, lastAccessTime:0, retention:0,
</span><span class='line'>sd:StorageDescriptor<span class="o">(</span>cols:<span class="o">[</span>FieldSchema<span class="o">(</span>name:sid, <span class="nb">type</span>:int, comment:Student ID<span class="o">)</span>, FieldSchema<span class="o">(</span>name:sname, <span class="nb">type</span>:string, comment:Student name<span class="o">)</span>, ...
</span><span class='line'>Time taken: 0.119 seconds, Fetched: <span class="m">6</span> row<span class="o">(</span>s<span class="o">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>/* more readable and verbose */
</span><span class='line'>hive&gt; describe formatted student<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'><span class="c"># col_name                data_type               comment             </span>
</span><span class='line'>      
</span><span class='line'>sid                   int                     Student ID
</span><span class='line'>sname                 string                  Student name
</span><span class='line'>gpa                   float                   Student GPA
</span><span class='line'>sizehs                int                     Size of student highschool
</span><span class='line'>      
</span><span class='line'><span class="c"># Detailed Table Information       </span>
</span><span class='line'>Database:             college                 
</span><span class='line'>Owner:                cloudera                
</span><span class='line'>CreateTime:           Tue Jan <span class="m">20</span> 15:22:58 PST 2015 
</span><span class='line'>LastAccessTime:       UNKNOWN                 
</span><span class='line'>Protect Mode:         None                    
</span><span class='line'>Retention:            <span class="m">0</span>                    
</span><span class='line'>Location:             hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/student  
</span><span class='line'>Table Type:           MANAGED_TABLE           
</span><span class='line'>Table Parameters:     
</span><span class='line'>  COLUMN_STATS_ACCURATE   <span class="nb">true                </span>
</span><span class='line'><span class="nb"> </span>comment              List of students
</span><span class='line'>  numFiles                <span class="m">1</span>
</span><span class='line'>  numRows                 <span class="m">0</span>
</span><span class='line'>  rawDataSize             <span class="m">0</span>
</span><span class='line'>  totalSize               <span class="m">213</span>
</span><span class='line'>  transient_lastDdlTime   <span class="m">1421796179</span>
</span><span class='line'>      
</span><span class='line'><span class="c"># Storage Information      </span>
</span><span class='line'>SerDe Library:        org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe  
</span><span class='line'>InputFormat:          org.apache.hadoop.mapred.TextInputFormat    
</span><span class='line'>OutputFormat:         org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat  
</span><span class='line'>Compressed:           No                      
</span><span class='line'>Num Buckets:          -1                      
</span><span class='line'>Bucket Columns:       <span class="o">[]</span>                   
</span><span class='line'>Sort Columns:         <span class="o">[]</span>                   
</span><span class='line'>Storage Desc Params:      
</span><span class='line'>  field.delim             <span class="p">;</span>
</span><span class='line'>  serialization.format    <span class="p">;</span>
</span><span class='line'>Time taken: 0.108 seconds, Fetched: <span class="m">36</span> row<span class="o">(</span>s<span class="o">)</span>
</span><span class='line'>
</span><span class='line'>/* see schema <span class="k">for</span> a column */
</span><span class='line'>hive&gt; describe student.sid<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>sid                   int                     from deserializer
</span><span class='line'>Time taken: 0.315 seconds, Fetched: <span class="m">1</span> row<span class="o">(</span>s<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Managed tables vs. External tables</h3>

<p><code>CREATE TABLE</code> commands (without <code>EXTERNAL</code>) create <em>managed tables</em> or <em>internal tables</em>.
It is internal/managed because the life cycle of their data is managed by Hive.
By default, Hive stores data for these tables in a subdirectory under the directory defined by <code>hive.metastore.warehouse.dir</code>, as illustrated below (see <a href="http://tdongsi.github.io/blog/2015/11/23/programming-hive-hive-cli/">Hive CLI</a> for <code>SET</code> and <code>dfs</code> commands).
When we drop a managed table with <code>DROP TABLE</code> command, the data in the table will be deleted.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>hive&gt; SET hive.metastore.warehouse.dir<span class="p">;</span>
</span><span class='line'>hive.metastore.warehouse.dir<span class="o">=</span>/user/hive/warehouse
</span><span class='line'>hive&gt; dfs -ls /user/hive/warehouse/college.db<span class="p">;</span>
</span><span class='line'>Found <span class="m">3</span> items
</span><span class='line'>drwxrwxrwx   - hive hive          <span class="m">0</span> 2015-01-21 11:29 /user/hive/warehouse/college.db/apply
</span><span class='line'>drwxrwxrwx   - hive hive          <span class="m">0</span> 2015-12-03 15:16 /user/hive/warehouse/college.db/college
</span><span class='line'>drwxrwxrwx   - hive hive          <span class="m">0</span> 2015-01-28 15:26 /user/hive/warehouse/college.db/student
</span></code></pre></td></tr></table></div></figure>


<p>As mentioned in <a href="http://tdongsi.github.io/blog/2015/11/26/programming-hive-data-types/">Schema on Read</a>, Hive does not have control over the underlying storage, even for <em>managed table</em>: for example, you can totally use another <code>dfs</code> command in the last example to modify files on HDFS.</p>

<p>Managed tables are not convenient for sharing data with other tools.
Instead, <em>external tables</em> can be defined to point to that data, but don&rsquo;t take ownership of data.
In the <code>CREATE EXTERNAL TABLE</code> command example at the beginning of this post, the data files are in HDFS at <code>/data/stocks</code> and the external table will be created and populated by reading all comma-delimited data files in that location.
The <code>LOCATION</code> clause is required for external table, to tell Hive where it is located.
Dropping an external table does not delete the data since Hive does not <em>own</em> the data.
However, the <em>metadata</em> for that table will be deleted.</p>

<p>To tell whether if a table is managed or external, use the command <code>DESCRIBE FORMATTED</code>. In the example in the last section, we see that the table <code>college.student</code> is a managed table because of its output:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>Location:            hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/student  
</span><span class='line'>Table Type:           MANAGED_TABLE
</span></code></pre></td></tr></table></div></figure>


<p>For external tables, the output will be like <code>Table Type: EXTERNAL_TABLE</code>.</p>

<h3>Altering Tables</h3>

<p>The <code>ALTER TABLE</code> statements <em>only</em> change <em>metadata</em> of the table, but not the data in the table. It&rsquo;s up to us to ensure that any schema modifications are consistent with the actual data.</p>

<p>Some basic <code>ALTER TABLE</code> statements for renaming table and changing table columns are shown in the following examples:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="cm">/* Renaming table */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">college</span> <span class="k">RENAME</span> <span class="k">TO</span> <span class="n">university</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm"> * Change columns: rename, change its position, type, or comment.</span>
</span><span class='line'><span class="cm"> * The keyword COLUMN is optional, as well as COMMENT clause.</span>
</span><span class='line'><span class="cm"> * This command changes metadata only. </span>
</span><span class='line'><span class="cm"> * The data has to be moved to match the new columns if needed.</span>
</span><span class='line'><span class="cm"> * Use FIRST, instead of AFTER, if the column is moved to first.</span>
</span><span class='line'><span class="cm"> */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span>
</span><span class='line'><span class="n">CHANGE</span> <span class="k">COLUMN</span> <span class="n">hms</span> <span class="n">hours_minutes_seconds</span> <span class="nb">INT</span>
</span><span class='line'><span class="k">COMMENT</span> <span class="s1">&#39;New comment&#39;</span>
</span><span class='line'><span class="k">AFTER</span> <span class="n">severity</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm"> * Add columns, to the end of existing columns.</span>
</span><span class='line'><span class="cm"> * Use CHANGE COLUMN to rearrange if needed.</span>
</span><span class='line'><span class="cm"> */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span>
</span><span class='line'><span class="k">ADD</span> <span class="n">COLUMNS</span> <span class="p">(</span>
</span><span class='line'><span class="n">app_name</span> <span class="n">STRING</span> <span class="k">COMMENT</span> <span class="s1">&#39;New column 1&#39;</span><span class="p">,</span>
</span><span class='line'><span class="n">session_id</span> <span class="nb">INT</span> <span class="k">COMMENT</span> <span class="s1">&#39;New column 2&#39;</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm"> * Remove all the existing columns and replaces with new </span>
</span><span class='line'><span class="cm"> * specified columns.</span>
</span><span class='line'><span class="cm"> */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span>
</span><span class='line'><span class="k">REPLACE</span> <span class="n">COLUMNS</span> <span class="p">(</span>
</span><span class='line'><span class="n">app_name</span> <span class="n">STRING</span> <span class="k">COMMENT</span> <span class="s1">&#39;New column 1&#39;</span><span class="p">,</span>
</span><span class='line'><span class="n">session_id</span> <span class="nb">INT</span> <span class="k">COMMENT</span> <span class="s1">&#39;New column 2&#39;</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* </span>
</span><span class='line'><span class="cm"> * You can add table properties or set current properties,</span>
</span><span class='line'><span class="cm"> * but not remove them </span>
</span><span class='line'><span class="cm"> */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">log_messages</span>
</span><span class='line'><span class="k">SET</span> <span class="n">TBLPROPERTIES</span> <span class="p">(</span>
</span><span class='line'><span class="s1">&#39;some_key&#39;</span> <span class="o">=</span> <span class="s1">&#39;some_value&#39;</span>
</span><span class='line'><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive Tutorial (Pt. 5): HiveQL Data Definition]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/02/programming-hive-hiveql-ddl/"/>
    <updated>2015-12-02T18:32:21-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/02/programming-hive-hiveql-ddl</id>
    <content type="html"><![CDATA[<p>This post covers data definition parts of HiveQL language, mostly for creating, altering, and dropping databases and tables. Note that Hive does not support row-level inserts, updates, and deletes. However, Hive adds extensions for better performance in the context of Hadoop.</p>

<h3>Databases</h3>

<p>In Hive, the concept of a database is basically just a namespace of tables. The keyword SCHEMA can be used instead of DATABASE in all the database-related commands. If you donâ€™t specify a database, the <code>default</code> database is used.</p>

<p>Some basic HiveQL&rsquo;s database commands is shown in the following examples:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">DATABASE</span> <span class="n">college</span><span class="p">;</span>
</span><span class='line'><span class="k">CREATE</span> <span class="k">DATABASE</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">college</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">SHOW</span> <span class="n">DATABASES</span><span class="p">;</span>
</span><span class='line'><span class="k">SHOW</span> <span class="n">DATABASES</span> <span class="k">LIKE</span> <span class="s1">&#39;h.*&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">CREATE</span> <span class="k">DATABASE</span> <span class="n">college</span>
</span><span class='line'><span class="k">LOCATION</span> <span class="s1">&#39;/my/preferred/directory&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* add comments to table */</span>
</span><span class='line'><span class="k">CREATE</span> <span class="k">DATABASE</span> <span class="n">college</span> <span class="k">COMMENT</span> <span class="s1">&#39;A college admission database&#39;</span><span class="p">;</span>
</span><span class='line'><span class="cm">/* show comments */</span>
</span><span class='line'><span class="k">DESCRIBE</span> <span class="k">DATABASE</span> <span class="n">college</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* add properties */</span>
</span><span class='line'><span class="k">CREATE</span> <span class="k">DATABASE</span> <span class="n">college</span> <span class="k">WITH</span> <span class="n">DBPROPERTIES</span> <span class="p">(</span> <span class="s1">&#39;creator&#39;</span> <span class="o">=</span> <span class="s1">&#39;CD&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span> <span class="o">=</span> <span class="s1">&#39;today&#39;</span> <span class="p">);</span>
</span><span class='line'><span class="cm">/* show properties */</span>
</span><span class='line'><span class="k">DESCRIBE</span> <span class="k">DATABASE</span> <span class="n">EXTENDED</span> <span class="n">college</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* set working database */</span>
</span><span class='line'><span class="n">USE</span> <span class="n">college</span><span class="p">;</span>
</span><span class='line'><span class="cm">/* this will show tables in this database */</span>
</span><span class='line'><span class="k">SHOW</span> <span class="n">TABLES</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">DROP</span> <span class="k">DATABASE</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">college</span><span class="p">;</span>
</span><span class='line'><span class="cm">/* Drop tables if there is any table in the database */</span>
</span><span class='line'><span class="k">DROP</span> <span class="k">DATABASE</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">college</span> <span class="k">CASCADE</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* You can set additional key-value pairs in properties.</span>
</span><span class='line'><span class="cm"> * No other metadata about the database can be changed. No way to delete a DB PROPERTY.</span>
</span><span class='line'><span class="cm"> */</span>
</span><span class='line'><span class="k">ALTER</span> <span class="k">DATABASE</span> <span class="n">college</span> <span class="k">SET</span> <span class="n">DBPROPERTIES</span> <span class="p">(</span><span class="s1">&#39;editor&#39;</span> <span class="o">=</span> <span class="s1">&#39;DC&#39;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that Hive will create separate directory for each database. The exception is the <code>default</code> database, which doesn&rsquo;t have its own directory. Tables in each database will be stored in subdirectories of the database directory. The location of the database directory is specified by the property <code>hive.metastore.warehouse.dir</code>. To help us understand better, these are illustrated by the Hive CLI commands as follows:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="o">[</span>cloudera@quickstart temp<span class="o">]</span><span class="nv">$ </span>hive
</span><span class='line'>
</span><span class='line'>Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
</span><span class='line'>hive&gt; describe database default<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>default   Default Hive database   hdfs://quickstart.cloudera:8020/user/hive/warehouse public  ROLE    
</span><span class='line'>Time taken: 0.01 seconds, Fetched: <span class="m">1</span> row<span class="o">(</span>s<span class="o">)</span>
</span><span class='line'>hive&gt; describe database college<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>college       hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db  cloudera    USER    
</span><span class='line'>Time taken: 0.011 seconds, Fetched: <span class="m">1</span> row<span class="o">(</span>s<span class="o">)</span>
</span><span class='line'>
</span><span class='line'>hive&gt; SET hive.metastore.warehouse.dir<span class="p">;</span>
</span><span class='line'>hive.metastore.warehouse.dir<span class="o">=</span>/user/hive/warehouse
</span><span class='line'>
</span><span class='line'>hive&gt; dfs -ls hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db<span class="p">;</span>
</span><span class='line'>Found <span class="m">3</span> items
</span><span class='line'>drwxrwxrwx   - hive hive          <span class="m">0</span> 2015-01-21 11:29 hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/apply
</span><span class='line'>drwxrwxrwx   - hive hive          <span class="m">0</span> 2015-01-20 15:22 hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/college
</span><span class='line'>drwxrwxrwx   - hive hive          <span class="m">0</span> 2015-01-28 15:26 hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/student
</span><span class='line'>hive&gt; dfs -ls hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/student<span class="p">;</span>
</span><span class='line'>Found <span class="m">1</span> items
</span><span class='line'>-rwxrwxrwx   <span class="m">1</span> cloudera hive        <span class="m">213</span> 2015-01-20 15:22 hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/student/student.data
</span><span class='line'>hive&gt; dfs -ls hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/college<span class="p">;</span>
</span><span class='line'>Found <span class="m">1</span> items
</span><span class='line'>-rwxrwxrwx   <span class="m">1</span> cloudera hive         <span class="m">66</span> 2015-01-20 15:22 hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/college/college.data
</span></code></pre></td></tr></table></div></figure>


<p>In the output of the <code>DESCRIBE DATABASE</code> commands above, the directory location of the database is shown, with <code>hdfs</code> as URI scheme. Note that <code>hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db</code> is equivalent to <code>hdfs://user/hive/warehouse/college.db</code>, where <code>quickstart.cloudera:8020</code> is simply the master nodeâ€™s DNS name and port on Cloudera Quickstart VM. The name of the database directory is always <code>database_name.db</code>, with <code>.db</code> suffix added to database name. The three tables <code>college</code>, <code>student</code>, and <code>apply</code> in the <code>college</code> database are created as sub-directories in that <code>college.db</code> directory, as shown above. When a database is dropped, its directory is also deleted. By default, Hive will not allow you to drop a database that contains tables. The second <code>DROP DATABASE</code> command with <code>CASCADE</code> will force Hive to drop the database by dropping the tables in the database first.</p>

<p>There is no command to show the current working database. When in doubt, it is safe to use the command <code>USE database_name;</code> repeatedly since there is no nesting of databases in Hive. Otherwise, you can set a property to show the current working database in Hive CLI prompt as follows:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>hive&gt; <span class="nb">set </span>hive.cli.print.current.db<span class="o">=</span><span class="nb">true</span><span class="p">;</span>
</span><span class='line'>hive <span class="o">(</span>default<span class="o">)</span>&gt; USE college<span class="p">;</span>
</span><span class='line'>OK
</span><span class='line'>Time taken: 0.278 seconds
</span><span class='line'>hive <span class="o">(</span>college<span class="o">)</span>&gt;
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive Tutorial (Pt. 4): Data Types]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/26/programming-hive-data-types/"/>
    <updated>2015-11-26T18:01:37-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/26/programming-hive-data-types</id>
    <content type="html"><![CDATA[<p>This post covers different data types and file formats supported by Hive.</p>

<h3>Data Types</h3>

<p>The following primitive data types are supported:</p>

<ul>
<li>TINYINT: 1 byte signed integer</li>
<li>SMALLINT: 2 bytes</li>
<li>INT: 4 bytes</li>
<li>BIGINT: 8 bytes</li>
<li>BOOLEAN</li>
<li>FLOAT</li>
<li>DOUBLE</li>
<li>STRING: Single or double quotes can be used for literals.</li>
<li>TIMESTAMP: Integer, float, or string.

<ul>
<li>Integer: For seconds from Unix epoch.</li>
<li>Float: Seconds from Unix epoch and nanoseconds.</li>
<li>String: JDBC-compliant java.sql.Timestamp format convention, i.e. YYYY-MM-DD hh:mm:ss.fffffffff</li>
</ul>
</li>
<li>BINARY: array of bytes. Used to include arbitrary bytes and prevent Hive from attempting to parse them.</li>
</ul>


<p>As you can see, Hive supports most basic primitive data types conventionally found in relational databases. Moreover, it helps to remember that these data types are implemented in Java, so their behaviors will be similar to their Java counterparts.</p>

<p>NOTE: Not mentioned in the <strong>Programming Hive</strong> book, but the types <code>DECIMAL</code> and <code>DATE</code> are introduced since Hive 0.13.0.
In addition, the book claimed &ldquo;Hive does not support character arrays with maximum-allowed lengths, as is common in other SQL dialects&rdquo; but <code>VARCHAR</code> type, introduced in Hive 0.12.0, does exactly that.</p>

<p>Besides primitive data types, Hive supports the following collection data types:</p>

<ul>
<li>STRUCT: Analogous to a C <code>struct</code> or POJO (Plain Old Java Object). The elements can be accessed using the DOT (.) notation.

<ul>
<li>Example: Declaration -> <code>struct&lt;name:string,id:int&gt;</code>. Literal -> <code>struct('John',1)</code>.</li>
</ul>
</li>
<li>MAP: A collection of key-value tuples. The elements can be accessed using array notation, e.g. persons[&lsquo;John&rsquo;].

<ul>
<li>Example: Declaration -> <code>map&lt;string,int&gt;</code>. Literal -> <code>map('John',1)</code>.</li>
</ul>
</li>
<li>ARRAY: Ordered sequences of the same type. The elements can be accessed using array notation, e.g. person[2].

<ul>
<li>Example: Declaration -> <code>array&lt;string&gt;</code>. Literal -> <code>array('John','Peter')</code>.</li>
</ul>
</li>
</ul>


<p>Relational databases don&rsquo;t usually support such collection types because they tend to break <strong>normal form</strong>.
In Hive/Hadoop, sacrificing normal form is pretty common as it can give benefit of higher processing throughput, especially with large amount of data (tens of terabytes).</p>

<h3>Text File Formats</h3>

<p>Hive can use comma-separated values (CSV) or tab-separated values (TSV) text file format. A Hive table declaration with all row format specified (with default values, however) looks like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">employees</span> <span class="p">(</span>
</span><span class='line'>  <span class="n">name</span>         <span class="n">STRING</span><span class="p">,</span>
</span><span class='line'>  <span class="n">salary</span>       <span class="nb">FLOAT</span><span class="p">,</span>
</span><span class='line'>  <span class="n">subordinates</span> <span class="nb">ARRAY</span><span class="o">&lt;</span><span class="n">STRING</span><span class="o">&gt;</span><span class="p">,</span>
</span><span class='line'>  <span class="n">deductions</span>   <span class="k">MAP</span><span class="o">&lt;</span><span class="n">STRING</span><span class="p">,</span> <span class="nb">FLOAT</span><span class="o">&gt;</span><span class="p">,</span>
</span><span class='line'>  <span class="n">address</span>      <span class="n">STRUCT</span><span class="o">&lt;</span><span class="n">street</span><span class="p">:</span><span class="n">STRING</span><span class="p">,</span> <span class="n">city</span><span class="p">:</span><span class="n">STRING</span><span class="p">,</span> <span class="k">state</span><span class="p">:</span><span class="n">STRING</span><span class="p">,</span> <span class="n">zip</span><span class="p">:</span><span class="nb">INT</span><span class="o">&gt;</span>
</span><span class='line'><span class="p">)</span>
</span><span class='line'><span class="k">ROW</span> <span class="n">FORMAT</span> <span class="n">DELIMITED</span>
</span><span class='line'><span class="n">FIELDS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">&#39;\001&#39;</span>
</span><span class='line'><span class="n">COLLECTION</span> <span class="n">ITEMS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">&#39;\002&#39;</span>
</span><span class='line'><span class="k">MAP</span> <span class="n">KEYS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">&#39;\003&#39;</span>
</span><span class='line'><span class="n">LINES</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">&#39;\n&#39;</span>
</span><span class='line'><span class="n">STORED</span> <span class="k">AS</span> <span class="n">TEXTFILE</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Schema on Read</h3>

<p>Different from databases, Hive has no control over the underlying storage: for example, you can modify files on HDFS that Hive will query. Hive tries its best to read the data and match the schema. If the file content does not match the schema such as non-numeric strings found when numbers expected, you may get null values.</p>

<h3>Additional References</h3>

<p>As of November 2015, the <strong>Programming Hive (2nd edition)</strong> book uses slightly a outdated Hive version 0.9.0 (Chapter 2, Installing Hive). Information in the following links are used when writing this post:</p>

<ol>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/Tutorial">https://cwiki.apache.org/confluence/display/Hive/Tutorial</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive Tutorial (Pt. 3): Runtime Modes]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/24/programming-hive-getting-started/"/>
    <updated>2015-11-24T18:24:30-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/24/programming-hive-getting-started</id>
    <content type="html"><![CDATA[<p>Following up on <a href="http://tdongsi.github.io/blog/2015/11/23/programming-hive-hive-cli/">Hive CLI</a>, this post covers some lower-level details of Hive such as Hadoop runtime modes and metastore.</p>

<h3>Runtime Modes</h3>

<p>There are different runtime modes for Hadoop.
Because Hive uses Hadoop jobs for most of its work, its behavior is dependent on Hadoop runtime mode that you are using.
However, even in distributed mode, Hive can decide on a per-query basis if it can perform the query using just local mode to provide better turnaround.</p>

<table>
<thead>
<tr>
<th> Local Mode </th>
<th> Distributed Mode </th>
<th> Pseudodistributed Mode </th>
</tr>
</thead>
<tbody>
<tr>
<td> Filesystem references use local filesystem. </td>
<td> Filesystem references use HDFS. </td>
<td> Similar to distributed mode. </td>
</tr>
<tr>
<td> MapReduce tasks in same process. </td>
<td>  MapReduce tasks in separate <br>processes, managed by JobTracker service. </td>
<td> Similar to distributed mode.</td>
</tr>
<tr>
<td> Default mode. </td>
<td> Usually configured for server clusters. </td>
<td> Like a cluster of one node.</td>
</tr>
</tbody>
</table>


<p><br></p>

<p>Pseudodistributed mode is mainly for developers working on personal machines or VM&rsquo;s when testing their applications since local mode doesnâ€™t fully reflect the behavior of a real cluster. Changes to configuration are done by editing the <code>hive-site.xml</code> file in <code>$HIVE_HOME/conf</code> folder (e.g., <code>/usr/lib/hive/conf</code> on Cloudera VM). Create one if it doesnâ€™t already exist.</p>

<h3>Metastore Using JDBC</h3>

<p>Hive requires only one extra component that Hadoop does not already have; the metastore component.
The metastore stores metadata such as table schema and partition information that you specify when you run commands such as <code>create table x...</code>, or <code>alter table y...</code>, etc.
Any JDBC-compliant database can be used for the metastore. In practice, most installations of Hive use MySQL.
In <code>hive-site.xml</code> file, the metastore database configuration looks like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>  <span class="nt">&lt;property&gt;</span>
</span><span class='line'>    <span class="nt">&lt;name&gt;</span>javax.jdo.option.ConnectionURL<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>    <span class="nt">&lt;value&gt;</span>jdbc:mysql://127.0.0.1/metastore?createDatabaseIfNotExist=true<span class="nt">&lt;/value&gt;</span>
</span><span class='line'>    <span class="nt">&lt;description&gt;</span>JDBC connect string for a JDBC metastore<span class="nt">&lt;/description&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/property&gt;</span>
</span><span class='line'>
</span><span class='line'>  <span class="nt">&lt;property&gt;</span>
</span><span class='line'>    <span class="nt">&lt;name&gt;</span>javax.jdo.option.ConnectionDriverName<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>    <span class="nt">&lt;value&gt;</span>com.mysql.jdbc.Driver<span class="nt">&lt;/value&gt;</span>
</span><span class='line'>    <span class="nt">&lt;description&gt;</span>Driver class name for a JDBC metastore<span class="nt">&lt;/description&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/property&gt;</span>
</span><span class='line'>
</span><span class='line'>  <span class="nt">&lt;property&gt;</span>
</span><span class='line'>    <span class="nt">&lt;name&gt;</span>javax.jdo.option.ConnectionUserName<span class="nt">&lt;/name&gt;</span>
</span><span class='line'>    <span class="nt">&lt;value&gt;</span>hive<span class="nt">&lt;/value&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/property&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>The information stored in metastore is typically much smaller than the data stored in Hive.
Therefore, you typically donâ€™t need a powerful dedicated database server for the metastore.
However since it represents a Single Point of Failure (SPOF), it is strongly recommended that you replicate and back up this database using the best practices like any other database instances.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive Tutorial (Pt. 2): Hive CLI]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/23/programming-hive-hive-cli/"/>
    <updated>2015-11-23T19:47:23-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/23/programming-hive-hive-cli</id>
    <content type="html"><![CDATA[<p>This post covers how to get started with Hive and some basics of Hive, including its command-line interface (CLI).</p>

<h3>Starting Hive with Cloudera Quickstart VM</h3>

<p>On Cloudera Quickstart VM, the cores of its Hive distribution, including files such as <code>hive-exec*.jar</code> and <code>hive-metastore*.jar</code>, can be found in <code>/usr/lib/hive/lib</code>.
The Hive executables can be found in <code>/usr/lib/hive/bin</code>. Running <code>hive</code> without any parameter will start Hive&rsquo;s CLI.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hive
</span><span class='line'>
</span><span class='line'>Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
</span><span class='line'>hive&gt; CREATE TABLE x (a INT);
</span><span class='line'>OK
</span><span class='line'>Time taken: 3.032 seconds
</span><span class='line'>hive&gt; SELECT * FROM x;
</span><span class='line'>OK
</span><span class='line'>Time taken: 0.465 seconds
</span><span class='line'>hive&gt; SELECT *        
</span><span class='line'>    &gt; FROM x;
</span><span class='line'>OK
</span><span class='line'>Time taken: 0.049 seconds
</span><span class='line'>hive&gt; DROP TABLE x;
</span><span class='line'>OK
</span><span class='line'>Time taken: 0.348 seconds
</span><span class='line'>hive&gt; exit;</span></code></pre></td></tr></table></div></figure>


<h3>Hive services</h3>

<p>The <code>hive</code> shell command is actually a wrapper to multiple Hive services, including the CLI.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hive --help
</span><span class='line'>Usage ./hive &lt;parameters&gt; --service serviceName &lt;service parameters&gt;
</span><span class='line'>Service List: beeline cli help hiveserver2 hiveserver hwi jar lineage metastore metatool orcfiledump rcfilecat schemaTool version 
</span><span class='line'>Parameters parsed:
</span><span class='line'>  --auxpath : Auxillary jars 
</span><span class='line'>  --config : Hive configuration directory
</span><span class='line'>  --service : Starts specific service/component. cli is default
</span><span class='line'>Parameters used:
</span><span class='line'>  HADOOP_HOME or HADOOP_PREFIX : Hadoop install directory
</span><span class='line'>  HIVE_OPT : Hive options
</span><span class='line'>For help on a particular service:
</span><span class='line'>  ./hive --service serviceName --help
</span><span class='line'>Debug help:  ./hive --debug --help</span></code></pre></td></tr></table></div></figure>


<p>Note the list of services following the line &ldquo;Service List&rdquo;.
There are several services available, most notably <strong>cli, hwi, jar, metastore</strong>.
You can use <code>--service name</code> option to invoke a service.
CLI is the default service, not specifying any service in <code>hive</code> command will run CLI service, as shown in &ldquo;Starting Hive&rdquo; section above.</p>

<p>For example, to run <a href="https://cwiki.apache.org/confluence/display/Hive/HiveWebInterface">Hive Web Interface</a>, run the service <strong>hwi</strong>. On Cloudera Quickstart VM, you might encounter this error:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hive --service hwi
</span><span class='line'>ls: cannot access /usr/lib/hive/lib/hive-hwi-*.war: No such file or directory
</span><span class='line'>15/11/23 20:22:50 INFO hwi.HWIServer: HWI is starting up
</span><span class='line'>15/11/23 20:22:50 FATAL hwi.HWIServer: HWI WAR file not found at /usr/lib/hive/usr/lib/hive/lib/hive-hwi-0.8.1-cdh4.0.0.jar</span></code></pre></td></tr></table></div></figure>


<p>To fix that error, edit the config file <code>hive-site.xml</code> in the <code>config</code> folder (e.g., <code>/usr/lib/hive/conf/hive-site.xml</code> on Cloudera VM) to point to the right location of HWI&rsquo;s <code>war</code> file.
On Cloudera Quickstart VM, the <code>war</code> file property block should look like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>...
</span><span class='line'> &lt;property&gt;
</span><span class='line'>    &lt;name&gt;hive.hwi.war.file&lt;/name&gt;
</span><span class='line'>    &lt;value&gt;/lib/hive-hwi.jar&lt;/value&gt;
</span><span class='line'>    &lt;description&gt;This is the WAR file with the jsp content for Hive Web Interface&lt;/description&gt;
</span><span class='line'>  &lt;/property&gt;
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>Running the <strong>hwi</strong> service again using <code>hive</code> command should work. In order to access the Hive Web Interface, go to <code>[Hive Server Address]</code>:9999/hwi on your web browser.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hive --service hwi
</span><span class='line'>ls: cannot access /usr/lib/hive/lib/hive-hwi-*.war: No such file or directory
</span><span class='line'>15/11/23 20:31:27 INFO hwi.HWIServer: HWI is starting up
</span><span class='line'>15/11/23 20:31:27 INFO mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
</span><span class='line'>15/11/23 20:31:27 INFO mortbay.log: jetty-6.1.26.cloudera.4
</span><span class='line'>15/11/23 20:31:27 INFO mortbay.log: Extract /usr/lib/hive/lib/hive-hwi.jar to /tmp/Jetty_0_0_0_0_9999_hive.hwi.0.13.1.cdh5.3.0.jar__hwi__.lcik1p/webapp
</span><span class='line'>15/11/23 20:31:28 INFO mortbay.log: Started SocketConnector@0.0.0.0:9999</span></code></pre></td></tr></table></div></figure>


<h3>Hive CLI</h3>

<p>Available options for Hive CLI can be displayed as follows:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hive --help --service cli
</span><span class='line'>usage: hive
</span><span class='line'> -d,--define &lt;key=value&gt;          Variable subsitution to apply to hive
</span><span class='line'>                                  commands. e.g. -d A=B or --define A=B
</span><span class='line'>    --database &lt;databasename&gt;     Specify the database to use
</span><span class='line'> -e &lt;quoted-query-string&gt;         SQL from command line
</span><span class='line'> -f &lt;filename&gt;                    SQL from files
</span><span class='line'> -H,--help                        Print help information
</span><span class='line'> -h &lt;hostname&gt;                    connecting to Hive Server on remote host
</span><span class='line'>    --hiveconf &lt;property=value&gt;   Use value for given property
</span><span class='line'>    --hivevar &lt;key=value&gt;         Variable subsitution to apply to hive
</span><span class='line'>                                  commands. e.g. --hivevar A=B
</span><span class='line'> -i &lt;filename&gt;                    Initialization SQL file
</span><span class='line'> -p &lt;port&gt;                        connecting to Hive Server on port number
</span><span class='line'> -S,--silent                      Silent mode in interactive shell
</span><span class='line'> -v,--verbose                     Verbose mode (echo executed SQL to the
</span><span class='line'>                                  console)</span></code></pre></td></tr></table></div></figure>


<h4>Hive variables and properties</h4>

<p>The <code>--define key=value</code> option is equivalent to the <code>--hivevar key=value</code> option. Both let you define custom variables in the <code>hivevar</code> namespace, separate from three other built-in namespaces, <code>hiveconf</code>, <code>system</code>, and <code>env</code>. By convention, the Hive namespaces for variables and properties are as follows:</p>

<ol>
<li>hivevar: user-defined custom variables.</li>
<li>hiveconf: Hive-specific configuration properties.</li>
<li>system: Java configuration properties.</li>
<li>env: (Read-only) environment variables by shell environment (e.g., bash).</li>
</ol>


<p>Inside Hive CLI, the command <code>SET</code> is used to display and change variables. For example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hive
</span><span class='line'>
</span><span class='line'>Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
</span><span class='line'>hive&gt; set env:HOME; &lt;-- display HOME variable in env namespace
</span><span class='line'>env:HOME=/home/cloudera
</span><span class='line'>hive&gt; set; &lt;-- display all variables
</span><span class='line'>...
</span><span class='line'>hive&gt; set -v; &lt;-- display even more variables
</span><span class='line'>...
</span><span class='line'>hive&gt; set hivevar:foo=bar; &lt;-- set foo variable in hivevar namespace to bar</span></code></pre></td></tr></table></div></figure>


<h4><code>-e query_string</code> and <code>-S</code> options</h4>

<p><code>-e</code> option allows you to execute a list of semicolon-separated queries as an input string. <code>-S</code> option for silent mode will remove non-essential output. For example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ hive -e "SELECT * FROM mytable LIMIT 3";
</span><span class='line'>OK
</span><span class='line'>name1 10
</span><span class='line'>name2 20
</span><span class='line'>name3 30
</span><span class='line'>Time taken: 4.955 seconds</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ hive -S -e "select * FROM mytable LIMIT 3"
</span><span class='line'>name1 10
</span><span class='line'>name2 20
</span><span class='line'>name3 30</span></code></pre></td></tr></table></div></figure>


<p><strong>Tip</strong>: To quickly search for the full name of a property that you only remember part of its name, pipe the Hive&rsquo;s <code>SET</code> command output to grep. For example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[cloudera@quickstart temp]$ hive -S -e "set" | grep warehouse
</span><span class='line'>hive.metastore.warehouse.dir=/user/hive/warehouse
</span><span class='line'>hive.warehouse.subdir.inherit.perms=true</span></code></pre></td></tr></table></div></figure>


<h4><code>-f script_file</code> option</h4>

<p>This option allows you to execute one or more queries contained in a script file. If you are already within the Hive CLI, you can use the <code>SOURCE</code> command to execute a script file. For example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ cat /path/to/file/withqueries.hql
</span><span class='line'>SELECT x.* FROM src x;
</span><span class='line'>$ hive
</span><span class='line'>hive&gt; source /path/to/file/withqueries.hql;</span></code></pre></td></tr></table></div></figure>


<p></p>

<h4><code>-i filename</code> option</h4>

<p>This option lets you specify an initialization file with a list of commands for the CLI to run when it starts. The default initialization file is the file <code>$HOME/.hiverc</code> if it exists.</p>

<h4>Tips</h4>

<ul>
<li>To print column headers (disabled by default), set the hiveconf property <code>hive.cli.print.header</code> to true: <code>set hive.cli.print.header=true;</code>.</li>
<li>Hive has a command history, saved into a file <code>$HOME/.hivehistory</code>. Use the up and down arrow keys to scroll through previous commands.</li>
<li>To run HDFS commands from within Hive CLI, drop the hdfs. For example:</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hive&gt; dfs -ls input; 
</span><span class='line'>Found 1 items
</span><span class='line'>-rw-r--r--   1 cloudera cloudera         31 2015-01-15 18:04 input/wordcount.txt</span></code></pre></td></tr></table></div></figure>


<ul>
<li>To run the bash shell commands from within Hive CLI, prefix <code>!</code> before the bash commands and terminate the line with a semicolon (;). Note that interactive commands, shell pipes <code>|</code>, and file globs <code>*</code> will not work. Example:</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hive&gt; !pwd;
</span><span class='line'>hive&gt; /home/cloudera/temp</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Set the property <code>set hive.exec.mode.local.auto=true;</code> to use local mode more aggressively and gain performance in Hive queries, especially when working with small data sets.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive Tutorial (Pt. 1): Introduction]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/22/programming-hive-chapter-1/"/>
    <updated>2015-11-22T17:22:51-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/22/programming-hive-chapter-1</id>
    <content type="html"><![CDATA[<!---
"Chapter 1: Introduction" of the "Programming Hive" book.
-->


<p>This post is the first of many Hive tutorial posts. Most of these posts are based on the <strong>Programming Hive</strong> book, with some observations from my own experience with <a href="http://tdongsi.github.io/blog/2015/11/20/wordcount-sample-in-cloudera-quickstart-vm/">Cloudera Quickstart VM</a>.</p>

<p><img class="center" src="http://tdongsi.github.io/images/hive/cat.gif" title="Cover" ></p>

<h3>Introduction</h3>

<p>Hive provides a SQL dialect, called Hive Query Language (HiveQL or HQL) for querying data stored in a Hadoop cluster. SQL knowledge is widespread for a reason; it&rsquo;s an effective, reasonably intuitive model for organizing and using data. Therefore, Hive helps lower the barrier, making transition to Hadoop from traditional relational databases easier for database users such as business analysts.</p>

<p>Note that Hive is more suited for data warehouse applications, where data is relatively static and fast response time is not required. For example, a simple query such as <code>select count(*) from my_table</code> can take several seconds for a very small table (mostly due to startup overhead for MapReduce jobs). Hive is a heavily batch-oriented system: in addition to large startup overheads, it neither provides record-level update, insert, or delete nor transactions. In short, Hive is not a full database (hint: check HBase).</p>

<p>HiveQL does not conform to the ANSI SQL standard (not many do), but it is quite close to MySQL dialect.</p>

<h3>Hive within the Hadoop Ecosystem</h3>

<p>A basic understanding of Hadoop and MapReduce can help you to understand and appreciate how Hive works. Simple examples such as WordCount in my <a href="http://tdongsi.github.io/blog/2015/11/21/explaining-wordcount-example/">last post</a> can be very involving when using the Hadoop Java API. The API requires Java developers to manage many low-level details, repetitive wiring to/from Mappers and Reducers. The WordCount example&rsquo;s Java implementation can be found <a href="https://wiki.apache.org/hadoop/WordCount">here</a>.</p>

<p>Hive not only eliminates advanced, sometimes repetitive Java coding but also provides a familiar interface to those who know SQL. Hive lets you complete a lot of work with relatively little effort. For example, the same WordCount example in HiveQL can be as simple as:</p>

<figure class='code'><figcaption><span>WordCount example in HiveQL</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">docs</span> <span class="p">(</span><span class="n">line</span> <span class="n">STRING</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="cm">/* Load text files into TABLE docs: each line as a row */</span>
</span><span class='line'><span class="k">LOAD</span> <span class="k">DATA</span> <span class="n">INPATH</span> <span class="s1">&#39;wordcount.txt&#39;</span> <span class="n">OVERWRITE</span> <span class="k">INTO</span> <span class="k">TABLE</span> <span class="n">docs</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">word_counts</span> <span class="k">AS</span>
</span><span class='line'><span class="k">SELECT</span> <span class="n">word</span><span class="p">,</span> <span class="k">count</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">AS</span> <span class="k">count</span>
</span><span class='line'><span class="k">FROM</span>
</span><span class='line'>   <span class="c1">-- explode will return rows of tokens</span>
</span><span class='line'>  <span class="p">(</span><span class="k">SELECT</span> <span class="n">explode</span><span class="p">(</span><span class="n">split</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="s1">&#39;\s&#39;</span><span class="p">))</span> <span class="k">AS</span> <span class="n">word</span>
</span><span class='line'>   <span class="k">FROM</span> <span class="n">docs</span><span class="p">)</span> <span class="n">w</span>
</span><span class='line'><span class="k">GROUP</span> <span class="k">BY</span> <span class="n">word</span>
</span><span class='line'><span class="k">ORDER</span> <span class="k">BY</span> <span class="n">word</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>




<!--
In the remaining sections of Chapter 1, the authors also discuss various related Hadoop projects such as Pig, Hue, HBase, Spark, Storm, Kafka, etc.
-->

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Overview of MapReduce: Explaining WordCount Example]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/21/explaining-wordcount-example/"/>
    <updated>2015-11-21T02:37:20-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/21/explaining-wordcount-example</id>
    <content type="html"><![CDATA[<p>MapReduce is a programming framework that decomposes large data processing jobs into individual tasks that can be executed in parallel across a cluster of servers. The name MapReduce comes from the fact that there are two fundamental data transformation operations: <em>map</em> and <em>reduce</em>. These MapReduce operations would be more clear if we walk through a simple example, such as WordCount in my last <a href="http://tdongsi.github.io/blog/2015/11/20/wordcount-sample-in-cloudera-quickstart-vm/">post</a>. The process flow of WordCount example is shown below:</p>

<!---
(from [here](https://www.safaribooksonline.com/library/view/programming-hive/9781449326944/ch01.html)):

![Process Flow of WordCount Example](https://www.safaribooksonline.com/library/view/programming-hive/9781449326944/httpatomoreillycomsourceoreillyimages1321235.png)
-->


<p><img class="center" src="http://tdongsi.github.io/images/hive/wordcount.png" title="Process Flow of WordCount Example" ></p>

<p>The fundamental data structure for input and output in MapReduce is the key-value pair. When starting the WordCount example, the Mapper processes the input documents line by line, with the key being the character offset into the document and the value being the line of text.</p>

<p>A <strong>map</strong> operation converts input key-values pairs from one form to another. In WordCount, the key (character offset) is discarded but it may not be always the case. The value (the line of text) is normalized (e.g., converted to lower case) and tokenized into words, using some technique such as splitting on whitespace. In this way, â€œHADOOPâ€ and â€œHadoopâ€ will be counted as the same word. For each word in the line, the Mapper outputs a key-value pair, with the word as the key and the number 1 as the value.</p>

<p>Next is the <strong>shuffling</strong> phase. Hadoop sorts the key-value pairs by key and it â€œshufflesâ€ all pairs with the same key to the same Reducer. In the WordCount example, each Reducer may get some range of keys, i.e. a group of words/tokens.</p>

<p>A <strong>reduce</strong> operation converts the collection for each key in input key-value pairs to another smaller collection (or a value when the collection has a single element). In WordCount, the input key is one of the words found and the value will be a collection of all the counts for that word. The Reducers add all the counts in the value collection and the final output are key-value pairs consisting of each word and the count for that word.</p>

<p>The three phases of processing in WordCount example with their input and output key-value pairs are summarized in the table below. Note that the input and output key-value pairs can be very different for each phase, not only in value but also in type.</p>

<table>
<thead>
<tr>
<th> </th>
<th> Mapper </th>
<th> Shuffling </th>
<th> Reducer </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>Input</strong> </td>
<td> <code>(offset, text_line)</code> </td>
<td> Multiple <code>(token,1)</code> </td>
<td> <code>(token,[1,1,1,...])</code> </td>
</tr>
<tr>
<td> <strong>Processing</strong> </td>
<td> Discard the key <code>offset</code>. <br> Normalize and tokenize <code>text_line</code>.</td>
<td> Move <code>(token,1)</code>with same <code>token</code> to same Reducer </td>
<td> Sum all elements in collection </td>
</tr>
<tr>
<td> <strong>Output</strong> </td>
<td> Multiple <code>(token,1)</code> </td>
<td> Sorted <code>(token,[1,1,1,...])</code> </td>
<td> <code>(token, count)</code> </td>
</tr>
</tbody>
</table>


<p><br></p>
]]></content>
  </entry>
  
</feed>
