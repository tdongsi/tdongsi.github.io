<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Sql | Personal Programming Notes]]></title>
  <link href="http://tdongsi.github.io/blog/categories/sql/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/"/>
  <updated>2016-05-08T07:46:33-07:00</updated>
  <id>http://tdongsi.github.io/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[(Pt. 7) Extending for Data Parity Checks]]></title>
    <link href="http://tdongsi.github.io/blog/2016/04/17/sql-unit-data-parity/"/>
    <updated>2016-04-17T16:39:19-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/04/17/sql-unit-data-parity</id>
    <content type="html"><![CDATA[<p>Navigation: <a href="/blog/2016/03/16/sql-unit-overview/">Overview</a>,
<a href="/blog/2016/03/20/sql-unit-functional-tests/">Pt 1</a>,
<a href="/blog/2016/03/28/sql-unit-test-runner/">Pt 2</a>,
<a href="/blog/2016/04/10/sql-unit-incremental-data-update/">Pt 3</a>,
<a href="/blog/2016/04/12/sql-unit-testing/">Pt 4</a>,
<a href="/blog/2016/04/14/sql-unit-vs-functional/">Pt 5</a>,
<a href="/blog/2016/04/16/sql-unit-extension/">Pt 6</a>.</p>

<p>As an example to discussion in <a href="/blog/2016/04/16/sql-unit-extension/">this post</a>, I will discuss how I recently added a new functionality to handle a new kind of tests.</p>

<h3>Background of data parity checks</h3>

<p>Recently, I had to do lots of data parity checks to verify changes in Extract-Load processes (i.e., EL with no Transform).
In those data parity checks, we want to make sure data in some columns of two tables (i.e., two projections) must be the same.
In other words, we want to verify if the two following SQL queries return completely matching rows and columns:</p>

<pre><code class="plain Data parity checks">select col1, col2 from old_table_name

matches

select col3, col4 from new_table_name
</code></pre>

<p>The straight-forward test would be to get all the rows and columns of those two projections, and perform equality check one by one.
It would be very time-consuming to write and execute such test cases in Java and TestNG.
Even when the query returns can be managed within the memory limit, it is still time-consuming to do data transfer for the two query returns, join the columns to prepare for comparison row by row.
Moreover, note that these expensive operations are carried out on the client side, our computers.</p>

<p>The more efficient way for this data parity check is to use these two SQL test queries in these test blocks (read <a href="/blog/2016/03/28/sql-unit-test-runner/">this post</a> for more introduction):</p>

<pre><code class="plain Test blocks for data parity check">/* @Test
{
    "name" : "parity_check",
    "query" : "select col1, col2 from old_table_name
                EXCEPT
                select col3, col4 from new_table_name
                limit 20",
    "expected" : ""
}
*/

/* @Test
{
    "name" : "parity_check_reverse",
    "query" : "select col3, col4 from new_table_name
                EXCEPT
                select col1, col2 from old_table_name
                limit 20",
    "expected" : ""
}
*/
</code></pre>

<p>The two SQL test queries is based on the following <a href="https://en.wikipedia.org/wiki/Algebra_of_sets">set theory identities</a>:</p>

<p><span class="math display">\[A = B \Leftrightarrow A \subseteq B \mbox{ and } B \subseteq A\]</span></p>




<p><span class="math display">\[A \subseteq B \Leftrightarrow A \setminus B = \varnothing\]</span></p>


<p>If the query <code>Table_A EXCEPT Table_B</code> returns nothing, it indicates that data in <code>Table_A</code> is a subset of data in <code>Table_B</code>.
Similarly for <code>Table_B EXCEPT Table_A</code> query.
Therefore, if two test cases pass, it means that the data in <code>Table_A</code> is equal to the data in <code>Table_B</code>.</p>

<p>Using these two queries, we shift most of computing works (<code>EXCEPT</code> operations) to the database server side, which is faster since the server cluster is usually much more powerful than our computers.
Moreover, in most of the cases when the tests pass, the data transfer would be minimal (zero row).
In short, these <code>EXCEPT</code>-based checks will save us lots of computation time and data transfer time.</p>

<p>The <code>limit 20</code> clause is also for minimizing data transfer and local computing works.
When the expected return of the SQL query is nothing (i.e., <code>"expected" : ""</code>), we should always add LIMIT clause to the query.
This will save some waiting time and make our log files cleaner when something went wrong and caused the test to fail.
For example, using the above test blocks, if there are one million additional, erroneous rows of data in <code>new_table_name</code> for some reason, the test case &ldquo;parity_check_reverse&rdquo; will fail.
However, instead of transferring one million rows, only 20 of those will be sent to the local host (test machine), thanks to the <code>LIMIT</code> clauses.
In addition, the log file of the Test Runner will NOT be flooded with one million rows of erroneous data while 20 sample rows are probably enough to investigate what happened.</p>

<h3>Extending SQL Test Runner</h3>

<p>If we only need to do a few simple data parity checks, a few (&ldquo;name&rdquo;, &ldquo;query&rdquo;, &ldquo;expected&rdquo;) test blocks as shown above will suffice.
However, there were tens of table pairs to be checked and many tables are really wide, about 100 columns.
For wide tables, for easy investigation if data parity checks fail, we check data in group of 6-10 columns.
Writing test blocks like above can become a daunting task, and such test blocks for wide tables can become hard to read.
Therefore, I create a new test block construct that is more friendly to write and read, as shown below.</p>

<pre><code class="plain New test block">/* @Test
{
    "name" : "parity_check",
    "query" : "select col1, col2 from old_table_name",
    "equal" : "select col3, col4 from new_table_name"
}
*/
</code></pre>

<p>Under the hood, this test block should be equivalent to the two test blocks shown in the last section.
That is, based on the two projection queries found in &ldquo;query&rdquo; and &ldquo;equal&rdquo; clauses, the SQL Test Runner will generate two test blocks with <code>EXCEPT</code>-based test queries as shown above.</p>

<p>Implementation of this new feature is summarized in the following steps:</p>

<ol>
<li>Define new JSON block.</li>
<li>Define new POJO (named <code>NameQueryEqual</code>) that maps to new JSON block.</li>
<li>Create a new class (named <code>NewTestHandler</code> for easy reference) that implements TestStrategy interface to handle the new POJO. Specifically:

<ol>
<li>From <code>NameQueryEqual</code> POJO, generate two <code>NameQueryExpected</code> POJOs with relevant queries (using <code>EXCEPT</code> operations).</li>
<li>Reuse the old TestHandler class to process two <code>NameQueryExpected</code> POJOs.</li>
</ol>
</li>
<li>Create a new test runner that extends the <code>BaseTestRunner</code> and uses the new <code>TestStrategy</code>.</li>
</ol>


<p>For step 1, the new JSON block is already defined as above.
From JSON, the corresponding POJO in step 2 can be easily defined:</p>

<pre><code class="java">/**
 * POJO for JSON test block comparing two projections
 * 
 * @author tdongsi
 */
public class NameQueryEqual {
    // Test name.
    public String name;
    // File lists to run
    public List&lt;String&gt; file;
    // Test query in SQL
    public String query;
    // Equivalent query in SQL
    public String equal;
}
</code></pre>

<p>For step 3, as emphasized in the <a href="/2016/04/16/sql-unit-extension/">last post</a>, we should NOT modify the old test runner to handle this new POJO.
Instead, we should create a new class <code>NewTestHandler</code> that implements TestStrategy interface to handle the new POJO and create a new test runner that uses the new TestStrategy (Strategy pattern).</p>

<p>The implementation of the new test block handler is NOT really complex, thanks to modular design of SQL Test Runner.
We only need to extract two projections from <code>NameQueryEqual</code>&rsquo;s attributes, generate two <code>EXCEPT</code>-based queries for those two projections (with <code>LIMIT</code> clauses), and create two  <code>NameQueryExpected</code> POJOs for those test queries.
Since we already have a TestHanlder class that can run and verify those <code>NameQueryExpected</code> objects, we only need to include a TestHandler object into the <code>NewTestHandler</code> class and delegate handling <code>NameQueryExpected</code> objects to it.
Note that this approach is recommended over subclassing <code>TestHandler</code> to include new code for handling the new <code>NameQueryEqual</code> POJO (i.e., &ldquo;composition over inheritance&rdquo;).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[(Pt. 6) Extending SQL Test Runner]]></title>
    <link href="http://tdongsi.github.io/blog/2016/04/16/sql-unit-extension/"/>
    <updated>2016-04-16T17:49:34-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/04/16/sql-unit-extension</id>
    <content type="html"><![CDATA[<p>Navigation: <a href="/blog/2016/03/16/sql-unit-overview/">Overview</a>,
<a href="/blog/2016/03/20/sql-unit-functional-tests/">Pt 1</a>,
<a href="/blog/2016/03/28/sql-unit-test-runner/">Pt 2</a>,
<a href="/blog/2016/04/10/sql-unit-incremental-data-update/">Pt 3</a>,
<a href="/blog/2016/04/12/sql-unit-testing/">Pt 4</a>,
<a href="/blog/2016/04/14/sql-unit-vs-functional/">Pt 5</a>.</p>

<p>In this post, I will discuss the design of the SQL Test Runner.
From that, I explain how to easily extend the Test Runner to add new capability for new testing needs.
In the <a href="http://localhost:4000/blog/2016/04/17/sql-unit-data-parity/">next post</a>, I will give an example on how I added a new functionality to handle a new kind of tests.</p>

<h3>Design Overview of SQL Test Runner</h3>

<p>When designing the SQL Test Runner, the following requirements should be taken into account:</p>

<p>1) Test frameworks should be closed to modifications.
If we have added a few hundred test cases that are running fine in the current test suite, we don&rsquo;t want them to suddenly fail just because a new feature must be added into the test framework.
That could be confusing and counter-productive for anyone who are using it.</p>

<p>2) At the same time, the test framework should be open to extension: ability to add new capability, to address new testing needs.
SQL Unit Testing in ETL context is a pretty new area for us.
Therefore, while the current SQL Unit Test framework appears adequate for most testing now, it must be able to support any new testing needs should they arise in the future.
The test framework should be flexible enough to add new capability to support different kinds of ETLs.</p>

<p>These two are also known as <a href="https://en.wikipedia.org/wiki/Open/closed_principle">Open/Closed principle</a>.
Besides that principle, SQL Test Runner codes also use <a href="https://en.wikipedia.org/wiki/Template_method_pattern"><strong>Template Method</strong></a> and <a href="https://en.wikipedia.org/wiki/Strategy_pattern"><strong>Strategy</strong></a> design patterns.
Knowing these design patterns will make it easier to understand the overall code structure and package organization of SQL Test Runner.</p>

<p>At the top level, there is a TestRunner interface that any SQL Test Runner class should implement.
For convenience, an abstract class BaseTestRunner is provided as a template with simple processing flow and naive parsing provided in its <code>runScript</code> method, as shown below (Template Method design pattern).
The template method <code>runScript</code> extracts the SQL statements and test blocks (<code>/* @Test ... */</code> blocks), then delegates to <code>codeHandler</code> and <code>testHandler</code> to process them, respectively.</p>

<pre><code class="java Template Method for running test scripts in BaseTestRunner">private CodeStrategy codeHandler;
private TestStrategy testHandler;
private JdbcConnection connection;

@Override
public final void runScript(String filePath) throws IOException, SQLException {
    SoftAssert sAssert = new SoftAssert();

    // Read in the SQL script
    String content = SqlTestUtility.readFile(filePath);

    // Remove comments
    String sqlCode = TestBlockUtility.removeComments(content);

    Matcher m = TestBlockUtility.testBlockRegex.matcher(sqlCode);
    int startIndex = 0;
    while (m.find()) {

        String currentSql = sqlCode.substring(startIndex, m.start());
        if ( currentSql.trim().length() &gt; 0 )
            codeHandler.runSqlCode(currentSql, connection);;

        testHandler.runTest( m.group(), connection, sAssert );

        startIndex = m.end();
    }

    codeHandler.runSqlCode(sqlCode.substring(startIndex), connection );
    sAssert.assertAll();
}
</code></pre>

<p>In the <code>BaseTestRunner</code> class, the <code>codeHandler</code> attribute can be any object that implements <code>CodeStrategy</code> interface (Strategy design pattern).
It will handle executing SQL statements that are found in the unit test scripts, such as the first two <code>INSERT</code> statements in the example script below.
Similarly, the <code>testHandler</code> attribute in the <code>BaseTestRunner</code> can be any object that implements <code>TestStrategy</code> interface.
It will handle test blocks (<code>/* @Test ... */</code> blocks) such as the two test blocks in the example script below.
There are many different ways to process a test block: the first test block might be executed using a Vertica-specific interface, while the second one is executed with a generic JDBC interface.
By using the Strategy design pattern, if there is a necessary change in executing SQL code or test blocks, the test framework is flexible enough to easily integrate that change.</p>

<pre><code class="sql Example unit test script">-- This will be handled by some CodeStrategy class
INSERT INTO stg_company_id (company_id,last_modify_date,region_id) 
VALUES (123,current_timestamp-19,'US');

INSERT INTO stg_company_contact (company_id,master_email,last_modify_date) 
VALUES (123,'before@mockdata.com', current_timestamp-15);

-- This will be handled by some TestStrategy class
/* @Test
-- First ETL run
{
    "name" : "Day1_etl_run",
    "vsql_file" : ["repo_home/sql/my_etl.sql"]
}
*/

/* @Test
{
    "name" : "Day1_check_email_address",
    "query" : "select company_id, email_address from dim_company",
    "expected" : "123 before@mockdata.com"
}
*/
</code></pre>

<p>The <code>codeHandler</code> and <code>testHandler</code> attributes are undefined in the abstract class BaseTestRunner, leaving the actual test runners to provide with concrete classes when they subclass the BaseTestRunner.
In this way, when another team needs to run a new format of test blocks or run test blocks in a different way, it will only need to define a new class that implements TestStrategy interface to handle those new test blocks.
Then, a new test runner class can be created by simply subclassing the BaseTestRunner, and provide the new TestStrategy class instead.
In the following example TestRunner class, a new <code>VerticaTestHandler</code> class is created to handle test blocks that are specific to Vertica, as opposed to generic JDBC-compatible databases.
Other components such as SqlCodeHandler to process SQL statements can be reused for this new TestRunner.</p>

<pre><code class="java Example TestRunner">/**
 * Test runner that uses Vertica JDBC connection.
 * It can handle test block of NameVsqlfile format that runs ETL scripts using local vsql.
 * 
 * @author tdongsi
 */
public class VerticaRunner extends BaseTestRunner implements TestRunner {
    public VerticaRunner(JdbcConnection jdbcConn, String vsqlPath) {
        this.setCodeHandler(new SqlCodeHandler());
        this.setTestHandler(new VerticaTestHandler(vsqlPath));
        this.setConnection(jdbcConn);
    }
}
</code></pre>

<h3>Extending Test Runner</h3>

<p>When extending a test runner, the behaviors of the test runners should NOT be inherited.
Instead, they should be encapsulated in classes that specify how to handle SQL statements (CodeStrategy interface) or test blocks <code>/* @Test {...} */</code> (TestStrategy interface).
When a new test runner is created to meet new testing needs, we should not subclass the previous test runner.
Instead, we can delegate the old behaviors to the old handlers while adding new classes to handle new behaviors or new functionality.
In other words, &ldquo;composition over inheritance&rdquo; principle applies here to separate test runner classes and test processing behaviors that each test runner uses.</p>

<p>Implementation of a new feature can be summarized in the following steps:</p>

<ol>
<li>Design new JSON block for the new test block.</li>
<li>Define new POJO that maps to new JSON block.</li>
<li>Create a new class that implements TestStrategy/CodeStrategy interface to handle the new POJO.</li>
<li>Create a new test runner that uses the new TestStrategy/CodeStrategy.</li>
</ol>


<p>For example, our current test runner that can run an ETL script in Vertica database using <code>vsql</code> command-line tool.
If we need a test runner that is able to run an ETL script in <strong>Netezza</strong> database, we should not modify our <em>current</em> test runner.
It will break the current suite of tests for Vertica.
Instead, we should create a new test runner class with new class extend TestStrategy to handle running ETL in Netezza.</p>

<p>In <a href="/blog/2016/04/17/sql-unit-data-parity/">another example</a>, I give more detailed steps of implementation when we need to add new capability to SQL Test Runner.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[(Pt. 5) Big Data: Functional Tests vs. Unit Tests]]></title>
    <link href="http://tdongsi.github.io/blog/2016/04/14/sql-unit-vs-functional/"/>
    <updated>2016-04-14T17:21:12-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/04/14/sql-unit-vs-functional</id>
    <content type="html"><![CDATA[<p>Navigation: <a href="/blog/2016/03/16/sql-unit-overview/">Overview</a>,
<a href="/blog/2016/03/20/sql-unit-functional-tests/">Pt 1</a>,
<a href="/blog/2016/03/28/sql-unit-test-runner/">Pt 2</a>,
<a href="/blog/2016/04/10/sql-unit-incremental-data-update/">Pt 3</a>,
<a href="/blog/2016/04/12/sql-unit-testing/">Pt 4</a>.</p>

<p>In the context of Big Data projects, the differences between functional tests and unit tests can be summarized as follows:</p>

<table>
<thead>
<tr>
<th>       </th>
<th> Functional tests      </th>
<th> Unit tests </th>
</tr>
</thead>
<tbody>
<tr>
<td> Data         </td>
<td> Production-like data </td>
<td> Mock (synthetic) data </td>
</tr>
<tr>
<td> Environment  </td>
<td> Pre-production. Tables deployed once. </td>
<td> Local VM. Regular setup/teardown. </td>
</tr>
<tr>
<td> Coverage     </td>
<td> Passive: Coverage depends on diverse real data. </td>
<td> Active: Mock data created to force corner cases. </td>
</tr>
<tr>
<td> Example usage </td>
<td> Snapshot testing </td>
<td> Incrementa data update testing </td>
</tr>
</tbody>
</table>


<p><br></p>

<p>It should be noted that functional and unit tests are complementary to each other.
Certain aspects of ETLs can be better verified as functional tests while others of the same ETLs should be verified as unit tests.
For example, as discussed in <a href="/blog/2016/04/10/sql-unit-incremental-data-update/">this post</a>, unit tests are better suited for testing incremental data update in ETL scripts.</p>

<p>On the other hand, for example, an ETL that performs some kind of classification, such as categorizing user types based on some clickstream patterns, should be tested in functional tests.
If there are more than 20 categories, it could become a daunting task to generate and maintain synthetic data for each of those categories.
Furthermore, synthetic data generation requires careful consideration and proper execution to have adequate coverage.
Otherwise, the synthetic data might not be as diverse as production data and we end up with less corner cases than production data.
Instead, in this particular case, we could use production-like data directly and write test queries in functional tests to check for corner cases for each category.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[(Pt. 4) SQL Unit Testing]]></title>
    <link href="http://tdongsi.github.io/blog/2016/04/12/sql-unit-testing/"/>
    <updated>2016-04-12T17:45:42-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/04/12/sql-unit-testing</id>
    <content type="html"><![CDATA[<p>Navigation: <a href="/blog/2016/03/16/sql-unit-overview/">Overview</a>,
<a href="/blog/2016/03/20/sql-unit-functional-tests/">Pt 1</a>,
<a href="/blog/2016/03/28/sql-unit-test-runner/">Pt 2</a>,
<a href="/blog/2016/04/10/sql-unit-incremental-data-update/">Pt 3</a>.</p>

<!-- 
Changes I made:
1. Mix of SQL code and test blocks.
1. New JSON block to run ETL script using VSQL

I would also discuss some guidelines of unit testing for ETL and when it makes sense to focus.

Running ETL script through JDBC is probably not a good idea.

Requirements of unit tests:

Readability:

#### Single-node VM

Remove KSAFE.

Add a new test.
  
Revert in Git.

#### Adding  unit test

Show SBG strategy.

#### Other usages

You can insert into the ETL script to verify step by step.
However, there is only one set of mock data. 
In unit testing, you might want multiple setup of mock data for different scenarios.
=> the other way is actually more flexible

Assumptions:

1. No ;
1. ETL is simple enough: the same tables are not updated and transformed multiple times in multiple steps. 


-->


<p>TODO indefinitely.</p>

<p>The idea is to use a local Vertica VM as sandbox test environment.
It could be a <a href="/blog/2016/01/10/find-and-replace-a-string-in-multiple-files/">single cluster VM</a> or <a href="/blog/2016/03/12/set-up-three-node-vertica-sandbox-vms-on-mac/">three-node cluster VM</a>.</p>

<p>The following changes in SQL Test Runner are critical to enable unit testing:</p>

<ol>
<li>Mix of SQL code and test blocks: We can use SQL code to do necessary synthetic data setup before running assertions, in SQL queries.</li>
<li>New test block to run ETL script using VSQL CLI: The ETL scripts are considered (large) classes/functions under test, and this new kind of test block simplify running those &ldquo;functions&rdquo; again and again with different synthetic data. Running using VSQL CLI is required since we execute ETL scripts in production using that tool.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[(Pt. 3) Testing Incremental Data Update]]></title>
    <link href="http://tdongsi.github.io/blog/2016/04/10/sql-unit-incremental-data-update/"/>
    <updated>2016-04-10T17:46:40-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/04/10/sql-unit-incremental-data-update</id>
    <content type="html"><![CDATA[<p>Navigation: <a href="/blog/2016/03/16/sql-unit-overview/">Overview</a>,
<a href="/blog/2016/03/20/sql-unit-functional-tests/">Pt 1</a>,
<a href="/blog/2016/03/28/sql-unit-test-runner/">Pt 2</a>
.</p>

<p>One of challenges in SQL testing is &ldquo;incremental data update&rdquo; in ETL scripts.
Challenges in functional testing motivates me to create a test framework to add unit-like tests for those ETL scripts.</p>

<h3>Incremental data update</h3>

<p>In the last <a href="/blog/2016/03/16/sql-unit-functional-tests/">blog post</a>, I go over evolution of functional testing in data mart projects.
In functional tests, we deploy the data marts, run all the DDL, DML and ETL scripts, and, then, execute a bunch of SQL test queries to validate the tables.</p>

<p>That kind of testing could be sufficient if the inputs of the ETL are snapshot tables: data extracted by the ETL scripts are from the latest snapshot of the data.
Preparing this snapshot might be expensive, especially for daily ETLs, since those tables will be truncated and reloaded with latest data.
This can be every inefficient since out of billions of records for twenty years of historical data, less than one percent of those will be updated over a day interval.
Therefore, for performance reasons, the ETLs usually perform <strong>incremental data update</strong>.
Some characteristics of &ldquo;incremental data update&rdquo; are as follows:</p>

<p>1) Only updated records are incrementally appended into some tables, used for staging purpose (a.k.a. staging tables).
These tables will be used as input for those ETLs with incremental update.
For example, let&rsquo;s say there is a company record with ID = 123 and some attribute such as master email <code>before@mock.com</code> on Day 1.
On Day 2, the company email could be udpated to <code>after@mock.com</code>.
The original record of company 123 with <code>before@mock.com</code> is not necessarily removed from the staging table.
Instead, a new row with updated data (ID = 123, email = <code>after@mock.com</code>) is appended into the staging table.</p>

<p>2) To keep the size of input tables and ETL running time bounded, we usually keep only a number of days worth of data in the staging tables.
In other words, any records older than some <code>D</code> days are truncated from those staging tables.
For example, after <code>D = 7</code> days since Day 2, if the company <code>ID = 123</code> has no update, its records will be removed from the staging tables.
Note that, after being truncated, that company <code>ID = 123</code> can be re-inserted into the staging table if some of its attribute is updated.</p>

<p><strong>Risks</strong>: The ETLs with incremental data update are usually much more complex.
Obviously, one risk of running ETL with incremental data update is duplicate records: we could have multiple rows for the same company <code>ID = 123</code>.
On the other hand, when data for company <code>ID = 123</code> are truncated from the staging tables after <code>D</code> days (0 row), it simply means that there is no update to that company during the last <code>D</code> days.
It means that the record for <code>ID = 123</code> should not be removed from the destination tables even though the input staging tables contain no such row for <code>ID = 123</code>.
In contrast, for snapshot data, each record is almost guaranteed unique on primary key, meaning exactly one row with company <code>ID = 123</code>.
The following example scenario illustrates the challenge and complexity of ETLs with incremental data update.</p>

<h3>Example scenario</h3>

<p>For sliding window of one week data <code>D = 7</code> in the staging tables <code>stg_company_id</code> and <code>stg_company_contact</code>, the company with <code>ID = 123</code> may have its email address updated like this:</p>

<ul>
<li>Day 1

<ul>
<li><code>stg_company_id</code> -> ID: 123, region: US.</li>
<li><code>stg_company_contact</code> -> ID: 123, email: <a href="&#x6d;&#97;&#x69;&#108;&#116;&#111;&#58;&#x62;&#101;&#x66;&#111;&#114;&#101;&#64;&#x6d;&#x6f;&#99;&#107;&#100;&#x61;&#x74;&#97;&#x2e;&#x63;&#x6f;&#x6d;&#46;">&#98;&#101;&#x66;&#x6f;&#x72;&#x65;&#64;&#109;&#x6f;&#x63;&#107;&#100;&#x61;&#x74;&#x61;&#x2e;&#x63;&#x6f;&#109;&#46;</a> (same company)</li>
</ul>
</li>
<li>Day 3

<ul>
<li>Email updated to <a href="&#x6d;&#x61;&#x69;&#108;&#116;&#x6f;&#58;&#x61;&#102;&#x74;&#x65;&#x72;&#x40;&#109;&#111;&#x63;&#x6b;&#100;&#x61;&#x74;&#x61;&#x2e;&#x63;&#x6f;&#109;">&#97;&#102;&#116;&#x65;&#x72;&#64;&#x6d;&#111;&#x63;&#x6b;&#100;&#97;&#x74;&#x61;&#x2e;&#99;&#111;&#109;</a> in <code>stg_company_contact</code>.</li>
<li><code>stg_company_id</code> has one row with ID = 123.</li>
<li><code>stg_company_contact</code> has two rows with ID = 123.</li>
</ul>
</li>
<li>Day 10

<ul>
<li>Data truncated from <code>stg_company_contact</code> as there is no update.</li>
<li>Data is also truncated from <code>stg_company_id</code> since Day 8 for the same reason.</li>
<li><code>stg_company_id</code> and <code>stg_company_contact</code> has zero row with ID = 123.</li>
</ul>
</li>
<li>Day 15

<ul>
<li>Email updated to <a href="&#109;&#97;&#105;&#x6c;&#x74;&#111;&#58;&#98;&#101;&#x79;&#111;&#x6e;&#x64;&#64;&#x6d;&#x6f;&#99;&#107;&#100;&#x61;&#116;&#x61;&#46;&#99;&#111;&#109;&#x2e;">&#x62;&#101;&#x79;&#x6f;&#110;&#x64;&#x40;&#x6d;&#x6f;&#x63;&#x6b;&#x64;&#x61;&#116;&#x61;&#46;&#99;&#111;&#109;&#x2e;</a></li>
<li><code>stg_company_id</code> has zero row with ID = 123.</li>
<li><code>stg_company_contact</code> has one row with ID = 123.</li>
</ul>
</li>
</ul>


<p>Despite the changing number of rows with <code>ID = 123</code>, the daily ETL should always returns a company with <code>ID = 123</code> in its output, the dimension table <code>dim_company</code>, with the <code>email_address</code> column updated accordingly.</p>

<h3>Initial functionality tests</h3>

<p>Initially, verifying incremental data update of ETLs is very challenging.
We approach testing incremental data update just like funcional tests: load the data mart with production-like data, and run multiple ETL runs to simulate multiple days.
Specifically, we collected a few sets of staging tables for a few days, and then manually simulate each set as the current day data before running the ETL.
After running the ETL, we will run the corresponding set of automated functional tests for that day, one set for each day.</p>

<p>That process is summarized as the following steps for each day:</p>

<ol>
<li>Manually set up the staging data (ETL input).</li>
<li>Manually run the ETL.</li>
<li>Run the corresponding set of automated functional tests.</li>
</ol>


<p>As you can see, even though running the tests is automated, the setup and running ETL is pretty much manual.
It is time consuming to manually set up and run ETLs: for production-like data, staging tables can contain millions of records for incremental data.
Since we run ETLs multiple times to properly verify incremental update, the running times add up.
Besides being time-consuming, the process also takes lots of mental energy to do each of the steps right, in the correct order.
Otherwise, the tests will fail for no apparent reason.</p>

<p>Despite the effort involved, the return is very little.
Most of the time, the difference in data between a few days or weeks are usually not enough to verify all corner cases in ETL scripts.
After running tests, we still don&rsquo;t know if a particular ETL will ever break when new data comes in and some infrequently updated column is updated in some particular way.</p>

<h3>Observations</h3>

<p>The painful experience of testing incremental data update for ETLs with production-like data leads to the following observations:</p>

<ol>
<li>We should only need a small number of records to reduce ETL running time.</li>
<li>We should create synthetic data to force rare logic branches and corner cases.</li>
<li>We should have a way to set up data automatically.</li>
<li>We should have a way to run the ETL under test automatically.</li>
</ol>


<p>These observations, especially small and synthetic data, sounds like unit testing.
It leads to my strong conviction that incremental data update should tested in a bunch of &ldquo;unit tests&rdquo;, with mock data to force corner cases.</p>

<h3>Unit tests - first look</h3>

<p>I made two changes in the SQL Test Runner to make it easier to do unit testing SQL scripts in Vertica:</p>

<ol>
<li>Add ability to run the SQL statements to set up data.</li>
<li>Add ability to run a list of specified ETLs.

<ul>
<li>For example, in our project, <code>vsql</code> is used to execute ETL scripts in SQL. Therefore, I added ability to invoke <code>vsql</code> to run a list of SQL files.</li>
</ul>
</li>
</ol>


<p>With that, a unit test to verify our ETL (e.g., <code>my_etl.sql</code>) that updates email address incrementally (in the example scenario above) will look like this:</p>

<pre><code class="sql Unit test for the example scenario in section above">/****************************
* Day 1
****************************/

INSERT INTO stg_company_id (company_id,last_modify_date,region_id) 
VALUES (123,current_timestamp-19,'US');

INSERT INTO stg_company_contact (company_id,master_email,last_modify_date) 
VALUES (123,'before@mockdata.com', current_timestamp-15);

/* @Test
-- First ETL run
{
    "name" : "Day1_etl_run",
    "vsql_file" : ["repo_home/sql/my_etl.sql"]
}
*/

/* @Test
{
    "name" : "Day1_check_email_address",
    "query" : "select company_id, email_address from dim_company",
    "expected" : "123 before@mockdata.com"
}
*/

/**********************************************************
Day 3: Email updated in stg_company_contact
**********************************************************/

INSERT INTO stg_company_contact (company_id,master_email,last_modify_date) 
VALUES (123,'after@mockdata.com',current_timestamp-12);


/* @Test
-- Day 3 ETL run
{
    "name" : "Day3_etl_run",
    "vsql_file" : ["repo_home/sql/my_etl.sql"]
}
*/

/* @Test
{
    "name" : "Day3_check_count",
    "query" : "select count(*) from dim_company",
    "expected" : "1"
}
*/

/* @Test
{
    "name" : "Day3_check_email_address",
    "query" : "select email_address from dim_company",
    "expected" : "after@mockdata.com"
}
*/

/**********************************************************
Day 10: Data truncated from staging table
**********************************************************/

TRUNCATE TABLE stg_company_id;
TRUNCATE TABLE stg_company_contact;

/* @Test
-- This ETL run should have no effect
{
    "name" : "Day10_etl_run",
    "vsql_file" : ["repo_home/sql/my_etl.sql"]
}
*/

/* @Test
{
    "name" : "Day10_check_count",
    "query" : "select count(*) from dim_company",
    "expected" : "1"
}
*/

/* @Test
{
    "name" : "Day10_check_email_address",
    "query" : "select email_address from dim_company",
    "expected" : "after@mockdata.com"
}
*/

/**********************************************************
Day 15: Another update in email
**********************************************************/

-- Email is updated
INSERT INTO stg_company_contact (company_id,master_email,last_modify_date) 
VALUES (123,'beyond@mockdata.com',current_timestamp-3);


/* @Test
-- Day 15 ETL run
{
    "name" : "Day15_etl_run",
    "vsql_file" : ["repo_home/sql/my_etl.sql"]
}
*/

/* @Test
{
    "name" : "Day15_check_count",
    "query" : "select count(*) from dim_company",
    "expected" : "1"
}
*/

/* @Test
{
    "name" : "Day15_check_email_address",
    "query" : "select email_address from dim_company",
    "expected" : "beyond@mockdata.com"
}
*/
</code></pre>

<p>Running the unit test script above from TestNG will be similar as in functional tests (see &ldquo;Level 3&rdquo; in <a href="/blog/2016/03/16/sql-unit-functional-tests/">this post</a>).
After one-time setup (in <code>@BeforeClass</code> and <code>@AfterClass</code> functions), there will be minimal Java code added (<code>@Test</code> functions):</p>

<pre><code class="java Calling unit test script">@BeforeClass
public void setup() {
    testRunner = new SqlTestRunner(getJdbcConnection());
}

@Test(enabled = true)
public void validate_dim_region() throws Exception {
        testRunner.runScript("unittests/etl_incremental_update_email.test");
}
</code></pre>

<p>The full setup for unit testing will be discussed in the next blog post.</p>
]]></content>
  </entry>
  
</feed>
