<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Sql | Personal Programming Notes]]></title>
  <link href="http://tdongsi.github.io/blog/categories/sql/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/"/>
  <updated>2015-12-02T20:42:21-08:00</updated>
  <id>http://tdongsi.github.io/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Programming Hive (Pt. 5): HiveQL Data Definition]]></title>
    <link href="http://tdongsi.github.io/blog/2015/12/02/programming-hive-hiveql-ddl/"/>
    <updated>2015-12-02T18:32:21-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/12/02/programming-hive-hiveql-ddl</id>
    <content type="html"><![CDATA[<p><img class="center" src="/images/hive/cat.gif" title="Cover" ></p>

<p>Chapter 4 of the book covers data definition parts of HiveQL language, mostly for creating, altering, and dropping databases and tables. The book defers discussion of views until chapter 7, indexes until Chapter 8, and functions until Chapter 13.</p>

<p>Hive does not support row-level inserts, updates, and deletes. It also adds extensions for better performance in the context of Hadoop.</p>

<h3>Databases</h3>

<p>In Hive, the concept of a database is basically just a namespace of tables. The keyword SCHEMA can be used instead of DATABASE in all the database-related commands. If you don’t specify a database, the <code>default</code> database is used.</p>

<p>Some basic HiveQL&rsquo;s database commands is shown in the following examples:</p>

<pre><code class="sql">CREATE DATABASE college;
CREATE DATABASE IF NOT EXISTS college;

SHOW DATABASES;
SHOW DATABASES LIKE ‘h.*’;

CREATE DATABASE college
LOCATION ‘/my/preferred/directory’;

/* add comments to table */
CREATE DATABASE college COMMENT ‘A college admission database’;
/* show comments */
DESCRIBE DATABASE college;

/* add properties */
CREATE DATABASE college WITH DBPROPERTIES ( ‘creator’ = ‘CD’, ‘date’ = ‘today’ );
/* show properties */
DESCRIBE DATABASE EXTENDED college;

/* set working database */
USE college;
/* this will show tables in this database */
SHOW TABLES;

DROP DATABASE IF EXISTS college;
/* Drop tables if there is any table in the database */
DROP DATABASE IF EXISTS college CASCADE;

/* You can set additional key-value pairs in properties.
 * No other metadata about the database can be changed. No way to delete a DB PROPERTY.
 */
ALTER DATABASE college SET DBPROPERTIES (‘editor’ = ‘DC’);
</code></pre>

<p>Note that Hive will create separate directory for each database. The exception is the <code>default</code> database, which doesn&rsquo;t have its own directory. Tables in each database will be stored in subdirectories of the database directory. The location of the database directory is specified by the property <code>hive.metastore.warehouse.dir</code>. These are illustrated by the Hive CLI commands as follows:</p>

<pre><code>[cloudera@quickstart temp]$ hive

Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
hive&gt; describe database default;
OK
default Default Hive database   hdfs://quickstart.cloudera:8020/user/hive/warehouse public  ROLE    
Time taken: 0.01 seconds, Fetched: 1 row(s)
hive&gt; describe database college;
OK
college     hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db  cloudera    USER    
Time taken: 0.011 seconds, Fetched: 1 row(s)

hive&gt; SET hive.metastore.warehouse.dir;
hive.metastore.warehouse.dir=/user/hive/warehouse

hive&gt; dfs -ls hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db;
Found 3 items
drwxrwxrwx   - hive hive          0 2015-01-21 11:29 hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/apply
drwxrwxrwx   - hive hive          0 2015-01-20 15:22 hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/college
drwxrwxrwx   - hive hive          0 2015-01-28 15:26 hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/student
hive&gt; dfs -ls hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/student;
Found 1 items
-rwxrwxrwx   1 cloudera hive        213 2015-01-20 15:22 hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/student/student.data
hive&gt; dfs -ls hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/college;
Found 1 items
-rwxrwxrwx   1 cloudera hive         66 2015-01-20 15:22 hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db/college/college.data
</code></pre>

<p>In the output of the <code>DESCRIBE DATABASE</code> commands above, the directory location of the database is shown, with <code>hdfs</code> as URI scheme. Note that <code>hdfs://quickstart.cloudera:8020/user/hive/warehouse/college.db</code> is equivalent to <code>hdfs://user/hive/warehouse/college.db</code>, where <code>quickstart.cloudera:8020</code> is simply the master node’s DNS name and port on Cloudera Quickstart VM. The name of the database directory is always <code>database_name.db</code> with <code>.db</code> suffix added to database name. The three tables <code>college</code>, <code>student</code>, and <code>apply</code> in the <code>college</code> database are created as sub-directories in that <code>college.db</code> directory, as shown above. When a database is dropped, its directory is also deleted. By default, Hive will not allow you to drop a table that contains tables. The second <code>DROP DATABASE</code> command with <code>CASCADE</code> will force Hive to drop the database by dropping the tables in the database first.</p>

<p>There is no command to show the current working database. When in doubt, it is safe to use the command <code>USE database_name;</code> repeatedly since there is no nesting of databases in Hive. Otherwise, you can set a property to show the current working database in Hive CLI prompt as follows:</p>

<pre><code>hive&gt; set hive.cli.print.current.db=true;
hive (default)&gt; USE college;
OK
Time taken: 0.278 seconds
hive (college)&gt; 
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Programming Hive (Pt. 4): Data Types]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/26/programming-hive-data-types/"/>
    <updated>2015-11-26T18:01:37-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/26/programming-hive-data-types</id>
    <content type="html"><![CDATA[<p><img class="center" src="/images/hive/cat.gif" title="Cover" ></p>

<p>Chapter 3 of the book covers different data types and file formats supported by Hive.</p>

<h3>Data Types</h3>

<p>The following primitive data types are supported:</p>

<ul>
<li>TINYINT: 1 byte signed integer</li>
<li>SMALLINT: 2 bytes</li>
<li>INT: 4 bytes</li>
<li>BIGINT: 8 bytes</li>
<li>BOOLEAN</li>
<li>FLOAT</li>
<li>DOUBLE</li>
<li>STRING: Single or doublbe quotes can be used for literals.</li>
<li>TIMESTAMP: Integer, float, or string.

<ul>
<li>Integer: For seconds from Unix epoch.</li>
<li>Float: Seconds from Unix epoch and nanoseconds.</li>
<li>String: JDBC-compliant java.sql.Timestamp format convention, i.e. YYYY-MM-DD hh:mm:ss.fffffffff</li>
</ul>
</li>
<li>BINARY: array of bytes. Used to include arbitrary bytes and prevent Hive from attempting to parse them.</li>
</ul>


<p>As you can see, Hive supports most basic primitive data types conventionally found in relational databases. Moreover, it helps to remember that these data types are implemented in Java, so their behaviors will be similar to their Java counterparts.</p>

<p>NOTE: Not metioned in the book, but the types <code>DECIMAL</code> and <code>DATE</code> are introduced since Hive 0.13.0. In addition, the book claimed &ldquo;Hive does not support character arrays with maximum-allowed lengths, as is common in other SQL dialects&rdquo; but <code>VARCHAR</code> type, introduced in Hive 0.12.0, does exactly that.</p>

<p>Besides primitive data types, Hive supports the following collection data types:</p>

<ul>
<li>STRUCT: Analogous to a C <code>struct</code> or POJO (Plain Old Java Object). The elements can be accessed using the DOT (.) notation.

<ul>
<li>Example: Declaration <code>struct&lt;name:string,id:int&gt;</code>. Literal <code>struct('John',1)</code>.</li>
</ul>
</li>
<li>MAP: A collection of key-value tuples. The elements can be accessed using array notation, e.g. persons[&lsquo;John&rsquo;].

<ul>
<li>Example: Declaration <code>map&lt;string,int&gt;</code>. Literal <code>map('John',1)</code>.</li>
</ul>
</li>
<li>ARRAY: Ordered sequences of the same type. The elements can be accessed using array notation, e.g. person[2].

<ul>
<li>Example: Declaration <code>array&lt;string&gt;</code>. Literal <code>array('John','Peter')</code>.</li>
</ul>
</li>
</ul>


<p>Relational databases don&rsquo;t usually support such collection types because they tend to break <strong>normal form</strong>. In Hive/Hadoop, sacrificing normal form is pretty common as it can give benefit of higher processing throughput, especially with large amount of data (tens of terarbytes).</p>

<h3>Text File Formats</h3>

<p>Hive can use comma-separated values (CSV) or tab-separated values (TSV) text file format. A Hive table declaration with all row format specified (with default values, however) looks like this:</p>

<pre><code class="sql">CREATE TABLE employees (
  name         STRING,
  salary       FLOAT,
  subordinates ARRAY&lt;STRING&gt;,
  deductions   MAP&lt;STRING, FLOAT&gt;,
  address      STRUCT&lt;street:STRING, city:STRING, state:STRING, zip:INT&gt;
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\001'
COLLECTION ITEMS TERMINATED BY '\002'
MAP KEYS TERMINATED BY '\003'
LINES TERMINATED BY '\n'
STORED AS TEXTFILE;
</code></pre>

<h3>Schema on Read</h3>

<p>Different from databases, Hive has no control over the underlying storage: for example, you can modify files on HDFS that Hive will query. Hive tries its best to read the data and match the schema. If the file content does not match the schema such as non-numeric strings found when numbers expected, you may get null values.</p>

<h3>Additional References</h3>

<p>As of November 2015, the book uses slightly a outdated Hive version 0.9.0 (Chapter 2, Installing Hive). Information in the following links are used when writing this post:</p>

<ol>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/Tutorial">https://cwiki.apache.org/confluence/display/Hive/Tutorial</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Programming Hive (Pt. 1): Introduction]]></title>
    <link href="http://tdongsi.github.io/blog/2015/11/22/programming-hive-chapter-1/"/>
    <updated>2015-11-22T17:22:51-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/11/22/programming-hive-chapter-1</id>
    <content type="html"><![CDATA[<!---
"Chapter 1: Introduction" of the "Programming Hive" book.
-->


<p>This post is the first of many posts summarizing the <strong>Programming Hive</strong> book, with some observations from my own experience.</p>

<p><img class="center" src="/images/hive/cat.gif" title="Cover" ></p>

<h3>Introduction</h3>

<p>Hive provides a SQL dialect, called Hive Query Language (HiveQL or HQL) for querying data stored in a Hadoop cluster. SQL knowledge is widespread for a reason; it&rsquo;s an effective, reasonably intuitive model for organizing and using data. Therefore, Hive helps lower the barrier, making transition to Hadoop from traditional relational databases easier for expert database designers and administrators.</p>

<p>Note that Hive is more suited for data warehouse applications, where data is relatively static and fast response time is not required. For example, a simple query such as <code>select count(*) from my_table</code> can take several seconds for a very small table (mostly due to startup overhead for MapReduce jobs). Hive is a heavily batch-oriented system: in addition to large startup overheads, it neither provides record-level update, insert, or delete nor transactions. In short, Hive is not a full database (hint: check HBase).</p>

<p>HiveQL does not conform to the ANSI SQL standard (not many do), but it is quite close to MySQL dialect.</p>

<h3>Hive within the Hadoop Ecosystem</h3>

<p>A basic understanding of Hadoop and MapReduce can help you to understand and appreciate how Hive works. Simple examples such as WordCount in my <a href="/blog/2015/11/21/explaining-wordcount-example/">last post</a> can be very involving when using the Hadoop Java API. The API requires Java developers to manage many low-level details, repetitive wiring to/from Mappers and Reducers. The WordCount example&rsquo;s Java implementation can be found <a href="https://wiki.apache.org/hadoop/WordCount">here</a>.</p>

<p>Hive not only eliminates advanced, sometimes repetitive Java coding but also provides a familiar interface to those who know SQL. Hive lets you complete a lot of work with relatively little effort. For example, the same WordCount example in HiveQL can be as simple as:</p>

<pre><code class="sql WordCount example in HiveQL">CREATE TABLE docs (line STRING);

/* Load text files into TABLE docs: each line as a row */
LOAD DATA INPATH 'wordcount.txt' OVERWRITE INTO TABLE docs;

CREATE TABLE word_counts AS
SELECT word, count(1) AS count
FROM
   -- explode will return rows of tokens
  (SELECT explode(split(line, '\s')) AS word
   FROM docs) w
GROUP BY word
ORDER BY word;
</code></pre>

<p>In the remaining sections of Chapter 1, the authors also discuss various related Hadoop projects such as Pig, Hue, HBase, Spark, Storm, Kafka, etc.</p>
]]></content>
  </entry>
  
</feed>
