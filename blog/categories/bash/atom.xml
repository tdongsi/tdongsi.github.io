<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Bash | Personal Programming Notes]]></title>
  <link href="http://tdongsi.github.io/blog/categories/bash/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/"/>
  <updated>2016-09-13T01:01:19-07:00</updated>
  <id>http://tdongsi.github.io/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Bash Trap]]></title>
    <link href="http://tdongsi.github.io/blog/2016/03/02/bash-trap/"/>
    <updated>2016-03-02T00:07:48-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/03/02/bash-trap</id>
    <content type="html"><![CDATA[<h3>Code snippet</h3>

<p>There is a simple idiom to ensure your bash scripts to always do proper cleanup operations before exiting, even when something goes wrong during execution.
In the context of Java or Python, this is similar to a <code>finally</code> clause that will execute after any exception is caught during execution.</p>

<pre><code class="bash DO THIS"># Setup trap to cleanup before exiting script
function cleanup {
    echo "Removing temp files..."
    if [[ -f $CMD_TMPFILE ]] ; then
        rm $CMD_TMPFILE
    fi
    if [[ -f $LOG_TMPFILE ]] ; then
        rm $LOG_TMPFILE
    fi
}
trap cleanup EXIT

# Setup

# Thousand lines of code here
</code></pre>

<p>Putting the cleanup operations at the end of the bash script might not work in cases of error.
Since the bash script already stops executing due to some fatal error, those clean up commands might never run.</p>

<pre><code class="bash DON'T DO THIS">
# Setup

# Thousand lines of code here

# This might not run when there is error
echo "Removing temp files..."
if [[ -f $CMD_TMPFILE ]] ; then
    rm $CMD_TMPFILE
fi
if [[ -f $LOG_TMPFILE ]] ; then
    rm $LOG_TMPFILE
fi
</code></pre>

<p>For example, in Vertica, you should always run <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/Functions/VerticaFunctions/START_REFRESH.htm"><code>SELECT START_REFRESH()</code></a>
at the end of a deployment script, regardless of any error encountered during script execution.
It is a good candidate for using <code>trap</code> statement.
Adding those commands at the end of the script will not work in cases there is an error during deployment, and you might end up with &ldquo;AHM Does Not Advance&rdquo;-related errors (see this <a href="/blog/2016/02/29/vertica-9-refresh-projections/">post</a>).</p>

<h3>Trap multiple signals</h3>

<p>Note that many online examples for <code>trap</code> use a list of signals for cleanup tasks like this <code>trap cleanup INT TERM EXIT</code>, i.e., trapping not only EXIT signal but also INT and TERM signals.
I believe once <code>EXIT</code> signal is used, other signals such as <code>INT</code> or <code>TERM</code> are redundant for cleanup purposes.
<code>EXIT</code> or 0 signal is invoked when the shell exits, an event that also happens when an <code>INT</code> or <code>TERM</code> signal is received.
It is easy to confirm that with the following short bash script:</p>

<pre><code class="plain Trap tests in Mac OSX">MTVL1288aeea2-82:code tdongsi$ cat test_trap.sh
#!/bin/bash
trap 'echo SIGNAL CAPTURED' EXIT
sleep 3

MTVL1288aeea2-82:code tdongsi$ ./test_trap.sh &amp; sleep 1; kill -INT %1
[1] 6613
SIGNAL CAPTURED
[1]+  Interrupt: 2            ./test_trap.sh

MTVL1288aeea2-82:code tdongsi$ ./test_trap.sh &amp; sleep 1; kill -TERM %1
[1] 6624
SIGNAL CAPTURED
[1]+  Terminated: 15          ./test_trap.sh
</code></pre>

<p>As shown above, a lone <code>EXIT</code> is enough to capture <code>INT</code> and <code>TERM</code> signals.
Having said that, I understand that my tests can only verify bash on Mac OSX.
There are probably different shell variants on different operating systems which do not always work that way.</p>

<p>The problem of those <code>trap</code> examples lies in when someone copies and uses the code directly from the web, without understanding how it works.
Listing multiple signals can make the <code>cleanup</code> steps executed twice, once for the signal such as <code>TERM</code> and once for <code>EXIT</code>, as shown in the modified experiment below.
Not all cleanup steps could be and should be executed twice.
For example, it is almost always true that removing some temporary file/folder should not be executed twice during a cleanup.</p>

<pre><code class="plain Problem of trapping multiple signals">MTVL1288aeea2-82:code tdongsi$ cat test_trap.sh
#!/bin/bash
trap 'echo SIGNAL CAPTURED' INT TERM EXIT
sleep 3

MTVL1288aeea2-82:code tdongsi$ ./test_trap.sh &amp; sleep 1; kill -INT %1
[1] 7258
SIGNAL CAPTURED
SIGNAL CAPTURED
[1]+  Exit 130                ./test_trap.sh

MTVL1288aeea2-82:code tdongsi$ ./test_trap.sh &amp; sleep 1; kill -TERM %1
[1] 7278
Terminated: 15
SIGNAL CAPTURED
SIGNAL CAPTURED
[1]+  Exit 143                ./test_trap.sh
</code></pre>

<p>In short, you should know how <code>trap</code> works on your production system before listing multiple signals as its parameters, especially when coupled with <code>EXIT</code> signal.</p>

<h3>Other usage notes</h3>

<p>The signal names might be specified with or without prefix <code>SIG</code> or even with numeric values for signal numbers, e.g., 2 for INT (see list below).</p>

<pre><code class="plain List of signals">MTVL1288aeea2-82:octopress tdongsi$ kill -l
 1) SIGHUP   2) SIGINT   3) SIGQUIT  4) SIGILL
 5) SIGTRAP  6) SIGABRT  7) SIGEMT   8) SIGFPE
 9) SIGKILL 10) SIGBUS  11) SIGSEGV 12) SIGSYS
13) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGURG
17) SIGSTOP 18) SIGTSTP 19) SIGCONT 20) SIGCHLD
21) SIGTTIN 22) SIGTTOU 23) SIGIO   24) SIGXCPU
25) SIGXFSZ 26) SIGVTALRM   27) SIGPROF 28) SIGWINCH
29) SIGINFO 30) SIGUSR1 31) SIGUSR2

OR 

MTVL1288aeea2-82:octopress tdongsi$ man signal
</code></pre>

<p>If one of the signals specified in <code>trap</code> statement is <code>DEBUG</code>, the list of COMMANDS specified in <code>trap</code> statement will be executed after every simple command.
This is useful for debugging purpose.
The following example is taken from <a href="http://tldp.org/LDP/Bash-Beginners-Guide/html/chap_12.html">here</a>:</p>

<pre><code class="bash Tracing when a variable is used">declare -t VARIABLE=value
trap "echo VARIABLE is being used here." DEBUG

# rest of the script
</code></pre>

<h3>References</h3>

<ol>
<li><a href="http://tldp.org/LDP/Bash-Beginners-Guide/html/chap_12.html">Signals and Traps</a></li>
<li><a href="http://redsymbol.net/articles/bash-exit-traps/">Other usages</a></li>
<li><a href="http://wiki.bash-hackers.org/commands/builtin/declare">declare</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Symlinks in Git]]></title>
    <link href="http://tdongsi.github.io/blog/2016/02/20/symlinks-in-git/"/>
    <updated>2016-02-20T11:28:11-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/02/20/symlinks-in-git</id>
    <content type="html"><![CDATA[<h3>Context</h3>

<p>I had folders with many symbolic links in them, linking to other files in the same Git repository.</p>

<pre><code class="bash Before">$ ls -l link
... link -&gt; /path/to/target
</code></pre>

<p>Unfortunately after committing into Git, they&rsquo;ve turned into plain text files.
Note that even after committing and pushing into Git, the symlinks still work fine.
However, after some branch switches and code merges, the symlinks become actual text files with the link target as the contents.</p>

<pre><code class="bash After">$ cat link
/path/to/target
</code></pre>

<p>If you unknowingly try to run some symlinks linked to SQL scripts like that, you might end up with numerous errors like this:</p>

<pre><code class="plain">vsql:schema_create.sql:1: ERROR 4856:  Syntax error at or near "/" at character 1
vsql:schema_create.sql:1: LINE 1: /Users/tdongsi/Github/my_repo/db_schema/file...
</code></pre>

<h3>Restoring the symlinks</h3>

<p>Before going into lengthy discussion on how Git handles symlinks and hard links, the quick solution for the above problem is the following Bash script:</p>

<pre><code class="bash">folder=/Users/tdongsi/Github/my_repo/scripts/sql
ls -d1 $folder/* | while read f; do
  ln -sf "$(cat $f)" "$f"
done
</code></pre>

<p>where <code>ls -d1 $folder/*</code> should be replaced with some command that will list exactly the files you want, preferably in full path.
Note that <code>-f</code> option of <code>ln</code> command is required to replace the file with the symlink. For examples:</p>

<pre><code class="bash Examples">ls -d1 vertica/*.sql | while read f; do
  ln -sf "$(cat $f)" "$f"
done

ls -d1 bash/* | while read f; do
  ln -sf "$(cat $f)" "$f"
done
</code></pre>

<p><strong>Best practice note</strong>: I think that the following template is preferred to the more commonly seen <code>for f in $(ls *);</code> <code>do...done</code>:</p>

<pre><code class="bash">ls * | while read f; do
  # command executed for each file
done
</code></pre>

<p>I think it is the better way to handle all file names, especially with spaces, since <code>"$f"</code> will still work.
In addition, <code>$(cmd)</code> is the same as <code>'cmd'</code> (backticks) but it can be nested, unlike using backticks.
It fact, it&rsquo;s the main reason why the backticks have been <a href="http://wiki.bash-hackers.org/scripting/obsolete">deprecated</a> from Bash scripting.</p>

<h3>How Git deals with symlinks</h3>

<p>How Git deals with symlinks is defined in the <a href="https://git-scm.com/docs/git-config">git config</a> <code>core.symlinks</code>.
If false, symbolic links are checked out as small plain files that contain the link text.
<a href="http://stackoverflow.com/questions/954560/how-does-git-handle-symbolic-links">Otherwise</a>, Git just stores the contents of the link (i.e., the path of the file system) in a &lsquo;blob&rsquo; just like it would for a normal file.
It also stores the name, mode and type (e.g., symlink) in the tree object that represents its containing directory.
When you checkout a tree containing the link, it restores the object as a symlink.</p>

<p>After the symlinks are checked out as plain text files, I believe it is pretty much no way for Git to restore symlinks again (i.e., follow symlinks inside text files).
It would be an insecure, undefined behavior: what if the symlink as text file is modified? What if the target is changed when moving between versions of that text file?</p>

<h3>Use hard links?</h3>

<p>You can use hard links instead of symlinks (a.k.a., soft links).
Git will handle a hard link like a copy of the file, except that the contents of the linked files change at the same time.
Git may see changes in both files if both the original file and the hard link are in the same repository.</p>

<p>One of the disadvantages is that the file will be created as a normal file during <code>git checkout</code>, because there is no way Git understand it as a link.
Moreover, hard link itself has many limitations, compared to symlinks, such as files have to reside on the same file-system or partition.
In Mac OSX, hard links to directories are not supported. There is a <a href="https://github.com/selkhateeb/hardlink">tool</a> to do that, but use it with caution.</p>

<p>Finally, it is important to note that hard links to files can be lost when moving between different versions/branches in Git, even if they are in the same repository.
When you switch branches back and forth, Git remove the old files and create new ones.
You still have the copies of the previous files, but they might have totally different inodes, while others (if not in the same Git repo) still refers to the old inodes.
Eventually, the file and its hard links may be out of sync, and appear like totally unrelated files to Git.
Therefore, using hard links, at best, is just a temporary solution.</p>

<h3>Links</h3>

<ol>
<li><a href="http://superuser.com/questions/638998/easiest-way-to-restore-symbolic-links-turned-into-text-files">Alternative ways to restore symlinks</a></li>
<li><a href="http://stackoverflow.com/questions/246215/how-can-i-list-files-with-their-absolute-path-in-linux">Alternative ways to list files</a></li>
<li><a href="https://git.wiki.kernel.org/index.php/Git">Git design overview</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Virtual Machine for ETL Testing]]></title>
    <link href="http://tdongsi.github.io/blog/2016/01/10/find-and-replace-a-string-in-multiple-files/"/>
    <updated>2016-01-10T23:49:15-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/01/10/find-and-replace-a-string-in-multiple-files</id>
    <content type="html"><![CDATA[<h3>Vertica Virtual Machine as sandbox test environment</h3>

<p>When developing data-warehouse solutions in Vertica, you want to set up some test environment.
Ideally, you should have separate schema for each developer.
However, it is usually NOT possible in my experience: developers and test engineers have to share very few schemas in development environment.
The explanation that I usually get is that having a schema for each developer will not scale in database maintenance and administration, and there are likely some limits in Vertica&rsquo;s commercial license.
If that is the case, I recommend that we look into using Vertica Community Edition on <strong>Virtual Machines (VMs)</strong> for sandbox test environment, as a cheap alternative.</p>

<p>Are VMs really necessary in data-warehouse testing? When testing Extract-Transform-Load (ETL) processes, I find that many of test cases require regular set-up and tear-down, adding mock records to force rare logical branches and corner cases, and/or running ETLs multiple times to simulate daily runs of those processes.
Regular tear-down requires dropping multiple tables regularly, which requires much greater care and drains much mental energy when working with others' data and tables.
Similarly, adding mock records into some commonly shared tables might affect others when they assume the data is production-like.
Running ETL scripts regularly, which could be computationally intensive, on a shared Vertica cluster might affect the performance or get affected by others' processes.
In short, for these tests, I cannot use the common schema that is shared with others since it might interfere others and/or destroy valuable common data.
Using a Vertica VM as the sandbox test environment helps us minimize interference to and from others' data and activities.</p>

<h3>Single-node VM and KSAFE clause</h3>

<p>I have been using a <strong>single-node</strong> Vertica VM to run tests for sometime. And it works wonderfully for testing purpose, especially when you want to isolate issues, for example, a corner case. The Vertica VM can be downloaded from HP Vertica&rsquo;s support website (NOTE: As of 2016 Jan 1st, the Vertica 7.1 VM is taken down while the Vertica 7.2 VM is not available).</p>

<p>The only minor problem is when we add <code>KSAFE 1</code> in our DDL scripts (i.e., <code>CREATE TABLE</code> statements) for production purposes. This gives error on single-node VM when running DDL scripts to set up schema.
The reason is that Vertica database with one or two hosts cannot be <em>k-safe</em> (i.e., it may lose data if it crashes) and three-node cluster is the minimum requirement to have <code>KSAFE 1</code> in <code>CREATE TABLE</code> statements to work.</p>

<p>Even then, the workaround for running those DDL scripts in tests is easy enough if all DDL scripts are all located in a single folder. The idea is that since <code>KSAFE 1</code> does not affect ETL processes' transform logics, we can remove those KSAFE clauses to set up the test schema and go ahead with our ETL testing. Specifically, in my project, my workflow for ETL testing with <strong>Git</strong> is as follows:</p>

<ul>
<li>Branch the latest code (<code>develop</code> branch) into a temporary branch (e.g., <code>local/develop</code> branch).</li>
<li>Find and remove <code>KSAFE 1</code> in all DDL files (see subsection below).</li>
<li>While still in <code>local/develop</code> branch, commit all these changes in a <strong>single</strong> commit with some unique description (e.g., &ldquo;KSAFE REMOVAL&rdquo;).</li>
<li>Add unit and functional tests to ETL scripts in this branch.</li>
<li>After tests are properly developed and checked-in, reverse the &ldquo;KSAFE REMOVAL&rdquo; commit above.

<ul>
<li>In SourceTree, it could be done by a simple right-click on that commit and selecting &ldquo;Reverse Commit&rdquo;.</li>
</ul>
</li>
<li>Merge <code>local/develop</code> branch into <code>develop</code> branch (create a pull request if needed). You will now have your tests with the latest codes in <code>develop</code> branch.</li>
</ul>


<h4>Find and replace a string in multiple files</h4>

<p>There are times and times again that you find that you have to replace every single occurrences of some string in multiple files with another string. Finding and removing <code>KSAFE 1</code> like the above workflow is an example where &ldquo;removing string&rdquo; is a special case of &ldquo;replacing string&rdquo; with nothing. This operation can be quickly done by the following bash command:</p>

<pre><code>grep -rl match_string your_dir/ | xargs sed -i 's/old_string/new_string/g'
</code></pre>

<p>If you are familiar with bash scripting, the above command is straight forward. This quick explanation is for anyone who does not understand the command:</p>

<ul>
<li><code>grep</code> command finds all files in <code>your_dir</code> directory that contain <code>match_string</code>. <code>-l</code> option makes sure it will return a list of files</li>
<li><code>sed</code> command then execute the replacement regex on all those files. A regex tip: the forward slash <code>/</code> delimiter could be another delimiter (e.g., <code>#</code>). This might be useful if you need to search HTML files.</li>
</ul>


<p>Example: In my case, all the DDL scripts are in multiple sub-directories under <code>tables</code> directory. To find and remove all <code>KSAFE 1</code> occurrences, the command is:</p>

<pre><code>grep -rl 'KSAFE 1' tables | xargs sed -i 's/KSAFE 1//g'
</code></pre>

<p>This will search for the string <code>KSAFE 1</code> in all files in the <code>tables</code> directory and replace <code>KSAFE 1</code> with nothing <code>''</code> for each occurrence of the string in each file.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Set Up Public-key SSH on Windows]]></title>
    <link href="http://tdongsi.github.io/blog/2015/03/22/install-ssh-on-windows/"/>
    <updated>2015-03-22T11:57:33-07:00</updated>
    <id>http://tdongsi.github.io/blog/2015/03/22/install-ssh-on-windows</id>
    <content type="html"><![CDATA[<p>Setting up public-key SSH on Windows is much more tricky than Linux (see <a href="/blog/2015/03/02/install-ssh-on-linux/">here</a>).</p>

<h3>Install OpenSSH for Windows</h3>

<p>In the following instructions, the example machine hostname (SSH server) is <code>frak16</code>, with username <code>oqa</code> in the domain <code>OBJY</code>.
Sometimes, another machine (client) is used to connect to this <code>frak16</code> machine to test connection settings.</p>

<p>(1) Install OpenSSH for Windows to the SSH server, e.g., <code>frak16</code>, at the following location <code>SSH_DIR=C:\space\oqa\OpenSSH</code>.
Use OpenSSH installer from <a href="http://www.mls-software.com/opensshd.html">here</a>.
Do NOT use OpenSSH for Windows from Sourceforge, which is outdated, even though many top links from Google search &ldquo;OpenSSH windows&rdquo; point to it.
Select &ldquo;Configure as Domain User&rdquo; when installing.</p>

<p>(2) In the <code>PATH</code> environment variable, make sure that <code>$(SSH_DIR)\bin</code> folder comes before MKS and Cygwin&rsquo;s bins folder, if applicable.
We need to use OpenSSH version of <code>chmod</code> and <code>chown</code>.</p>

<p>(3) Edit the file <code>etc/passwd</code> inside <code>SSH_DIR</code> (defined above).
Make sure that the home directory for your username is present and in <strong>Cygwin notation</strong>, e.g., &ldquo;/cygdrive/c/space/oqa&rdquo; for user <code>oqa</code>.
Make sure there is only one <code>oqa</code> user, like <code>U-OBJY\oqa</code> (domain user) for <code>OBJY</code> domain.
Delete other <code>oqa</code> users such as local users if needed.</p>

<pre><code>oqa:unused_by_nt/2000/xp:13331:10513:oqa,U-OBJY\oqa,S-1-5-21-343818398-1708537768-1417001333-3331:/cygdrive/c/space/oqa:/bin/switch
</code></pre>

<p>(4) Edit <code>$(SSH_DIR)\etc\banner.txt</code> to include welcome message that you prefer, to make it less verbose and more informative. I would change it to include the current host name to indicate which host is currently connected.</p>

<p>(5a) (Optional but recommended) Run SSH server is debug mode to verify that settings are correct. Run the following command for a test run:</p>

<pre><code>C:\space\cuongd\OpenSSH&gt;usr\sbin\sshd -d -d -d
</code></pre>

<p>(5b) Use ssh from another host (as client) to test connection. You will have to enter username and password to connect to <code>frak16</code> from this client.</p>

<pre><code class="plain From another machine as client">ssh username@hostname -v

### Example
ssh oqa@frak16 -v
</code></pre>

<p>If the client is Windows and using OpenSSH, make sure the client&rsquo;s <code>etc/ssh_config</code> file in its OpenSSH installation folder is as follows:</p>

<pre><code class="plain ssh_config">
# Site-wide defaults for various options

# Host *
#   ForwardAgent no
#   ForwardX11 no
#   RhostsAuthentication no
#   RhostsRSAAuthentication yes
#   RSAAuthentication yes
#   PasswordAuthentication yes
#   FallBackToRsh no
#   UseRsh no
#   BatchMode no
#   CheckHostIP yes
#   StrictHostKeyChecking yes
#   IdentityFile ~/.ssh/identity
#   IdentityFile ~/.ssh/id_dsa
IdentityFile /cygdrive/c/space/cuongd/.ssh/id_rsa    &lt;--- Verify THIS
#   Port 22
#   Protocol 2,1
#   Cipher blowfish
#   EscapeChar ~
</code></pre>

<p>(6) After making sure the SSH is installed and working properly on <code>frak16</code>, run the following in a Command prompt with Admin power to start SSH as a service:</p>

<pre><code>net start opensshd
</code></pre>

<p>Now, you can connect to this Windows machine <code>frak16</code> using password authentication.</p>

<h3>Set up public-key SSH</h3>

<p>(1) If the client is already set up, it should have its public key file. Copy content of that file to <code>$(HOME_DIR)\.ssh\authorized_keys</code> file on the SSH server (e.g., <code>frak16</code>).</p>

<p>If you don&rsquo;t have the public key file for the client, run <code>ssh-keygen -t rsa</code> on the client machine.
The client machine&rsquo;s public key file has the name like &ldquo;id_rsa.pub&rdquo;.</p>

<p>(2) On the SSH server (e.g., <code>frak16</code>), edit <code>$(SSH_DIR)\etc\sshd_config</code> to enable PubkeyAuthentication. The following lines must be enabled:</p>

<pre><code class="plain sshd_config">RSAAuthentication yes
PubkeyAuthentication yes
</code></pre>

<p>(3) Recursively from <code>$(HOME_DIR)</code>, use <code>chown</code> to set ownership to <code>oqa</code> and <code>chmod</code> to set all folders and files in <code>$(HOME_DIR)\.ssh</code> to read-only.</p>

<pre><code class="plain Set ownership and access">### Set the ownership to user oqa
c:\space\oqa&gt;chown -R oqa .
c:\space\oqa&gt;chmod -R 700 .ssh
c:\space\oqa\.ssh&gt;chmod 600 authorized_keys
</code></pre>

<p>(4) Run SSH server in debug mode again to verify that public-key SSH settings are correct.
Run this command &ldquo;ssh oqa@frak16 &lsquo;ipconfig&rsquo;&rdquo; from the client machine and verify that no password is required.</p>

<p>(5) Start SSH server permanently by running, in an elevated Command Prompt.
As of 2015 Feb, I tried running SSH as a Windows service but it does not work reliably.</p>

<pre><code class="plain Start SSH">$(SSH_DIR)\usr\sbin\sshd.exe
</code></pre>

<h3>Troubleshooting</h3>

<p>Some of the most frequently encountered problems are discussed in this section.</p>

<h4>Ownership of <code>.ssh</code> folder</h4>

<p>You might encounter this problem when configuring public-key authentication.
If you try to run the server in debug mode, you might see the following messages:</p>

<pre><code class="plain SSH server output in debug mode (sshd -d -d -d)">debug2: input_userauth_request: try method publickey
debug1: test whether pkalg/pkblob are acceptable
debug1: temporarily_use_uid: 13331/10513 (e=13331/10513)
debug1: trying public key file /cygdrive/c/space/oqa/.ssh/authorized_keys
debug3: secure_filename: checking '/cygdrive/c/space/oqa/.ssh'
Authentication refused: bad ownership or modes for directory /cygdrive/c/space/o
qa/.ssh
</code></pre>

<p>In this case, it&rsquo;s an ownership problem on the SSH server.
You can try another location for <code>.ssh</code> folder on the SSH server to see if it resolves the problem.
In most cases, you can manually fix the above problem by using the following commands:</p>

<pre><code class="plain">### Set the ownership to user oqa
c:\space\oqa&gt;chown -R oqa .
c:\space\oqa&gt;chmod -R 700 .ssh
c:\space\oqa\.ssh&gt;chmod 600 authorized_keys
</code></pre>

<p>Note that <code>chmod</code> from OpenSSH must be used, instead of <code>chmod</code> from MKS or Cygwin.
In addition, if there is a Local User <code>oqa</code>, remove that user so that <code>chown</code> will assign ownership to Domain User <code>oqa</code>.</p>

<h4>Outdated SSH installer</h4>

<pre><code class="plain">C:\space\cuongd&gt;scp test.txt oqa@frak16:/cygdrive/c/space/oqa

Received disconnect from 172.21.62.116: 2: fork failed: Resource temporarily una
vailable
lost connection
</code></pre>

<p>If you see errors like this, you probably used OpenSSH installer from Sourceforge.
That installer is outdated and buggy.
Use the latest installer from <a href="http://www.mls-software.com/opensshd.html">here</a> instead.</p>

<h4>Cannot bind any address</h4>

<p>You might find the following error message when connecting to an SSH server running in debug mode.</p>

<pre><code class="plain">debug1: rexec_argv[3]='-d'
debug2: fd 3 setting O_NONBLOCK
debug3: sock_set_v6only: set socket 3 IPV6_V6ONLY
debug1: Bind to port 22 on ::.
Bind to port 22 on :: failed: Address already in use.
debug2: fd 3 setting O_NONBLOCK
debug1: Bind to port 22 on 0.0.0.0.
Bind to port 22 on 0.0.0.0 failed: Address already in use.
Cannot bind any address.
</code></pre>

<p>If you installed Cygwin and/or MKS on your Windows SSH server, their SSH services (sshd for Cygwin and secshd for MKS) are probably using the port 22.
Verify that by using the following command in Windows:</p>

<pre><code class="plain Check service usage">C:\space\cuongd\OpenSSH&gt;netstat -b -a

Active Connections

  Proto  Local Address          Foreign Address        State
  TCP    0.0.0.0:22             frak15:0               LISTENING
[secshd.exe]
  TCP    0.0.0.0:23             frak15:0               LISTENING
[telnetd.exe]
  TCP    0.0.0.0:135            frak15:0               LISTENING
  RpcSs
[svchost.exe]
</code></pre>

<p>You can turn off SSH services from Cygwin and MKS by going to Computer > Manage > Go to Services > Stop the relevant service (Windows 7).</p>

<h4>File transfer</h4>

<p>If you installed <code>putty</code> on Windows, note that you CANNOT simply use <code>pscp</code> (that is included with <code>putty</code> installation) to transfer file to another Windows machine with OpenSSH.</p>

<pre><code class="plain PSCP error">C:\space\cuongd&gt;pscp -i C:\space\cuongd\.ssh\id_rsa_putty test.txt oqa@frak16:/cygdrive/c/space/oqa
Error: Unable to use key file "C:\space\cuongd\.ssh\id_rsa" (OpenSSH SSH-2 private key)
</code></pre>

<p>You have to convert the OpenSSH&rsquo;s generated private key to a Putty private key, as detailed <a href="http://www.cnx-software.com/2012/07/20/how-use-putty-with-an-ssh-private-key-generated-by-openssh/">here</a>.</p>

<p>An alternative is to use <code>scp</code> that is included with the OpenSSH installation. Note that this might not work (you still have to enter your password):</p>

<pre><code class="plain This will not work. Password required.">C:\space\cuongd&gt;scp -i C:\space\cuongd\.ssh\id_rsa test.txt oqa@frak16:/cygdrive/c/space/oqa
</code></pre>

<p>Since OpenSSH for Windows is extracted from Cygwin, trying Cygwin-style command turns out to be a good idea. This command allows password-less file transfer:</p>

<pre><code class="plain Password NOT required.">C:\space\cuongd&gt;scp -i /cygdrive/c/space/cuongd/.ssh/id_rsa test.txt oqa@frak16:/cygdrive/c/space/oqa
</code></pre>

<p>Note that files transferred over <code>scp</code> may not be readable (mode 000), regardless of file mode on the sending host.
Therefore, remember to <code>chmod a+r</code> on the receiving host after file transfer, especially in an automation script, or you&rsquo;ll get errors related to file access/file not found.</p>

<h4>Other troubleshooting tips</h4>

<ul>
<li>You may miss adding/setting some environment variables, e.g., <code>PATH</code>. After editing environment variables, you may need to restart your SSHD on a <strong>new</strong> Command Prompt windows to have those new environment variables in effect.</li>
<li>Remember to disable firewall on Windows machines.</li>
</ul>


<h3>Links</h3>

<ol>
<li><a href="http://www.mls-software.com/opensshd.html">Latest OpenSSH installer</a></li>
<li><a href="http://www.cnx-software.com/2012/07/20/how-use-putty-with-an-ssh-private-key-generated-by-openssh/">Use Putty with an SSH private key generated by OpenSSH</a></li>
<li><a href="http://www.worldgoneweb.com/2011/installing-openssh-on-windows-7/">And old tutorial</a>: uses an old OpenSSH installer from Sourceforge. Most of the steps are not needed in the new installers.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Set Up Public-key SSH on Linux]]></title>
    <link href="http://tdongsi.github.io/blog/2015/03/02/install-ssh-on-linux/"/>
    <updated>2015-03-02T10:57:26-08:00</updated>
    <id>http://tdongsi.github.io/blog/2015/03/02/install-ssh-on-linux</id>
    <content type="html"><![CDATA[<p>(1) Log into a Linux system (for CentOS, v5.8 or better) with your user account.</p>

<p>(2) Go to the directory <code>~/.ssh</code>. If such directory is not present, create one and set the permissions to 755.</p>

<pre><code>mkdir ~/.ssh
chmod 755 ~/.ssh
cd ~/.ssh
</code></pre>

<p>(3) Generate your private and public keys</p>

<pre><code>[frak10-b13]$ ssh-keygen
</code></pre>

<p>When you get &ldquo;Enter passphrase (empty for no passphrase):&rdquo;, you can hit enter for a null passphrase for now.
The passphrase can be changed later by using the -p option.
Note that from the <code>man</code> page: &ldquo;USING GOOD, UNGUESSABLE PASSPHRASES IS STRONGLY RECOMMENDED.&rdquo;.
If <code>ssh-keygen</code> returns with &ldquo;You must specify a key type (-t).&rdquo;, then add the flag &ldquo;-t rsa&rdquo;.</p>

<p>(4) The ssh-keygen tool stores the private key in <code>$HOME/.ssh/id_rsa</code> and the public key in <code>$HOME/.ssh/id_rsa.pub</code> in the userâ€™s home directory.
The user should then copy the contents of <code>id_rsa.pub</code> to the <code>$HOME/.ssh/authorized_keys</code> file in his home directory on the <strong>remote</strong> machine.
Verify that you have and authorized_keys file in ~/.ssh. If not create one and set the permissions:</p>

<pre><code>cat id_rsa.pub &gt;&gt; authorized_keys
chmod 644 ~/.ssh/authorized_keys
</code></pre>

<p>Verify that you have a known_hosts file <code>~/.ssh/known_hosts</code>.
If not, you can begin to populate this file by doing an ssh session to the system you want to connect to and
answer <code>yes</code> to this question:</p>

<pre><code>The authenticity of host 'reda64 (172.21.32.38)' can't be established.
RSA key fingerprint is 3f:39:60:a8:b6:c7:37:e6:a6:ff:f5:d2:0b:fc:86:83.
Are you sure you want to continue connecting (yes/no)?
</code></pre>

<h3>Links</h3>

<ol>
<li><a href="https://en.wikipedia.org/wiki/Ssh-keygen">ssh-keygen</a></li>
</ol>

]]></content>
  </entry>
  
</feed>
