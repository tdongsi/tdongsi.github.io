<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Java | Personal Programming Notes]]></title>
  <link href="http://tdongsi.github.io/blog/categories/java/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/"/>
  <updated>2019-01-04T13:41:58-08:00</updated>
  <id>http://tdongsi.github.io/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[IntelliJ Setup for Jenkins Development]]></title>
    <link href="http://tdongsi.github.io/blog/2018/02/09/intellij-setup-for-jenkins-shared-library-development/"/>
    <updated>2018-02-09T21:32:59-08:00</updated>
    <id>http://tdongsi.github.io/blog/2018/02/09/intellij-setup-for-jenkins-shared-library-development</id>
    <content type="html"><![CDATA[<p>This posts will show how to setup IntelliJ for development of Jenkins <a href="/blog/2017/12/30/groovy-hook-script-and-jenkins-configuration-as-code/">Groovy Init Scripts</a> and <a href="https://jenkins.io/doc/book/pipeline/shared-libraries/">shared libraries</a>, including auto-complete for <a href="https://jenkins.io/doc/pipeline/steps/">Jenkins pipeline steps</a>.
This is based on my original write-up in <a href="https://github.com/tdongsi/jenkins-config/blob/develop/docs/IDE.md">this project</a>.</p>

<!--more-->


<p>NOTE: this setup is NOT intended for Jenkins plugin or core development.</p>

<h3>Start a new Gradle project</h3>

<p>It is best to start a new project:</p>

<ol>
<li>Select <strong>File | New Project</strong></li>
<li>Select <strong>Gradle</strong></li>
<li>Select <strong>Java</strong> AND <strong>Groovy</strong>
<img src="/images/idea/screen01.png" title="Start" alt="Screeshot" /></li>
<li>Choose <strong>GroupId</strong> and <strong>ArtifactId</strong>
<img src="/images/idea/screen02.png" title="Project Name" alt="Screeshot" /></li>
<li>Enter path to Gradle. For Gradle on Mac installed via Homebrew, the Gradle home is like this:
<img src="/images/idea/screen03.png" title="Configure Gradle" alt="Screeshot" />
NOTE: For Gradle installed on a Mac via Homebrew, the path &ldquo;/usr/local/opt/gradle/libexec&rdquo; may be preferrable to &ldquo;/usr/local/Cellar/gradle/X.X/libexec&rdquo; since the former will stay the same after Gradle version upgrades.
In addition, if you work extensively with Grails/Gradle/Groovy, you may prefer installing via <a href="https://sdkman.io/install"><code>sdk</code> tool</a> instead of Homebrew.</li>
<li>Choose <strong>Project name</strong> and <strong>Project Location</strong>
<img src="/images/idea/screen04.png" title="Project location" alt="Screeshot" /></li>
<li>Finish
<img src="/images/idea/screen05.png" title="Finish" alt="Screeshot" /></li>
</ol>


<h3>Configure IDEA</h3>

<p>Set up for Jenkins Plugins files which are of types <strong>.hpi</strong> or <strong>.jpi</strong>.</p>

<ol>
<li>Select <strong>IntelliJ IDEA | Preferences | Editor | File Types</strong></li>
<li>Select <strong>Archive</strong></li>
<li>Select <strong>+</strong> at the bottom left corner</li>
<li>Add both <strong>.hpi</strong> and <strong>.jpi</strong></li>
<li>Select <strong>OK</strong></li>
</ol>


<p><img src="/images/idea/screen06.png" title="Configure plugin files" alt="Screeshot" /></p>

<p>Modify <strong>build.gradle</strong> to add the following lines.</p>

<pre><code class="groovy">    compile 'org.jenkins-ci.main:jenkins-core:2.23'

    // Jenkins plugins
    compile group: 'org.jenkins-ci.plugins', name: 'credentials', version: '2.1.13', ext: 'jar'
    compile group: 'org.jenkins-ci.plugins', name: 'matrix-auth', version: '1.6', ext: 'jar'
    compile group: 'org.jenkins-ci.plugins.workflow', name: 'workflow-cps', version: '2.39', ext: 'jar'

    // TRICKY: The lib folder contains all other plugins *JAR* files
    // if not found in Maven
    compile fileTree(dir: 'lib', include: ['*.jar'])
</code></pre>

<p>The above example will grab Jenkins core libraries, Matrix Authorization Plugin hpi, other plugin dependencies and javadocs for all imported libraries.
Having these libraries imported will enable code auto-completion, syntax checks, easy refactoring when working with Groovy scripts for Jenkins.
It will be a great productivity boost.</p>

<p>NOTE 1: The last line <code>compile fileTree</code> is the last resort for any Jenkins plugins that you cannot find the right group ID and artifact ID.
It is rare these days but such cases cannot be completely ruled out.</p>

<p>NOTE 2: The <code>ext: 'jar'</code> is VERY important to ensure that <code>jar</code> files, instead of <code>hpi</code>/<code>jpi</code> files, are being downloaded and understood by IntellJ.
Without that <code>ext</code> option specified, IntellJ won&rsquo;t find JAR files nested in <code>hpi</code>/<code>jpi</code> files which is the default binaries for Jenkins plugins.</p>

<p>The final <strong>build.gradle</strong> will look like <a href="https://github.com/tdongsi/jenkins-steps-override/blob/master/build.gradle">this</a>.
All of the above setup should suffice for working with <a href="http://tdongsi.github.io/blog/2017/12/30/groovy-hook-script-and-jenkins-configuration-as-code/">Groovy Init Scripts</a>.
For working with Jenkins Shared Pipeline Libraries, we should take one extra step shown as follows.</p>

<h3>Setup for Jenkins pipeline library</h3>

<p>All Groovy files in Jenkins shared library for Pipelines have to follow this directory structure:</p>

<pre><code class="text Directory structure of a Shared Library repository">(root)
+- src                     # Groovy source files
|   +- org
|       +- foo
|           +- Bar.groovy  # for org.foo.Bar class
+- vars
|   +- foo.groovy          # for global 'foo' variable
|   +- foo.txt             # help for 'foo' variable
+- resources               # resource files (external libraries only)
|   +- org
|       +- foo
|           +- bar.json    # static helper data for org.foo.Bar
</code></pre>

<p>Note that the Groovy code can be in both <a href="http://tdongsi.github.io/blog/2017/12/26/class-in-jenkins-shared-library/"><code>src</code></a>
and <a href="http://tdongsi.github.io/blog/2017/03/17/jenkins-pipeline-shared-libraries/"><code>vars</code></a> folders.
Therefore, you need to add the following lines in <code>build.gradle</code> to inform Gradle locations of Groovy source codes:</p>

<pre><code class="groovy">sourceSets {
    main {
        groovy {
            srcDirs = ['vars', 'src']
        }
    }

    test {
        groovy {
            srcDirs = ['test']
        }
    }
}
</code></pre>

<p>Optionally, for unit testing Jenkins shared library, we have to add the following dependencies into our <strong>build.gradle</strong> file.</p>

<pre><code class="groovy">    testCompile group: 'com.lesfurets', name: 'jenkins-pipeline-unit', version: '1.1'
    testCompile group: 'org.spockframework', name: 'spock-core', version: '1.1-groovy-2.4'
</code></pre>

<p>Please see <a href="/blog/2018/06/07/jenkins-pipeline-unit-testing/">this blog post</a> for more details on unit testing.
The final <strong>build.gradle</strong> will look like <a href="https://github.com/tdongsi/jenkins-steps-override/blob/master/build.gradle">this</a>.</p>

<h4>Auto-completion for Jenkins Pipeline</h4>

<p>IntelliJ can&rsquo;t auto-complete <a href="https://jenkins.io/doc/pipeline/steps/">Jenkins pipeline steps</a> such as <code>echo</code> or <code>sh</code> out of the box.
We have to make it aware of those Jenkins pipeline DSLs, via a generic process explained <a href="https://confluence.jetbrains.com/display/GRVY/Scripting+IDE+for+DSL+awareness">here</a>.
Fortunately, it is much easier than it looks and you don&rsquo;t have to actually write GroovyDSL script for tens of Jenkins pipeline steps.
Jenkins make it easy by auto-generating the GroovyDSL script and it is accessible via &ldquo;IntelliJ IDEA GDSL&rdquo; link, as shown in screenshot below.</p>

<p><img src="/images/idea/screen08.png" title="GroovyDSL" alt="Screeshot" /></p>

<p>The &ldquo;IntelliJ IDEA GDSL&rdquo; link can be found by accessing &ldquo;Pipeline Syntax&rdquo; section, which is visible in the left navigation menu of any Pipeline-based job (e.g., &ldquo;Admin&rdquo; job in the example above).
After clicking on the &ldquo;IntelliJ IDEA GDSL&rdquo; link, you will be able to download a plain text file with content starting like this:</p>

<pre><code class="groovy IntelliJ IDEA GDSL">//The global script scope
def ctx = context(scope: scriptScope())
contributor(ctx) {
method(name: 'build', type: 'Object', params: [job:'java.lang.String'], doc: 'Build a job')
method(name: 'build', type: 'Object', namedParams: [parameter(name: 'job', type: 'java.lang.String'), parameter(name: 'parameters', type: 'Map'), parameter(name: 'propagate', type: 'boolean'), parameter(name: 'quietPeriod', type: 'java.lang.Integer'), parameter(name: 'wait', type: 'boolean'), ], doc: 'Build a job')
method(name: 'echo', type: 'Object', params: [message:'java.lang.String'], doc: 'Print Message')
method(name: 'error', type: 'Object', params: [message:'java.lang.String'], doc: 'Error signal')
...
</code></pre>

<p>As you can see, it is a GroovyDSL file that describes the known pipeline steps such as <code>echo</code> and <code>error</code>.
Note that GDSL files can be different for different Jenkins instances, depending on Pipeline-supported plugins currently installed on individual Jenkins instance.
To make IntelliJ aware of the current Jenkins pipeline steps available on our Jenkins, we need to place that GDSL file into a location known to source folders.
As shown in the last section, anywhere in both <code>vars</code> and <code>src</code> folders are eligible as such although I personally prefer to put the GDSL file into <code>vars</code> folder (<a href="https://github.com/tdongsi/jenkins-steps-override/tree/master/vars">for example</a>).</p>

<p>After installing the GDSL file into a proper location, IntelliJ may complain with the following message <em>DSL descriptor file has been change and isn’t currently executed</em> and you have to click <strong>Activate back</strong> to get the IntelliJ aware of the current DSLs.
After that, you can enjoy auto-completion as well as documentation of the Jenkine Pipeline DSLs.</p>

<h3>More information</h3>

<ul>
<li><a href="https://github.com/tdongsi/jenkins-steps-override">Example of final setup</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Jacoco in Maven Projects]]></title>
    <link href="http://tdongsi.github.io/blog/2017/09/23/jacoco-in-maven-project/"/>
    <updated>2017-09-23T21:39:13-07:00</updated>
    <id>http://tdongsi.github.io/blog/2017/09/23/jacoco-in-maven-project</id>
    <content type="html"><![CDATA[<p>This blog post goes over some recipes for adding code coverage report to Maven-based projects with Jacoco.</p>

<!--more-->


<h3>Standard usage</h3>

<p>Based on <a href="http://www.eclemma.org/jacoco/trunk/doc/maven.html">offical instruction</a> and <a href="https://stackoverflow.com/questions/36199422/maven-unit-test-code-coverage">this</a>, you need to add the following code snippet in to your Maven <code>pom.xml</code>.</p>

<pre><code class="xml Jacoco usage (typical Maven project)">&lt;project&gt;
...

    &lt;dependencies&gt;
        ...
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            ...
            &lt;!-- Code Coverage report generation --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.jacoco&lt;/groupId&gt;
                &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt;
                &lt;version&gt;0.7.9&lt;/version&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;prepare-agent&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                    &lt;execution&gt;
                        &lt;id&gt;generate-code-coverage-report&lt;/id&gt;
                        &lt;phase&gt;test&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;report&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;
</code></pre>

<p>At least, you need &ldquo;prepare-agent&rdquo; before test phase for Jacoco instrumentation and &ldquo;report&rdquo; after test phase for generating the report.
You could subject the project to code coverage and generate the same report without making any changes to the pom file.
To do this, run the following command:</p>

<pre><code class="plain Jacoco from Maven command-line">mvn jacoco:prepare-agent test jacoco:report
</code></pre>

<p>You may get the following error:</p>

<pre><code class="plain">[ERROR] No plugin found for prefix 'jacoco' in the current project ...
</code></pre>

<p>There are two options to fix that error.
The easiest way is to specify the <code>groupId</code> and <code>artifactId</code> parameters of the plugin explicitly.
You can also add <code>version</code> to ensure the stability of your build pipeline.</p>

<pre><code class="plain">mvn clean org.jacoco:jacoco-maven-plugin:0.7.9:prepare-agent install org.jacoco:jacoco-maven-plugin:0.7.9:report
</code></pre>

<p>The more long-term solution is to add the following in to your Maven &ldquo;settings.xml&rdquo;.</p>

<pre><code class="xml Maven settings">&lt;pluginGroups&gt;
    &lt;pluginGroup&gt;org.jacoco&lt;/pluginGroup&gt;
&lt;/pluginGroups&gt;
</code></pre>

<h3>Tests with Mock</h3>

<p>If mocking is involved in unit tests, you need to use “instrument” and “restore-instrumented” steps.</p>

<p>Reference:</p>

<ul>
<li><a href="https://github.com/powermock/powermock/wiki/Code-coverage-with-JaCoCo">PowerMock instruction</a></li>
<li><a href="https://github.com/powermock/powermock-examples-maven/blob/master/jacoco-offline/pom.xml">PowerMock example pom.xml</a></li>
</ul>


<h3>Multi-module Maven projects</h3>

<p>Officially, multi-module Maven projects are supported differently by Jacoco as documented <a href="https://github.com/jacoco/jacoco/wiki/MavenMultiModule">here</a>.
Instrumentation will be similar but the challenge of multi-module Maven projects lies in how to collect and report code coverage of all modules correctly.
Jacoco Maven standard goals, as shown in sections above, work on single modules only: Tests are executed within the module and contributed coverage only to code within the same module.
Coverage reports were created for each module separately.</p>

<p>In the past, there are some ad-hoc solutions such as <a href="https://dzone.com/articles/jacoco-maven-multi-module">this</a> (for Jacoco 0.5.x) to work around that limit.
However, those patterns are also error-prone and hard to customize, especially when Jacoco is used with Surefire plugin.
Fortunately, Jacoco recently introduced a new Maven goal &ldquo;report-aggregate&rdquo; in its release 0.7.7 which will aggregate code coverage data across Maven modules.
Its usage is also present in the same <a href="https://github.com/jacoco/jacoco/wiki/MavenMultiModule">link</a> (quoted below) but it is too succint and not very helpful for new users.</p>

<p><blockquote><p>Create a dedicated module in your project for generation of the report. This module should depend on all or some other modules in the project.</p></blockquote></p>

<p>Let' say you have a multi-module Maven project with this structure:</p>

<pre><code class="plain Multi-module Maven project">root pom
  |- module a
  |- module b
  |- module c
</code></pre>

<p>To use Jacoco &ldquo;report-aggregate&rdquo; goal for these modules, you first need to add a dedicated &ldquo;coverage&rdquo; module.
This &ldquo;coverage&rdquo; module should be added into the root POM.
The multi-module Maven project should now look like this:</p>

<pre><code class="plain Multi-module Maven project with aggregate coverage module">root pom
  |- module a
  |- module b
  |- module c
  |- module "coverage"
</code></pre>

<p>The POMs for each module does not need to change at all.
The POM for the &ldquo;coverage&rdquo; module will look like this:</p>

<pre><code class="xml Maven pom.xml for coverage module">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;parent&gt;
        &lt;groupId&gt;com.company&lt;/groupId&gt;
        &lt;artifactId&gt;company-pom&lt;/artifactId&gt;
        &lt;version&gt;3.0&lt;/version&gt;
    &lt;/parent&gt;

    &lt;artifactId&gt;report&lt;/artifactId&gt;
    &lt;name&gt;Jacoco Report&lt;/name&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;my.example&lt;/groupId&gt;
            &lt;artifactId&gt;module-a&lt;/artifactId&gt;
            &lt;version&gt;210.0.00-SNAPSHOT&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;my.example&lt;/groupId&gt;
            &lt;artifactId&gt;module-b&lt;/artifactId&gt;
            &lt;version&gt;210.0.00-SNAPSHOT&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;my.example&lt;/groupId&gt;
            &lt;artifactId&gt;module-c&lt;/artifactId&gt;
            &lt;version&gt;210.0.00-SNAPSHOT&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.jacoco&lt;/groupId&gt;
                &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt;
                &lt;version&gt;0.7.9&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;excludes&gt;
                        &lt;!-- Example of excluding classes 
                        &lt;exclude&gt;**/com/company/config/AutoConfiguration.class&lt;/exclude&gt;
                        --&gt;
                    &lt;/excludes&gt;
                &lt;/configuration&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;id&gt;report-aggregate&lt;/id&gt;
                        &lt;phase&gt;verify&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;report-aggregate&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;

            &lt;!-- This coverage module should never be deployed --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;skip&gt;true&lt;/skip&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;
</code></pre>

<p>Note that we still require &ldquo;prepare-agent&rdquo; step to run before the first test suite.
Depending on what plugins are being used and how the modules are organized within the project, we might have different setup for that particular step.
One option is to run from the command-line:</p>

<pre><code>tdongsi$ ls
Dockerfile              README.md               module1       pom.xml
Jenkinsfile             coverage                module2       scripts

tdongsi$ mvn -B clean org.jacoco:jacoco-maven-plugin:0.7.9:prepare-agent install
</code></pre>

<p>Links:</p>

<ul>
<li><a href="https://stackoverflow.com/questions/13031219/how-to-configure-multi-module-maven-sonar-jacoco-to-give-merged-coverage-rep/37871210#37871210">Example of report-aggregate</a></li>
<li><a href="https://github.com/jacoco/jacoco/tree/master/jacoco-maven-plugin.test/it/it-report-aggregate">Example Maven project</a></li>
</ul>


<h4>Customizations</h4>

<p>In theory, a global threshold can be defined in <code>coverage/pom.xml</code> to enforce code coverage standard across teams.
However, in practice, different teams are at different stages of module/service maturity and blindly having a global threshold will hamper teams working on newer services/modules.
In addition, it does not make sense to enforce code coverage on some Maven modules such as those generated in GRPC.</p>

<p>In Jacoco, you can set different coverage limits for individual modules instead of a global threshold for all modules.
In the following example, you can specify a coverage threshold for module A by modifying module A&rsquo;s pom.xml file:</p>

<pre><code class="xml Module A's pom.xml">...

&lt;/plugins&gt;
...
    &lt;plugin&gt;
        &lt;groupId&gt;com.atlassian.maven.plugins&lt;/groupId&gt;
        &lt;artifactId&gt;maven-clover2-plugin&lt;/artifactId&gt;
    &lt;/plugin&gt;

    &lt;plugin&gt;
        &lt;groupId&gt;org.jacoco&lt;/groupId&gt;
        &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt;
        &lt;version&gt;0.7.9&lt;/version&gt;

        &lt;executions&gt;
            &lt;execution&gt;
                &lt;id&gt;check&lt;/id&gt;
                &lt;goals&gt;
                &lt;goal&gt;check&lt;/goal&gt;
                &lt;/goals&gt;
                &lt;configuration&gt;
                    &lt;!-- NOTE: Set haltOnFailureto true when code coverage is enforced --&gt;
                    &lt;haltOnFailure&gt;false&lt;/haltOnFailure&gt;

                    &lt;rules&gt;
                        &lt;rule &gt;
                            &lt;element&gt;CLASS&lt;/element&gt;
                            &lt;limits&gt;
                                &lt;limit &gt;
                                    &lt;counter&gt;LINE&lt;/counter&gt;
                                    &lt;value&gt;COVEREDRATIO&lt;/value&gt;
                                    &lt;minimum&gt;0.80&lt;/minimum&gt;
                                &lt;/limit&gt;
                                &lt;limit &gt;
                                    &lt;counter&gt;BRANCH&lt;/counter&gt;
                                    &lt;value&gt;COVEREDRATIO&lt;/value&gt;
                                    &lt;minimum&gt;0.80&lt;/minimum&gt;
                                &lt;/limit&gt;
                            &lt;/limits&gt;
                            &lt;excludes&gt;
                                &lt;!-- 
                                &lt;exclude&gt;com.test.ExampleExclusion&lt;/exclude&gt;
                                --&gt;
                            &lt;/excludes&gt;
                        &lt;/rule&gt;
                    &lt;/rules&gt;
                &lt;/configuration&gt;
            &lt;/execution&gt;
        &lt;/executions&gt;
    &lt;/plugin&gt;
&lt;/plugins&gt;
</code></pre>

<p>As you can see, you can also specify files being excluded from coverage calculation.</p>

<h3>References</h3>

<ul>
<li><a href="http://www.jacoco.org/jacoco/trunk/doc/maven.html">Jacoco Maven plugin</a>: there are example POMs.</li>
</ul>


<!--
* [Cross-module reporting](https://stackoverflow.com/questions/41885772/jacoco-simple-integration-test-solution/41901853#41901853)
-->

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[DSL Implementation in Groovy]]></title>
    <link href="http://tdongsi.github.io/blog/2017/08/13/groovy-dsl/"/>
    <updated>2017-08-13T15:18:30-07:00</updated>
    <id>http://tdongsi.github.io/blog/2017/08/13/groovy-dsl</id>
    <content type="html"><![CDATA[<p>Domain-Specific Language is a mini language for a specific problem and/or in a narrow context.
For example, internally used automation tools usually define some small DSL for configuration and most users understand the context and what DSL offers.</p>

<p>This blog post offers my simplistic view of how an internal DSL is implemented in Groovy via closure delegation.
It shows the progression from standard Java-like implementation -> its fluent version -> final DSL form.
This might help undrestanding the inner workings of a DSL such as Jenkins&rsquo;s Pipeline steps.
There are probably more advanced methods/frameworks for creating DSL.
However, those are not in the scope of this post.</p>

<!--more-->


<h3>Example DSL</h3>

<p>We want to implement a simple DSL that is similar to <a href="https://jenkins.io/doc/pipeline/steps/">Pipeline steps in Jenkinsfile</a>.</p>

<pre><code class="plain DSL in Jenkinsfile">{
    withEnv("PATH=/usr/bin")
    echo("Starting pipeline")
    sh("ls .")
    error("Error here")
}
</code></pre>

<p>In this DSL example, users will write a sequence of steps using a small, pre-defined set of custom statements such as <code>echo</code> and <code>sh</code> above.
For each step in the DSL, the backend classes and objects will perform some execution in the background, using the relevant context specific to the domain (e.g., Jenkins domain).
For simplicity, <code>println</code> statements will be used in the following examples.</p>

<p>The advantage of DSL is that the <strong>developers</strong> can implement the backend in some fully-featured language such as Java but the <strong>users</strong> don&rsquo;t need to know such language to use it.
Such a separation is common in DevOps and automation frameworks where the users want the flexibility of configuring based on their needs but don&rsquo;t want to get exposed to the implementation details (which are usually ugly and compplicated).
Instead, the <strong>users</strong> only need to learn the DSL to use it while still have the flexibility to do what they want.
One example can be found in data science domain where data scientists are usually more comfortable developing in R or SQL but automated deployment frameworks or tools can be in another language such as Java.</p>

<h3>Version 1: Java-like standard implementation</h3>

<p>First, we show a standard implementation in Java to show how backend execution can be implemented.
In the advanced versions, the difference is only in its public interface to make it more user-friendly but the backend execution will be similar.</p>

<pre><code class="groovy Standard Java implementation">/**
 * Java code with standard implementation
 * Try to simulate some kind of DSL like Pipeline steps in Jenkins
 */
class JavaDsl {

    void echo(String message) {
        println "Echo: $message";
    }

    void sh(String script) {
        println "Shell: $script";
    }

    void error(String message) {
        println "Error here: $message";
    }

    // A more advanced DSL
    void withEnv(String var) {
        println "Using: $var";
    }

    void execute() {
        println "Executing ...";
    }

}

println "1) Standard Java implementation";
JavaDsl javaDsl = new JavaDsl();
javaDsl.withEnv("PATH=/usr/bin");
javaDsl.echo("Starting pipeline");
javaDsl.sh("ls .");
javaDsl.error("Error here");
javaDsl.execute();
println "";
</code></pre>

<p>The problem of this approach is that users have to write Java (or Groovy) code directly to use it.</p>

<h3>Version 2: Fluent interface with Builder pattern</h3>

<pre><code class="groovy Fluent Java implementation">/**
 * Java code with Builder pattern
 * Try to simulate some kind of DSL like Pipeline steps in Jenkins
 */
class JavaBuilderDsl {

    JavaBuilderDsl echo(String message) {
        println "Echo: $message"
        return this
    }

    JavaBuilderDsl sh(String script) {
        println "Shell: $script"
        return this
    }

    JavaBuilderDsl error(String message) {
        println "Error here: $message"
        return this
    }

    // A more advanced DSL
    JavaBuilderDsl withEnv(String var) {
        println "Using: $var"
        return this
    }

    void execute() {
        println "Executing ..."
    }
}

println "2) Fluent Java implementation (Builder)"
JavaBuilderDsl builderDsl = new JavaBuilderDsl()
builderDsl.withEnv("PATH=/usr/bin")
        .echo("Starting pipeline")
        .sh("ls .")
        .error("Error here")
        .execute()
println ""
</code></pre>

<p>In this version, <a href="https://en.wikipedia.org/wiki/Builder_pattern#Java">the Build design pattern</a> is used in the implementation.
As shown above, the code is much more fluent with the object name <code>builderDsl</code> not being repeated every single line.
As a result, the code is less verbose and much more user-friendly.</p>

<h3>Version 3: DSL with Groovy closure</h3>

<pre><code class="groovy Standard Groovy implementation">/**
 * Groovy code with standard implementation
 * Try to simulate some kind of DSL like Pipeline steps in Jenkins
 */
class GroovyDsl {

    def echo(String message) {
        println "Echo: $message"
    }

    def sh(String script) {
        println "Shell: $script"
    }

    def error(String message) {
        println "Error here: $message"
    }

    // A more advanced DSL
    def withEnv(String var) {
        println "Using: $var"
    }

    static void execute(closure) {
        GroovyDsl body = new GroovyDsl()
        closure(body)
        println "Executing ..."
    }

}

println "3) Standard Groovy implementation"
GroovyDsl.execute { dsl -&gt;
    dsl.withEnv("PATH=/usr/bin")
    dsl.echo("Starting pipeline")
    dsl.sh("ls .")
    dsl.error("Error here")
}
println ""
</code></pre>

<p>This first version of Groovy implementation is presented here to show connection with its Java counterparts.
As shown below, the input variable <code>dsl</code> in the closure can be abstracted away using delegate.</p>

<pre><code class="groovy Transparent DSL with delegate">class GroovyDsl {

    def echo(String message) {
        println "Echo: $message"
    }

    def sh(String script) {
        println "Shell: $script"
    }

    def error(String message) {
        println "Error here: $message"
    }

    // A more advanced DSL
    def withEnv(String var) {
        println "Using: $var"
    }

    static void execute(Closure closure) {
        GroovyDsl body = new GroovyDsl()
        // TRICKY: Modify the input var? Hmmm.
        closure.delegate = body
        closure()
        println "Executing ..."
    }

    static void executeBest(Closure closure) {
        GroovyDsl body = new GroovyDsl()
        body.with(closure)
        println "Executing ..."
    }

}

println "4) DSL-style Groovy implementation"
GroovyDsl.execute {
    withEnv("PATH=/usr/bin")
    echo("Starting pipeline")
    sh("ls .")
    error("Error here")
}
println ""

println "4b) DSL-style Groovy (better) implementation"
GroovyDsl.executeBest {
    withEnv("PATH=/usr/bin")
    echo("Starting pipeline")
    sh("ls .")
    error("Error here")
}
println ""
</code></pre>

<p>In this final version, only a very small boiler-plate code <code>GroovyDsl.executeBest</code> remains.
The following lines form a mini language (i.e., DSL) that can be exposed to users.
The users can start using the DSL without having to learn Groovy or Java.</p>

<p>Note that the <code>executeBest</code> is the equivalent but less straight-forward way to do the same thing with delegate.
Compared with <code>execute</code>, it has the benefit of NOT modifying the input reference <code>closure</code>.</p>

<h3>Reference</h3>

<ul>
<li><a href="http://groovy-lang.org/closures.html">Groovy closure</a></li>
<li><a href="https://jenkins.io/doc/pipeline/steps/">Jenkins pipeline steps</a></li>
<li><a href="https://dzone.com/articles/groovy-dsl-simple-example">Another example Groovy implementation</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Unit Tests Pass on Local but Fail on CI]]></title>
    <link href="http://tdongsi.github.io/blog/2016/06/30/java-intermittent-test-failures/"/>
    <updated>2016-06-30T17:51:13-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/06/30/java-intermittent-test-failures</id>
    <content type="html"><![CDATA[<p>We have all seen it before: intermittent unit test failures.
It could be agonizing that unit tests pass locally, but then fail in the Jenkins unit test build.</p>

<!--more-->


<p>In our experience, one of the most common causes is:
<strong>static initialization code that dynamically sets a static member variable from a config file value.</strong></p>

<p>What happens locally?
If you’re running from the command line, you probably have some environment variables set.
These allow some ConfigHelper class to find the resource properties files and load them.
In the end, code that looks like the following often ends up succeeding:</p>

<pre><code class="java DbQueue class">private static final String MY_CONFIG = ConfigHelper.getBoolean("config_key", false);
</code></pre>

<p>But the unit tests on the CI server run without being set up for a Tomcat application server run.
Instead, they run using some mock framework such as JMockit.
Mocking in this scenario is a good, desirable thing.
However, it also means that code like that ends up failing to find those resources.
In the example above, the class <code>DbQueue</code>&rsquo;s static code was invoked <strong>even though the class itself has been mocked out</strong>.
And very often, classes like that throw some misleading exceptions, especially when trying to load and convert to a numeric value from a resource.</p>

<p>So, how do we fix it?
How do we prevent that class static member initialization code from being invoked in Jenkins test build?
The answer is when we mock the class in JMockit using the <code>@Mocked</code> annotation, we can provide the <code>stubOutClassInitialization=true</code> parameter, like this:</p>

<pre><code class="java Mock with JMockit">public class MyTest {
    @Mocked( stubOutClassInitialization = true )
    DbQueue queue;

    ...
}
</code></pre>

<p>That will prevent the static code in the class <code>DbQueue</code> from running in Jenkins unit test builds.
The additional benefit of doing this <em>correctly</em> and <em>completely</em> is that we’ll be able to run our unit tests from inside Eclipse WITHOUT setting the <code>–DSBNHOME=</code> environment variable and the test will still complete as desired.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java: Unit Test Performance]]></title>
    <link href="http://tdongsi.github.io/blog/2016/06/06/java-unit-test-performance/"/>
    <updated>2016-06-06T22:47:42-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/06/06/java-unit-test-performance</id>
    <content type="html"><![CDATA[<p>According to <a href="https://www.youtube.com/watch?v=wEhu57pih5w">this</a>, the right way of automated testing is that we have lots of unit tests as majority of our overall automated tests, supplemented by a smaller set of functional tests and even fewer sets of integration tests (a.k.a., Test Automation Pyramid).
However, for that strategy to work, we should pay attention to unit test performance.
It is not productive for us developers to wait 30+ minutes to run unit tests locally, especially when we have multiple check-ins per day.
In addition, the runtime will get compounded as we add more unit tests.
Here, I list out few commonly observed mistakes to avoid and suggestions that frequently improve Java unit test performance.</p>

<!--more-->


<p>1) Do NOT add loggings/printing to your tests.
Use TestNG assertions instead of checking screen output.
Remove from the test classes all the <code>System.out.println</code> statements (that we might add when we start writing unit tests).
The logs don&rsquo;t matter when we&rsquo;re running in parallel.
Moreover, it could add 5-10 minutes to the build time, regardless of running in sequential or parallel.</p>

<p>2) Another common mistake is to override the default <code>System.out</code> by calling <code>System.setOut(PrintStream)</code> and verify by asserting against log statements.
This tactic is often used to verify expected method invocations, which will subsequently generate some specific log entries.
For such behavior testing, consider using <a href="https://jmockit.googlecode.com/svn-history/r2056/trunk/www/tutorial/BehaviorBasedTesting.html">Jmockit Verifications</a> instead of depending on output of logs generated.</p>

<p>3) Mock logging and config classes if applicable.
Otherwise, we might encountered errors like &ldquo;Exception encountered, logging will be disabled&rdquo;, probably thrown by JMockit.
If there is any static initialization block in the mocked class for logging and configuration purposes, consider using <code>(stubOutClassInitialization = true)</code> (see <a href="/blog/2016/06/30/java-intermittent-test-failures/">this</a>).</p>

<p>4) Choosing the right parallel execution settings can substantially improve the execution time.
However, for parallel test runs, consider splitting big test classes (> 100 tests) that are taking much longer than others.
As we are running test classes in parallel across multiple JVMs, it is often the case that all JVMs are shut down except for one or two which are running some big test classes.
Splitting those classes into multiple smaller classes will distribute the load equally across multiple JVMs.</p>

<p>5) Out of all the <code>maven-surefire</code> options for running tests in parallel, the one that worked considering JMockit limitations with parallel execution (and our test structure) are as below:</p>

<pre><code class="xml Maven-surefire options">&lt;parallel&gt;classes&lt;/parallel&gt;
&lt;forkCount&gt;${forkCount}&lt;/forkCount&gt;
&lt;reuseForks&gt;false&lt;/resuseForks&gt;
</code></pre>
]]></content>
  </entry>
  
</feed>
