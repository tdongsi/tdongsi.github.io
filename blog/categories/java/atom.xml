<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Java | Personal Programming Notes]]></title>
  <link href="http://tdongsi.github.io/blog/categories/java/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/"/>
  <updated>2016-05-04T01:02:34-07:00</updated>
  <id>http://tdongsi.github.io/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Java: Unit Test Performance]]></title>
    <link href="http://tdongsi.github.io/blog/2016/05/06/java-unit-test-performance/"/>
    <updated>2016-05-06T22:47:42-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/05/06/java-unit-test-performance</id>
    <content type="html"><![CDATA[<p>According to <a href="https://www.youtube.com/watch?v=wEhu57pih5w">this</a>, the right way of automated testing is that we have lots of unit tests as majority of our overall automated tests, supplemented by a smaller set of functional tests and even fewer sets of integration tests (a.k.a. Test Automation Pyramid).
That is the testing strategy that I agreed with and it has been adapted at work for a while.</p>

<p>However, for that strategy to work, we should pay attention to unit test performance.
It is not productive for developers to wait 30+ minutes to run unit tests locally, especially when we have multiple check-ins per day.
In addition, the runtime will get compounded as we add more unit tests.
Here, I list out few mistakes to avoid and suggestions that frequently improve Java unit test performance.</p>

<p>1) Do NOT add loggings/printing to your tests.
Use TestNG assertions instead of checking screen output.
Remove from the test classes all the <code>System.out.println</code> statements (that we might add when we start writing unit tests).
The logs don&rsquo;t matter when we&rsquo;re running in parallel.
Moreover, it could add 5-10 minutes to the build time, regardless of running in sequential or parallel.</p>

<p>2) Another common mistake is to override the default <code>System.out</code> by calling <code>System.setOut(PrintStream)</code> and verify by asserting against log statements.
This tactic is often used to verify expected method invocations, which will subsequently generate some specific log entries.
For such behavior testing, consider using <a href="https://jmockit.googlecode.com/svn-history/r2056/trunk/www/tutorial/BehaviorBasedTesting.html">Jmockit Verifications</a> instead of depending on output of logs generated.</p>

<p>3) Mock logging and config classes if applicable.
Otherwise, we might encountered errors like &ldquo;Exception encountered, logging will be disabled&rdquo;, probably thrown by JMockit.
If there is any static initialization block in the mocked class for logging and configuration purposes, consider using <code>(stubOutClassInitialization = true)</code> (see <a href="/blog/2016/05/01/java-intermittent-test-failures/">this</a>).</p>

<p>4) Choosing the right parallel execution settings can substantially improve the execution time.
However, for parallel test runs, consider splitting big test classes (> 100 tests) that are taking much longer than others.
As we are running test classes in parallel across multiple JVMs, it is often the case that all JVMs are shut down except for one or two which are running some big test classes.
Splitting those classes into multiple smaller classes will distribute the load equally across multiple JVMs.</p>

<p>5) Out of all the <code>maven-surefire</code> options for running tests in parallel, the one that worked considering JMockit limitations with parallel execution (and our test structure) are as below:</p>

<pre><code class="xml Maven-surefire options">&lt;parallel&gt;classes&lt;/parallel&gt;
&lt;forkCount&gt;${forkCount}&lt;/forkCount&gt;
&lt;reuseForks&gt;false&lt;/resuseForks&gt;
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Unit Tests Pass on Local but Fail on CI]]></title>
    <link href="http://tdongsi.github.io/blog/2016/05/01/java-intermittent-test-failures/"/>
    <updated>2016-05-01T17:51:13-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/05/01/java-intermittent-test-failures</id>
    <content type="html"><![CDATA[<p>We have all seen it before: intermittent unit test failures.
It could be agonizing that unit tests pass locally, but then fail in the Jenkins unit test build.</p>

<p>In our experience, one of the most common causes is:
<strong>Class static initialization code that dynamically sets a static member variable from a config file value.</strong></p>

<p>What happens locally?
If you’re running from the command line, you probably have some environment variables set.
These allow some ConfigHelper class to find the resource properties files and load them.
In the end, code that looks like the following often ends up succeeding:</p>

<pre><code class="java DbQueue class">private static final String MY_CONFIG = ConfigHelper.getBoolean("config_key", false);
</code></pre>

<p>But the unit tests on the CI server run without being set up for a Tomcat application server run.
Instead, they run using some mock framework such as JMockit.
That’s a good, desirable thing.
However, it also means that code like that ends up failing to find those resources.
In the example above, the class <code>DbQueue</code>&rsquo;s static code was invoked <strong>even though the class itself has been mocked out</strong>.
And very often, classes like that throw some misleading exceptions, especially when trying to load and convert a numeric value from a resource.</p>

<p>So, how do we fix it?
How do we prevent that class static member initialization from being invoked in Jenkins test build?
The answer is when we mock the class in JMockit using the <code>@Mocked</code> annotation, we can provide the <code>stubOutClassInitialization=true</code> parameter, like this:</p>

<pre><code class="java Mock with JMockit">public class MyTest {
    @Mocked( stubOutClassInitialization = true )
    DbQueue queue;

    ...
}
</code></pre>

<p>That will prevent the static code in the class <code>DbQueue</code> from running in Jenkins unit test builds.
The additional benefit of doing this <em>correctly</em> and <em>completely</em> is that we’ll be able to run our unit tests from inside Eclipse WITHOUT setting the <code>–DSBNHOME=</code> environment variable and the test will still complete as desired.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Convert Python Objects to JSON (Ordered Keys)]]></title>
    <link href="http://tdongsi.github.io/blog/2016/04/25/convert-python-objects-to-json-ordered-keys/"/>
    <updated>2016-04-25T01:26:22-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/04/25/convert-python-objects-to-json-ordered-keys</id>
    <content type="html"><![CDATA[<p>In the JSON output shown in the last <a href="/blog/2016/04/21/convert-python-objects-to-json/">post</a>, the keys are printed out of order since they are unordered in the internal dictionary <code>__dict__</code>.
In theory, it does not matter when converting to/from JSON.
However, it sometimes makes sense for the keys to be printed in order, especially when we need to look for two keys in JSON next to each other or one key before another.
For example, in the <code>Config</code> object in the last post, it is better to see <code>source</code> and <code>target</code> configurations side by side and, then, get to know what kind of tests from <code>testName</code> key before reading details of tests in <code>queries</code> key.
Setting <code>sort_keys</code> option in <code>json.dump</code> is not applicable here since the keys will be sorted by their names, not their order of appearance like we do in the Java example.</p>

<p>To have the keys appear in order as defined when converting to JSON, we have two options:</p>

<h3>Option 1: use OrderedDict as your base class</h3>

<p>This option is just a quick and dirty workaround: our <code>Config</code> class should extend <code>collections.OrderedDict</code> class and, in the code, we refer to <code>object["att"]</code> instead of <code>object.att</code>.</p>

<pre><code class="python Example of using OrderedDict as your Config class">class OrderedConfig(collections.OrderedDict):
    pass

def ordered_config_file(filename, query_generator):

    hive_source = OrderedConfig()
    hive_source["type"] = "hive"
    hive_source["url"] = "jdbc:hive2://192.168.5.184:10000/DWH"
    vertica_target = OrderedConfig()
    vertica_target["type"] = "vertica"
    vertica_target["url"] = "jdbc:vertica://192.168.5.174:5433/VMart"

    config = OrderedConfig()
    config["source"] = hive_source
    config["target"] = vertica_target
    config["testName"] = "count"
    config["queries"] = query_generator

    with open(filename, 'w') as config_file:
        json.dump(config, config_file, indent=4)
</code></pre>

<p>We have some extra typing, but in general, it is good enough for some configuration objects.
Note that you can now dump your configuration object directly into file because it now behaves like a dictionary.</p>

<pre><code class="json Pretty print">{
    "source": {
        "type": "hive", 
        "url": "jdbc:hive2://192.168.5.184:10000/DWH"
    }, 
    "target": {
        "type": "vertica", 
        "url": "jdbc:vertica://192.168.5.174:5433/VMart"
    }, 
    "testName": "count", 
    "queries": "..."
}
</code></pre>

<h3>Option 2: use OrderedDict as your attribute dictionary.</h3>

<p>In order to refer to attributes directly as <code>object.att</code> and still get JSON ordered like in the Java example, it will need some works.
Note that the obvious solution <code>__dict__ = OrderedDict()</code> will NOT work due to a Python bug.</p>

<pre><code class="python Failed attempt due to a Python bug">class Config(object):
   def __init__(self):
       self.__dict__ = collections.OrderedDict()


  with open(filename, 'w') as config_file:
      json.dump(config, config_file, default=lambda o: o.__dict__, indent=4)
</code></pre>

<p>I got an empty object as my JSON output.
It can be pretty confusing since we can still refer to attributes using standard notation <code>object.att</code> and correctly retrieve values.
After searching the web, I finally figured out that it is a known bug, as documented <a href="https://mail.python.org/pipermail/python-bugs-list/2006-April/033155.html">here</a>.
It says that if <code>__dict__</code> is not an actual <code>dict()</code>, then it is ignored, and attribute lookup fails if using that dictionary directly.</p>

<p>To work around that problem, we have to use <code>OrderedDict</code> as an attribute in <code>__dict__</code> and modify <code>__getattr__</code> and <code>__setattr__</code> methods to use this <code>OrderedDict</code> instead.
The modified <code>Config</code> class and modified <code>default=</code> parameter is shown below.</p>

<pre><code class="python Modified Config class">class Config(object):

    ODICT = "odict"

    def __init__(self):
        self.__dict__[self.ODICT] = collections.OrderedDict()

    def __getattr__(self, item):
        return self.__dict__[self.ODICT][item]

    def __setattr__(self, key, value):
        self.__dict__[self.ODICT][key] = value
</code></pre>

<pre><code class="python Modified JSON dump">    with open(filename, 'w') as config_file:
        json.dump(config, config_file, default=lambda o: o.__dict__[Config.ODICT], indent=4)
</code></pre>

<p>The JSON output now has the keys appear in the order as they are defined, similar to Jackson example above:</p>

<pre><code class="json Pretty print with ordering">{
    "source": {
        "type": "hive", 
        "host": "192.168.5.184", 
        "user": "cloudera", 
        "password": "password", 
        "url": "jdbc:hive2://192.168.5.184:10000/DWH"
    }, 
    "target": {
        "type": "vertica", 
        "host": "192.168.5.174", 
        "user": "dbadmin", 
        "password": "password", 
        "url": "jdbc:vertica://192.168.5.174:5433/VMart"
    }, 
    "testName": "count", 
    "queries": "..."
}
</code></pre>

<p>With that, for configuration editing purposes, using the Python object to JSON conversion is more convenient than Java (POJO) to JSON conversion.
We can add new custom attributes if needed without having to define a new class.
The <code>Config</code> class is all you need for all configuration writing.
The full working code for converting Python object to JSON is shown below.</p>

<pre><code class="python Full code">import collections
import json

class Config(object):

    ODICT = "odict"

    def __init__(self):
        self.__dict__[self.ODICT] = collections.OrderedDict()

    def __getattr__(self, item):
        return self.__dict__[self.ODICT][item]

    def __setattr__(self, key, value):
        self.__dict__[self.ODICT][key] = value

    pass

def get_hive_config():
    """ Get pre-defined Hive configuration.

    :return: Config object for Hive.
    """

    conn = Config()
    conn.type = "hive"
    conn.host = "192.168.5.184"
    conn.user = "cloudera"
    conn.password = "password"
    conn.url = "jdbc:hive2://192.168.5.184:10000/DWH"

    return conn

def get_vertica_config():
    """ Get pre-defined Vertica configuration.

    :return: Config object for Vertica.
    """

    conn = Config()
    conn.type = "vertica"
    conn.host = "192.168.5.174"
    conn.user = "dbadmin"
    conn.password = "password"
    conn.url = "jdbc:vertica://192.168.5.174:5433/VMart"

    return conn

def create_config_file(filename, query_generator):

    hive_source = get_hive_config()
    vertica_target = get_vertica_config()

    config = Config()
    config.source = hive_source
    config.target = vertica_target
    config.testName = "count"
    config.queries = query_generator

    with open(filename, 'w') as config_file:
        json.dump(config, config_file, default=lambda o: o.__dict__[Config.ODICT], indent=4)

def main():

    FILE_NAME = "hive_vertica_count.json"
    query_generator = generate_count_queries()
    create_config_file(FILE_NAME, query_generator)

if __name__ == "__main__":
    main()
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Convert Python Objects to JSON]]></title>
    <link href="http://tdongsi.github.io/blog/2016/04/21/convert-python-objects-to-json/"/>
    <updated>2016-04-21T22:09:50-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/04/21/convert-python-objects-to-json</id>
    <content type="html"><![CDATA[<h3>JSON serialization in Java</h3>

<p>In Java, it is pretty straight-forward to convert Java objects (POJO) to JSON using <a href="https://github.com/FasterXML/jackson">Jackson library</a>.
The following code will convert an example POJO to JSON:</p>

<pre><code class="java Example POJO">public class Config {
    public String type;
    public String host;
    public String user;
    public String password;
    public String url;
}
</code></pre>

<pre><code class="java Jackson examples">ObjectMapper mapper = new ObjectMapper();
Config conn = new Config();
conn.type = "hive";
conn.host = "192.168.5.184";
conn.user = "cloudera";
conn.password = "password";
conn.url = "jdbc:hive2://192.168.5.184:10000/DWH";

// POJO to JSON in file
mapper.writeValue(new File("config.json"), obj);
// POJO to JSON in String
String jsonInString = mapper.writerWithDefaultPrettyPrinter()
        .writeValueAsString(conn);
</code></pre>

<p>The JSON output is shown below.
Note that the keys (e.g., &ldquo;type&rdquo;, &ldquo;host&rdquo;) appear in the same order as defined in the <code>Config</code> class.
This will become important later when we try to convert Python objects to JSON.</p>

<pre><code class="json JSON representation of Config object">{
  "type" : "hive",
  "host" : "192.168.5.184",
  "user" : "cloudera",
  "password" : "password",
  "url" : "jdbc:hive2://192.168.5.184:10000/DWH"
}
</code></pre>

<h3>JSON serialization in Python</h3>

<p>In Python, we have <code>json</code> module to convert a <em>serializable</em> object to JSON format.
The first attempt at JSON serialization in Python may look like this, with a slightly complex Python object is intentionally used as an example:</p>

<pre><code class="python First attempt at JSON serialization">class Config(object):
    pass


def get_hive_config():
    """ Get pre-defined Hive configuration.

    :return: Config object for Hive.
    """

    conn = Config()
    conn.type = "hive"
    conn.host = "192.168.5.184"
    conn.user = "cloudera"
    conn.password = "password"
    conn.url = "jdbc:hive2://192.168.5.184:10000/DWH"

    return conn


def get_vertica_config():
    """ Get pre-defined Vertica configuration.

    :return: Config object for Vertica.
    """

    conn = Config()
    conn.type = "vertica"
    conn.host = "192.168.5.174"
    conn.user = "dbadmin"
    conn.password = "password"
    conn.url = "jdbc:vertica://192.168.5.174:5433/VMart"

    return conn


def create_config_file(filename, query_generator):

    hive_source = get_hive_config()
    vertica_target = get_vertica_config()

    config = Config()
    config.source = hive_source
    config.target = vertica_target
    config.testName = "count"
    config.queries = query_generator

    with open(filename, 'w') as config_file:
        json.dump(config, config_file)


def main():

    FILE_NAME = "hive_vertica_count.json"
    query_generator = generate_count_queries()
    create_config_file(FILE_NAME, query_generator)
</code></pre>

<p>This first attempt with <code>json.dump(config, config_file)</code> will fail with the following error:</p>

<pre><code class="python JSON serialization error">TypeError: &lt;__main__.Config object at 0x10ab824d0&gt; is not JSON serializable
</code></pre>

<p>As the message indicates, <code>Config</code> object is not JSON serializable.
<code>json.dump</code> function expects a serializable object such as one of Python standard object types (see Python to JSON mapping table below) or their subclasses.</p>

<table>
<thead>
<tr>
<th> Python </th>
<th> JSON </th>
</tr>
</thead>
<tbody>
<tr>
<td> dict </td>
<td> object </td>
</tr>
<tr>
<td> list, tuple </td>
<td> array </td>
</tr>
<tr>
<td> str, unicode </td>
<td> string </td>
</tr>
<tr>
<td> int, long, float </td>
<td> number </td>
</tr>
<tr>
<td> True </td>
<td> true </td>
</tr>
<tr>
<td> False </td>
<td> false </td>
</tr>
<tr>
<td> None </td>
<td> null </td>
</tr>
</tbody>
</table>


<p><br></p>

<p>The solution for that problem is to specify the <code>default</code> parameter with a function that returns object&rsquo;s <code>__dict__</code> attribute.
<code>__dict__</code> is the internal attribute dictionary that contains all attributes associated with an object.
Object attribute references are translated to lookups in this dictionary, e.g., <code>o.x</code> is translated to <code>o.__dict__["x"]</code>.</p>

<pre><code class="python Correct options">    with open(filename, 'w') as config_file:
        json.dump(config, config_file, default=lambda o: o.__dict__, indent=4)
</code></pre>

<pre><code class="python Pretty print without ordering">{
    "source": {
        "url": "jdbc:hive2://192.168.5.184:10000/DWH", 
        "host": "192.168.5.184", 
        "password": "password", 
        "type": "hive", 
        "user": "cloudera"
    }, 
    "queries": "...", 
    "target": {
        "url": "jdbc:vertica://192.168.5.174:5433/VMart", 
        "host": "192.168.5.174", 
        "password": "password", 
        "type": "vertica", 
        "user": "dbadmin"
    }, 
    "testName": "count"
}
</code></pre>

<p>Note that simply using <code>json.dump(config.__dict__, config_file)</code> will NOT work if any attribute of the object is another complex object (e.g., <code>source</code> and <code>target</code> attributes in this example).
For more complex objects such as those include <code>set</code>s, we may have to define our own Encoder that extends <code>json.JSONEncoder</code> and provide it to <code>json.dump</code> function.
The next <a href="/blog/2016/04/25/convert-python-objects-to-json-ordered-keys/">post</a> will discuss how to print keys in order of which they are defined, like in the Java example.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[(Pt. 7) Extending for Data Parity Checks]]></title>
    <link href="http://tdongsi.github.io/blog/2016/04/17/sql-unit-data-parity/"/>
    <updated>2016-04-17T16:39:19-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/04/17/sql-unit-data-parity</id>
    <content type="html"><![CDATA[<p>Navigation: <a href="/blog/2016/03/16/sql-unit-overview/">Overview</a>,
<a href="/blog/2016/03/20/sql-unit-functional-tests/">Pt 1</a>,
<a href="/blog/2016/03/28/sql-unit-test-runner/">Pt 2</a>,
<a href="/blog/2016/04/10/sql-unit-incremental-data-update/">Pt 3</a>,
<a href="/blog/2016/04/12/sql-unit-testing/">Pt 4</a>,
<a href="/blog/2016/04/14/sql-unit-vs-functional/">Pt 5</a>,
<a href="/blog/2016/04/16/sql-unit-extension/">Pt 6</a>.</p>

<p>As an example to discussion in <a href="/blog/2016/04/16/sql-unit-extension/">this post</a>, I will discuss how I recently added a new functionality to handle a new kind of tests.</p>

<h3>Background of data parity checks</h3>

<p>Recently, I had to do lots of data parity checks to verify changes in Extract-Load processes (i.e., EL with no Transform).
In those data parity checks, we want to make sure data in some columns of two tables (i.e., two projections) must be the same.
In other words, we want to verify if the two following SQL queries return completely matching rows and columns:</p>

<pre><code class="plain Data parity checks">select col1, col2 from old_table_name

matches

select col3, col4 from new_table_name
</code></pre>

<p>The straight-forward test would be to get all the rows and columns of those two projections, and perform equality check one by one.
It would be very time-consuming to write and execute such test cases in Java and TestNG.
Even when the query returns can be managed within the memory limit, it is still time-consuming to do data transfer for the two query returns, join the columns to prepare for comparison row by row.
Moreover, note that these expensive operations are carried out on the client side, our computers.</p>

<p>The more efficient way for this data parity check is to use these two SQL test queries, using the test blocks shown in <a href="/blog/2016/03/28/sql-unit-test-runner/">this post</a>:</p>

<pre><code class="plain Test blocks for data parity check">/* @Test
{
    "name" : "parity_check",
    "query" : "select col1, col2 from old_table_name
                EXCEPT
                select col3, col4 from new_table_name
                limit 20",
    "expected" : ""
}
*/

/* @Test
{
    "name" : "parity_check_reverse",
    "query" : "select col3, col4 from new_table_name
                EXCEPT
                select col1, col2 from old_table_name
                limit 20",
    "expected" : ""
}
*/
</code></pre>

<p>The two SQL test queries is based on the following <a href="https://en.wikipedia.org/wiki/Algebra_of_sets">set theory identities</a>:</p>

<p><span class="math display">\[A = B \Leftrightarrow A \subseteq B \mbox{ and } B \subseteq A\]</span></p>




<p><span class="math display">\[A \subseteq B \Leftrightarrow A \setminus B = \varnothing\]</span></p>


<p>If the query <code>Table_A EXCEPT Table_B</code> returns nothing, it indicates that data in <code>Table_A</code> is a subset of data in <code>Table_B</code>.
Similarly for <code>Table_B EXCEPT Table_A</code> query.
Therefore, if two test cases pass, it means that the data in <code>Table_A</code> is equal to the data in <code>Table_B</code>.</p>

<p>Using these two queries, we shift most of computing works (<code>EXCEPT</code> operations) to the database server side, which is faster since the server cluster is usually much more powerful than our computers.
Moreover, in most of the cases when the tests pass, the data transfer would be usually minimal (zero row).
In short, these <code>EXCEPT</code>-based checks will save us lots of computation time, data transfer time, and assertion check time.</p>

<p>The <code>limit 20</code> clause is also for minimizing data transfer and local computing works.
When the expected return of the SQL query is nothing (i.e., <code>"expected" : ""</code>), we should always add LIMIT clause to the query.
This will save some waiting time and make our log files cleaner when something went wrong and caused the test to fail.
For example, using the above test blocks, if there are one million additional, erroneous rows of data in <code>new_table_name</code> for some reason, the test case &ldquo;parity_check_reverse&rdquo; will fail.
However, instead of transferring one million rows, only 20 of those will be sent to the local host (test machine), thanks to the <code>LIMIT</code> clauses.
In addition, the log file of the Test Runner will NOT be flooded with one million rows of erroneous data while 20 sample rows are probably enough to investigate what happened.</p>

<h3>Extending SQL Test Runner</h3>

<p>If we only need to do a few simple data parity checks, a few (&ldquo;name&rdquo;, &ldquo;query&rdquo;, &ldquo;expected&rdquo;) test blocks as shown above will suffice.
However, there were tens of table pairs to be checked and many tables are really wide, about 100 columns.
For wide tables, for easy investigation if data parity checks fail, we check data in group of 6-10 columns.
Writing test blocks like above can become a daunting task, and such test blocks for wide tables can become hard to read.
Therefore, I create a new test block construct that is more friendly to write and read, as shown below.</p>

<pre><code class="plain New test block">/* @Test
{
    "name" : "parity_check",
    "query" : "select col1, col2 from old_table_name",
    "equal" : "select col3, col4 from new_table_name"
}
*/
</code></pre>

<p>Under the hood, this test block should be equivalent to the two test blocks shown in the last section.
That is, based on the two projection queries found in &ldquo;query&rdquo; and &ldquo;equal&rdquo; clauses, the SQL Test Runner will generate two test blocks with <code>EXCEPT</code>-based test queries as shown above.</p>

<p>Implementation of this new feature is summarized in the following steps:</p>

<ol>
<li>Define new JSON block.</li>
<li>Define new POJO (named <code>NameQueryEqual</code>) that maps to new JSON block.</li>
<li>Create a new class (named <code>NewTestHandler</code> for easy reference) that implements TestStrategy interface to handle the new POJO. Specifically:

<ol>
<li>From <code>NameQueryEqual</code> POJO, generate two <code>NameQueryExpected</code> POJOs with relevant queries (using <code>EXCEPT</code> operations).</li>
<li>Reuse the old TestHandler class to process two <code>NameQueryExpected</code> POJOs.</li>
</ol>
</li>
<li>Create a new test runner that extends the <code>BaseTestRunner</code> and uses the new <code>TestStrategy</code>.</li>
</ol>


<p>For step 1, the new JSON block is already defined as above.
From JSON, the corresponding POJO in step 2 can be easily defined:</p>

<pre><code class="java">/**
 * POJO for JSON test block comparing two projections
 * 
 * @author tdongsi
 */
public class NameQueryEqual {
    // Test name.
    public String name;
    // File lists to run
    public List&lt;String&gt; file;
    // Test query in SQL
    public String query;
    // Equivalent query in SQL
    public String equal;
}
</code></pre>

<p>For step 3, as emphasized in the <a href="/2016/04/16/sql-unit-extension/">last post</a>, we should NOT modify the old test runner to handle this new POJO.
Instead, we should create a new class <code>NewTestHandler</code> that implements TestStrategy interface to handle the new POJO and create a new test runner that uses the new TestStrategy (Strategy pattern).</p>

<p>The implementation of the new test block handler is NOT really complex, thanks to modular design of SQL Test Runner.
We only need to extract two projections from <code>NameQueryEqual</code>&rsquo;s attributes, generate two <code>EXCEPT</code>-based queries for those two projections (with <code>LIMIT</code> clauses), and create two  <code>NameQueryExpected</code> POJOs for those test queries.
Since we already have a TestHanlder class that can run and verify those <code>NameQueryExpected</code> objects, we only need to include a TestHandler object into the <code>NewTestHandler</code> class and delegate handling <code>NameQueryExpected</code> objects to it.
Note that this approach is recommended over subclassing <code>TestHandler</code> to include new code for handling the new <code>NameQueryEqual</code> POJO (i.e., &ldquo;composition over inheritance&rdquo;).</p>
]]></content>
  </entry>
  
</feed>
