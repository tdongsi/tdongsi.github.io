<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Java | Personal Programming Notes]]></title>
  <link href="http://tdongsi.github.io/blog/categories/java/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/"/>
  <updated>2021-03-13T22:20:50-08:00</updated>
  <id>http://tdongsi.github.io/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[IntelliJ Setup for Jenkins Development]]></title>
    <link href="http://tdongsi.github.io/blog/2018/02/09/intellij-setup-for-jenkins-shared-library-development/"/>
    <updated>2018-02-09T21:32:59-08:00</updated>
    <id>http://tdongsi.github.io/blog/2018/02/09/intellij-setup-for-jenkins-shared-library-development</id>
    <content type="html"><![CDATA[<p>This posts will show how to setup IntelliJ for development of Jenkins <a href="/blog/2017/12/30/groovy-hook-script-and-jenkins-configuration-as-code/">Groovy Init Scripts</a> and <a href="https://jenkins.io/doc/book/pipeline/shared-libraries/">shared libraries</a>, including auto-complete for <a href="https://jenkins.io/doc/pipeline/steps/">Jenkins pipeline steps</a>.
This is based on my original write-up in <a href="https://github.com/tdongsi/jenkins-config/blob/develop/docs/IDE.md">this project</a>.</p>

<!--more-->


<p>NOTE: this setup is NOT intended for Jenkins plugin or core development.</p>

<h3>Start a new Gradle project</h3>

<p>It is best to start a new project:</p>

<ol>
<li>Select <strong>File | New Project</strong></li>
<li>Select <strong>Gradle</strong></li>
<li>Select <strong>Java</strong> AND <strong>Groovy</strong>
<img src="/images/idea/screen01.png" title="Start" alt="Screeshot" /></li>
<li>Choose <strong>GroupId</strong> and <strong>ArtifactId</strong>
<img src="/images/idea/screen02.png" title="Project Name" alt="Screeshot" /></li>
<li>Enter path to Gradle. For Gradle on Mac installed via Homebrew, the Gradle home is like this:
<img src="/images/idea/screen03.png" title="Configure Gradle" alt="Screeshot" />
NOTE: For Gradle installed on a Mac via Homebrew, the path &ldquo;/usr/local/opt/gradle/libexec&rdquo; may be preferrable to &ldquo;/usr/local/Cellar/gradle/X.X/libexec&rdquo; since the former will stay the same after Gradle version upgrades.
In addition, if you work extensively with Grails/Gradle/Groovy, you may prefer installing via <a href="https://sdkman.io/install"><code>sdk</code> tool</a> instead of Homebrew.</li>
<li>Choose <strong>Project name</strong> and <strong>Project Location</strong>
<img src="/images/idea/screen04.png" title="Project location" alt="Screeshot" /></li>
<li>Finish
<img src="/images/idea/screen05.png" title="Finish" alt="Screeshot" /></li>
</ol>


<h3>Configure IDEA</h3>

<p>Set up for Jenkins Plugins files which are of types <strong>.hpi</strong> or <strong>.jpi</strong>.</p>

<ol>
<li>Select <strong>IntelliJ IDEA | Preferences | Editor | File Types</strong></li>
<li>Select <strong>Archive</strong></li>
<li>Select <strong>+</strong> at the bottom left corner</li>
<li>Add both <strong>.hpi</strong> and <strong>.jpi</strong></li>
<li>Select <strong>OK</strong></li>
</ol>


<p><img src="/images/idea/screen06.png" title="Configure plugin files" alt="Screeshot" /></p>

<p>Modify <strong>build.gradle</strong> to add the following lines.</p>

<pre><code class="groovy">    compile 'org.jenkins-ci.main:jenkins-core:2.23'

    // Jenkins plugins
    compile group: 'org.jenkins-ci.plugins', name: 'credentials', version: '2.1.13', ext: 'jar'
    compile group: 'org.jenkins-ci.plugins', name: 'matrix-auth', version: '1.6', ext: 'jar'
    compile group: 'org.jenkins-ci.plugins.workflow', name: 'workflow-cps', version: '2.39', ext: 'jar'

    // TRICKY: The lib folder contains all other plugins *JAR* files
    // if not found in Maven
    compile fileTree(dir: 'lib', include: ['*.jar'])
</code></pre>

<p>The above example will grab Jenkins core libraries, Matrix Authorization Plugin hpi, other plugin dependencies and javadocs for all imported libraries.
Having these libraries imported will enable code auto-completion, syntax checks, easy refactoring when working with Groovy scripts for Jenkins.
It will be a great productivity boost.</p>

<p>NOTE 1: The last line <code>compile fileTree</code> is the last resort for any Jenkins plugins that you cannot find the right group ID and artifact ID.
It is rare these days but such cases cannot be completely ruled out.</p>

<p>NOTE 2: The <code>ext: 'jar'</code> is VERY important to ensure that <code>jar</code> files, instead of <code>hpi</code>/<code>jpi</code> files, are being downloaded and understood by IntellJ.
Without that <code>ext</code> option specified, IntellJ won&rsquo;t find JAR files nested in <code>hpi</code>/<code>jpi</code> files which is the default binaries for Jenkins plugins.</p>

<p>The final <strong>build.gradle</strong> will look like <a href="https://github.com/tdongsi/jenkins-steps-override/blob/master/build.gradle">this</a>.
All of the above setup should suffice for working with <a href="http://tdongsi.github.io/blog/2017/12/30/groovy-hook-script-and-jenkins-configuration-as-code/">Groovy Init Scripts</a>.
For working with Jenkins Shared Pipeline Libraries, we should take one extra step shown as follows.</p>

<h3>Setup for Jenkins pipeline library</h3>

<p>All Groovy files in Jenkins shared library for Pipelines have to follow this directory structure:</p>

<pre><code class="text Directory structure of a Shared Library repository">(root)
+- src                     # Groovy source files
|   +- org
|       +- foo
|           +- Bar.groovy  # for org.foo.Bar class
+- vars
|   +- foo.groovy          # for global 'foo' variable
|   +- foo.txt             # help for 'foo' variable
+- resources               # resource files (external libraries only)
|   +- org
|       +- foo
|           +- bar.json    # static helper data for org.foo.Bar
</code></pre>

<p>Note that the Groovy code can be in both <a href="http://tdongsi.github.io/blog/2017/12/26/class-in-jenkins-shared-library/"><code>src</code></a>
and <a href="http://tdongsi.github.io/blog/2017/03/17/jenkins-pipeline-shared-libraries/"><code>vars</code></a> folders.
Therefore, you need to add the following lines in <code>build.gradle</code> to inform Gradle locations of Groovy source codes:</p>

<pre><code class="groovy">sourceSets {
    main {
        groovy {
            srcDirs = ['vars', 'src']
        }
    }

    test {
        groovy {
            srcDirs = ['test']
        }
    }
}
</code></pre>

<p>Optionally, for unit testing Jenkins shared library, we have to add the following dependencies into our <strong>build.gradle</strong> file.</p>

<pre><code class="groovy">    testCompile group: 'com.lesfurets', name: 'jenkins-pipeline-unit', version: '1.1'
    testCompile group: 'org.spockframework', name: 'spock-core', version: '1.1-groovy-2.4'
</code></pre>

<p>Please see <a href="/blog/2018/06/07/jenkins-pipeline-unit-testing/">this blog post</a> for more details on unit testing.
The final <strong>build.gradle</strong> will look like <a href="https://github.com/tdongsi/jenkins-steps-override/blob/master/build.gradle">this</a>.</p>

<h4>Auto-completion for Jenkins Pipeline</h4>

<p>IntelliJ can&rsquo;t auto-complete <a href="https://jenkins.io/doc/pipeline/steps/">Jenkins pipeline steps</a> such as <code>echo</code> or <code>sh</code> out of the box.
We have to make it aware of those Jenkins pipeline DSLs, via a generic process explained <a href="https://confluence.jetbrains.com/display/GRVY/Scripting+IDE+for+DSL+awareness">here</a>.
Fortunately, it is much easier than it looks and you don&rsquo;t have to actually write GroovyDSL script for tens of Jenkins pipeline steps.
Jenkins make it easy by auto-generating the GroovyDSL script and it is accessible via &ldquo;IntelliJ IDEA GDSL&rdquo; link, as shown in screenshot below.</p>

<p><img src="/images/idea/screen08.png" title="GroovyDSL" alt="Screeshot" /></p>

<p>The &ldquo;IntelliJ IDEA GDSL&rdquo; link can be found by accessing &ldquo;Pipeline Syntax&rdquo; section, which is visible in the left navigation menu of any Pipeline-based job (e.g., &ldquo;Admin&rdquo; job in the example above).
After clicking on the &ldquo;IntelliJ IDEA GDSL&rdquo; link, you will be able to download a plain text file with content starting like this:</p>

<pre><code class="groovy IntelliJ IDEA GDSL">//The global script scope
def ctx = context(scope: scriptScope())
contributor(ctx) {
method(name: 'build', type: 'Object', params: [job:'java.lang.String'], doc: 'Build a job')
method(name: 'build', type: 'Object', namedParams: [parameter(name: 'job', type: 'java.lang.String'), parameter(name: 'parameters', type: 'Map'), parameter(name: 'propagate', type: 'boolean'), parameter(name: 'quietPeriod', type: 'java.lang.Integer'), parameter(name: 'wait', type: 'boolean'), ], doc: 'Build a job')
method(name: 'echo', type: 'Object', params: [message:'java.lang.String'], doc: 'Print Message')
method(name: 'error', type: 'Object', params: [message:'java.lang.String'], doc: 'Error signal')
...
</code></pre>

<p>As you can see, it is a GroovyDSL file that describes the known pipeline steps such as <code>echo</code> and <code>error</code>.
Note that GDSL files can be different for different Jenkins instances, depending on Pipeline-supported plugins currently installed on individual Jenkins instance.
To make IntelliJ aware of the current Jenkins pipeline steps available on our Jenkins, we need to place that GDSL file into a location known to source folders.
As shown in the last section, anywhere in both <code>vars</code> and <code>src</code> folders are eligible as such although I personally prefer to put the GDSL file into <code>vars</code> folder (<a href="https://github.com/tdongsi/jenkins-steps-override/tree/master/vars">for example</a>).</p>

<p>After installing the GDSL file into a proper location, IntelliJ may complain with the following message <em>DSL descriptor file has been change and isn’t currently executed</em> and you have to click <strong>Activate back</strong> to get the IntelliJ aware of the current DSLs.
After that, you can enjoy auto-completion as well as documentation of the Jenkine Pipeline DSLs.</p>

<h3>More information</h3>

<ul>
<li><a href="https://github.com/tdongsi/jenkins-steps-override">Example of final setup</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Jacoco in Maven Projects]]></title>
    <link href="http://tdongsi.github.io/blog/2017/09/23/jacoco-in-maven-project/"/>
    <updated>2017-09-23T21:39:13-07:00</updated>
    <id>http://tdongsi.github.io/blog/2017/09/23/jacoco-in-maven-project</id>
    <content type="html"><![CDATA[<p>This blog post goes over some recipes for adding code coverage report to Maven-based projects with Jacoco.</p>

<!--more-->


<h3>Standard usage</h3>

<p>Based on <a href="http://www.eclemma.org/jacoco/trunk/doc/maven.html">offical instruction</a> and <a href="https://stackoverflow.com/questions/36199422/maven-unit-test-code-coverage">this</a>, you need to add the following code snippet in to your Maven <code>pom.xml</code>.</p>

<pre><code class="xml Jacoco usage (typical Maven project)">&lt;project&gt;
...

    &lt;dependencies&gt;
        ...
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            ...
            &lt;!-- Code Coverage report generation --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.jacoco&lt;/groupId&gt;
                &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt;
                &lt;version&gt;0.7.9&lt;/version&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;prepare-agent&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                    &lt;execution&gt;
                        &lt;id&gt;generate-code-coverage-report&lt;/id&gt;
                        &lt;phase&gt;test&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;report&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;
</code></pre>

<p>At least, you need &ldquo;prepare-agent&rdquo; before test phase for Jacoco instrumentation and &ldquo;report&rdquo; after test phase for generating the report.
You could subject the project to code coverage and generate the same report without making any changes to the pom file.
To do this, run the following command:</p>

<pre><code class="plain Jacoco from Maven command-line">mvn jacoco:prepare-agent test jacoco:report
</code></pre>

<p>You may get the following error:</p>

<pre><code class="plain">[ERROR] No plugin found for prefix 'jacoco' in the current project ...
</code></pre>

<p>There are two options to fix that error.
The easiest way is to specify the <code>groupId</code> and <code>artifactId</code> parameters of the plugin explicitly.
You can also add <code>version</code> to ensure the stability of your build pipeline.</p>

<pre><code class="plain">mvn clean org.jacoco:jacoco-maven-plugin:0.7.9:prepare-agent install org.jacoco:jacoco-maven-plugin:0.7.9:report
</code></pre>

<p>The more long-term solution is to add the following in to your Maven &ldquo;settings.xml&rdquo;.</p>

<pre><code class="xml Maven settings">&lt;pluginGroups&gt;
    &lt;pluginGroup&gt;org.jacoco&lt;/pluginGroup&gt;
&lt;/pluginGroups&gt;
</code></pre>

<h3>Tests with Mock</h3>

<p>If mocking is involved in unit tests, you need to use “instrument” and “restore-instrumented” steps.</p>

<p>Reference:</p>

<ul>
<li><a href="https://github.com/powermock/powermock/wiki/Code-coverage-with-JaCoCo">PowerMock instruction</a></li>
<li><a href="https://github.com/powermock/powermock-examples-maven/blob/master/jacoco-offline/pom.xml">PowerMock example pom.xml</a></li>
</ul>


<h3>Multi-module Maven projects</h3>

<p>Officially, multi-module Maven projects are supported differently by Jacoco as documented <a href="https://github.com/jacoco/jacoco/wiki/MavenMultiModule">here</a>.
Instrumentation will be similar but the challenge of multi-module Maven projects lies in how to collect and report code coverage of all modules correctly.
Jacoco Maven standard goals, as shown in sections above, work on single modules only: Tests are executed within the module and contributed coverage only to code within the same module.
Coverage reports were created for each module separately.</p>

<p>In the past, there are some ad-hoc solutions such as <a href="https://dzone.com/articles/jacoco-maven-multi-module">this</a> (for Jacoco 0.5.x) to work around that limit.
However, those patterns are also error-prone and hard to customize, especially when Jacoco is used with Surefire plugin.
Fortunately, Jacoco recently introduced a new Maven goal &ldquo;report-aggregate&rdquo; in its release 0.7.7 which will aggregate code coverage data across Maven modules.
Its usage is also present in the same <a href="https://github.com/jacoco/jacoco/wiki/MavenMultiModule">link</a> (quoted below) but it is too succint and not very helpful for new users.</p>

<p><blockquote><p>Create a dedicated module in your project for generation of the report. This module should depend on all or some other modules in the project.</p></blockquote></p>

<p>Let' say you have a multi-module Maven project with this structure:</p>

<pre><code class="plain Multi-module Maven project">root pom
  |- module a
  |- module b
  |- module c
</code></pre>

<p>To use Jacoco &ldquo;report-aggregate&rdquo; goal for these modules, you first need to add a dedicated &ldquo;coverage&rdquo; module.
This &ldquo;coverage&rdquo; module should be added into the root POM.
The multi-module Maven project should now look like this:</p>

<pre><code class="plain Multi-module Maven project with aggregate coverage module">root pom
  |- module a
  |- module b
  |- module c
  |- module "coverage"
</code></pre>

<p>The POMs for each module does not need to change at all.
The POM for the &ldquo;coverage&rdquo; module will look like this:</p>

<pre><code class="xml Maven pom.xml for coverage module">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;parent&gt;
        &lt;groupId&gt;com.company&lt;/groupId&gt;
        &lt;artifactId&gt;company-pom&lt;/artifactId&gt;
        &lt;version&gt;3.0&lt;/version&gt;
    &lt;/parent&gt;

    &lt;artifactId&gt;report&lt;/artifactId&gt;
    &lt;name&gt;Jacoco Report&lt;/name&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;my.example&lt;/groupId&gt;
            &lt;artifactId&gt;module-a&lt;/artifactId&gt;
            &lt;version&gt;210.0.00-SNAPSHOT&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;my.example&lt;/groupId&gt;
            &lt;artifactId&gt;module-b&lt;/artifactId&gt;
            &lt;version&gt;210.0.00-SNAPSHOT&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;my.example&lt;/groupId&gt;
            &lt;artifactId&gt;module-c&lt;/artifactId&gt;
            &lt;version&gt;210.0.00-SNAPSHOT&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.jacoco&lt;/groupId&gt;
                &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt;
                &lt;version&gt;0.7.9&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;excludes&gt;
                        &lt;!-- Example of excluding classes 
                        &lt;exclude&gt;**/com/company/config/AutoConfiguration.class&lt;/exclude&gt;
                        --&gt;
                    &lt;/excludes&gt;
                &lt;/configuration&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;id&gt;report-aggregate&lt;/id&gt;
                        &lt;phase&gt;verify&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;report-aggregate&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;

            &lt;!-- This coverage module should never be deployed --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;skip&gt;true&lt;/skip&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;
</code></pre>

<p>Note that we still require &ldquo;prepare-agent&rdquo; step to run before the first test suite.
Depending on what plugins are being used and how the modules are organized within the project, we might have different setup for that particular step.
One option is to run from the command-line:</p>

<pre><code>tdongsi$ ls
Dockerfile              README.md               module1       pom.xml
Jenkinsfile             coverage                module2       scripts

tdongsi$ mvn -B clean org.jacoco:jacoco-maven-plugin:0.7.9:prepare-agent install
</code></pre>

<p>Links:</p>

<ul>
<li><a href="https://stackoverflow.com/questions/13031219/how-to-configure-multi-module-maven-sonar-jacoco-to-give-merged-coverage-rep/37871210#37871210">Example of report-aggregate</a></li>
<li><a href="https://github.com/jacoco/jacoco/tree/master/jacoco-maven-plugin.test/it/it-report-aggregate">Example Maven project</a></li>
</ul>


<h4>Customizations</h4>

<p>In theory, a global threshold can be defined in <code>coverage/pom.xml</code> to enforce code coverage standard across teams.
However, in practice, different teams are at different stages of module/service maturity and blindly having a global threshold will hamper teams working on newer services/modules.
In addition, it does not make sense to enforce code coverage on some Maven modules such as those generated in GRPC.</p>

<p>In Jacoco, you can set different coverage limits for individual modules instead of a global threshold for all modules.
In the following example, you can specify a coverage threshold for module A by modifying module A&rsquo;s pom.xml file:</p>

<pre><code class="xml Module A's pom.xml">...

&lt;/plugins&gt;
...
    &lt;plugin&gt;
        &lt;groupId&gt;com.atlassian.maven.plugins&lt;/groupId&gt;
        &lt;artifactId&gt;maven-clover2-plugin&lt;/artifactId&gt;
    &lt;/plugin&gt;

    &lt;plugin&gt;
        &lt;groupId&gt;org.jacoco&lt;/groupId&gt;
        &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt;
        &lt;version&gt;0.7.9&lt;/version&gt;

        &lt;executions&gt;
            &lt;execution&gt;
                &lt;id&gt;check&lt;/id&gt;
                &lt;goals&gt;
                &lt;goal&gt;check&lt;/goal&gt;
                &lt;/goals&gt;
                &lt;configuration&gt;
                    &lt;!-- NOTE: Set haltOnFailureto true when code coverage is enforced --&gt;
                    &lt;haltOnFailure&gt;false&lt;/haltOnFailure&gt;

                    &lt;rules&gt;
                        &lt;rule &gt;
                            &lt;element&gt;CLASS&lt;/element&gt;
                            &lt;limits&gt;
                                &lt;limit &gt;
                                    &lt;counter&gt;LINE&lt;/counter&gt;
                                    &lt;value&gt;COVEREDRATIO&lt;/value&gt;
                                    &lt;minimum&gt;0.80&lt;/minimum&gt;
                                &lt;/limit&gt;
                                &lt;limit &gt;
                                    &lt;counter&gt;BRANCH&lt;/counter&gt;
                                    &lt;value&gt;COVEREDRATIO&lt;/value&gt;
                                    &lt;minimum&gt;0.80&lt;/minimum&gt;
                                &lt;/limit&gt;
                            &lt;/limits&gt;
                            &lt;excludes&gt;
                                &lt;!-- 
                                &lt;exclude&gt;com.test.ExampleExclusion&lt;/exclude&gt;
                                --&gt;
                            &lt;/excludes&gt;
                        &lt;/rule&gt;
                    &lt;/rules&gt;
                &lt;/configuration&gt;
            &lt;/execution&gt;
        &lt;/executions&gt;
    &lt;/plugin&gt;
&lt;/plugins&gt;
</code></pre>

<p>As you can see, you can also specify files being excluded from coverage calculation.</p>

<h3>References</h3>

<ul>
<li><a href="http://www.jacoco.org/jacoco/trunk/doc/maven.html">Jacoco Maven plugin</a>: there are example POMs.</li>
</ul>


<!--
* [Cross-module reporting](https://stackoverflow.com/questions/41885772/jacoco-simple-integration-test-solution/41901853#41901853)
-->

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[DSL Implementation in Groovy]]></title>
    <link href="http://tdongsi.github.io/blog/2017/08/13/groovy-dsl/"/>
    <updated>2017-08-13T15:18:30-07:00</updated>
    <id>http://tdongsi.github.io/blog/2017/08/13/groovy-dsl</id>
    <content type="html"><![CDATA[<p>Domain-Specific Language is a mini language for a specific problem and/or in a narrow context.
For example, internally used automation tools usually define some small DSL for configuration and most users understand the context and what DSL offers.</p>

<p>This blog post offers my simplistic view of how an internal DSL is implemented in Groovy via closure delegation.
It shows the progression from standard Java-like implementation -> its fluent version -> final DSL form.
This might help undrestanding the inner workings of a DSL such as Jenkins&rsquo;s Pipeline steps.
There are probably more advanced methods/frameworks for creating DSL.
However, those are not in the scope of this post.</p>

<!--more-->


<h3>Example DSL</h3>

<p>We want to implement a simple DSL that is similar to <a href="https://jenkins.io/doc/pipeline/steps/">Pipeline steps in Jenkinsfile</a>.</p>

<pre><code class="plain DSL in Jenkinsfile">{
    withEnv("PATH=/usr/bin")
    echo("Starting pipeline")
    sh("ls .")
    error("Error here")
}
</code></pre>

<p>In this DSL example, users will write a sequence of steps using a small, pre-defined set of custom statements such as <code>echo</code> and <code>sh</code> above.
For each step in the DSL, the backend classes and objects will perform some execution in the background, using the relevant context specific to the domain (e.g., Jenkins domain).
For simplicity, <code>println</code> statements will be used in the following examples.</p>

<p>The advantage of DSL is that the <strong>developers</strong> can implement the backend in some fully-featured language such as Java but the <strong>users</strong> don&rsquo;t need to know such language to use it.
Such a separation is common in DevOps and automation frameworks where the users want the flexibility of configuring based on their needs but don&rsquo;t want to get exposed to the implementation details (which are usually ugly and compplicated).
Instead, the <strong>users</strong> only need to learn the DSL to use it while still have the flexibility to do what they want.
One example can be found in data science domain where data scientists are usually more comfortable developing in R or SQL but automated deployment frameworks or tools can be in another language such as Java.</p>

<h3>Version 1: Java-like standard implementation</h3>

<p>First, we show a standard implementation in Java to show how backend execution can be implemented.
In the advanced versions, the difference is only in its public interface to make it more user-friendly but the backend execution will be similar.</p>

<pre><code class="groovy Standard Java implementation">/**
 * Java code with standard implementation
 * Try to simulate some kind of DSL like Pipeline steps in Jenkins
 */
class JavaDsl {

    void echo(String message) {
        println "Echo: $message";
    }

    void sh(String script) {
        println "Shell: $script";
    }

    void error(String message) {
        println "Error here: $message";
    }

    // A more advanced DSL
    void withEnv(String var) {
        println "Using: $var";
    }

    void execute() {
        println "Executing ...";
    }

}

println "1) Standard Java implementation";
JavaDsl javaDsl = new JavaDsl();
javaDsl.withEnv("PATH=/usr/bin");
javaDsl.echo("Starting pipeline");
javaDsl.sh("ls .");
javaDsl.error("Error here");
javaDsl.execute();
println "";
</code></pre>

<p>The problem of this approach is that users have to write Java (or Groovy) code directly to use it.</p>

<h3>Version 2: Fluent interface with Builder pattern</h3>

<pre><code class="groovy Fluent Java implementation">/**
 * Java code with Builder pattern
 * Try to simulate some kind of DSL like Pipeline steps in Jenkins
 */
class JavaBuilderDsl {

    JavaBuilderDsl echo(String message) {
        println "Echo: $message"
        return this
    }

    JavaBuilderDsl sh(String script) {
        println "Shell: $script"
        return this
    }

    JavaBuilderDsl error(String message) {
        println "Error here: $message"
        return this
    }

    // A more advanced DSL
    JavaBuilderDsl withEnv(String var) {
        println "Using: $var"
        return this
    }

    void execute() {
        println "Executing ..."
    }
}

println "2) Fluent Java implementation (Builder)"
JavaBuilderDsl builderDsl = new JavaBuilderDsl()
builderDsl.withEnv("PATH=/usr/bin")
        .echo("Starting pipeline")
        .sh("ls .")
        .error("Error here")
        .execute()
println ""
</code></pre>

<p>In this version, <a href="https://en.wikipedia.org/wiki/Builder_pattern#Java">the Build design pattern</a> is used in the implementation.
As shown above, the code is much more fluent with the object name <code>builderDsl</code> not being repeated every single line.
As a result, the code is less verbose and much more user-friendly.</p>

<h3>Version 3: DSL with Groovy closure</h3>

<pre><code class="groovy Standard Groovy implementation">/**
 * Groovy code with standard implementation
 * Try to simulate some kind of DSL like Pipeline steps in Jenkins
 */
class GroovyDsl {

    def echo(String message) {
        println "Echo: $message"
    }

    def sh(String script) {
        println "Shell: $script"
    }

    def error(String message) {
        println "Error here: $message"
    }

    // A more advanced DSL
    def withEnv(String var) {
        println "Using: $var"
    }

    static void execute(closure) {
        GroovyDsl body = new GroovyDsl()
        closure(body)
        println "Executing ..."
    }

}

println "3) Standard Groovy implementation"
GroovyDsl.execute { dsl -&gt;
    dsl.withEnv("PATH=/usr/bin")
    dsl.echo("Starting pipeline")
    dsl.sh("ls .")
    dsl.error("Error here")
}
println ""
</code></pre>

<p>This first version of Groovy implementation is presented here to show connection with its Java counterparts.
As shown below, the input variable <code>dsl</code> in the closure can be abstracted away using delegate.</p>

<pre><code class="groovy Transparent DSL with delegate">class GroovyDsl {

    def echo(String message) {
        println "Echo: $message"
    }

    def sh(String script) {
        println "Shell: $script"
    }

    def error(String message) {
        println "Error here: $message"
    }

    // A more advanced DSL
    def withEnv(String var) {
        println "Using: $var"
    }

    static void execute(Closure closure) {
        GroovyDsl body = new GroovyDsl()
        // TRICKY: Modify the input var? Hmmm.
        closure.delegate = body
        closure()
        println "Executing ..."
    }

    static void executeBest(Closure closure) {
        GroovyDsl body = new GroovyDsl()
        body.with(closure)
        println "Executing ..."
    }

}

println "4) DSL-style Groovy implementation"
GroovyDsl.execute {
    withEnv("PATH=/usr/bin")
    echo("Starting pipeline")
    sh("ls .")
    error("Error here")
}
println ""

println "4b) DSL-style Groovy (better) implementation"
GroovyDsl.executeBest {
    withEnv("PATH=/usr/bin")
    echo("Starting pipeline")
    sh("ls .")
    error("Error here")
}
println ""
</code></pre>

<p>In this final version, only a very small boiler-plate code <code>GroovyDsl.executeBest</code> remains.
The following lines form a mini language (i.e., DSL) that can be exposed to users.
The users can start using the DSL without having to learn Groovy or Java.</p>

<p>Note that the <code>executeBest</code> is the equivalent but less straight-forward way to do the same thing with delegate.
Compared with <code>execute</code>, it has the benefit of NOT modifying the input reference <code>closure</code>.</p>

<h3>Reference</h3>

<ul>
<li><a href="http://groovy-lang.org/closures.html">Groovy closure</a></li>
<li><a href="https://jenkins.io/doc/pipeline/steps/">Jenkins pipeline steps</a></li>
<li><a href="https://dzone.com/articles/groovy-dsl-simple-example">Another example Groovy implementation</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Convert Python Objects to JSON]]></title>
    <link href="http://tdongsi.github.io/blog/2016/05/21/convert-python-objects-to-json/"/>
    <updated>2016-05-21T22:09:50-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/05/21/convert-python-objects-to-json</id>
    <content type="html"><![CDATA[<p>In this post, we looks into converting a plain, simple Python object into JSON.
JSON serialization in Java is also provided as an example.
In the <a href="/blog/2016/05/25/convert-python-objects-to-json-ordered-keys/">following post</a>, we will look into a more advanced method of conversion with attributes pretty-printed in order, like in the Java example.</p>

<!--more-->


<h3>JSON serialization in Java</h3>

<p>In Java, it is pretty straight-forward to convert Java objects (POJO) to JSON using <a href="https://github.com/FasterXML/jackson">Jackson library</a>.
The following code will convert an example POJO to JSON:</p>

<pre><code class="java Example POJO">public class Config {
    public String type;
    public String host;
    public String user;
    public String password;
    public String url;
}
</code></pre>

<pre><code class="java Jackson examples">ObjectMapper mapper = new ObjectMapper();
Config conn = new Config();
conn.type = "hive";
conn.host = "192.168.5.184";
conn.user = "cloudera";
conn.password = "password";
conn.url = "jdbc:hive2://192.168.5.184:10000/DWH";

// POJO to JSON in file
mapper.writeValue(new File("config.json"), obj);
// POJO to JSON in String
String jsonInString = mapper.writerWithDefaultPrettyPrinter()
        .writeValueAsString(conn);
</code></pre>

<p>The JSON output is shown below.
Note that the keys (e.g., &ldquo;type&rdquo;, &ldquo;host&rdquo;) appear in the same order as defined in the <code>Config</code> class.
This will become important later when we try to convert Python objects to JSON.</p>

<pre><code class="json JSON representation of Config object">{
  "type" : "hive",
  "host" : "192.168.5.184",
  "user" : "cloudera",
  "password" : "password",
  "url" : "jdbc:hive2://192.168.5.184:10000/DWH"
}
</code></pre>

<h3>JSON serialization in Python</h3>

<p>In Python, we have <code>json</code> module to convert a <em>serializable</em> object to JSON format.
The first attempt at JSON serialization in Python may look like this, with a slightly complex Python object is intentionally used as an example:</p>

<pre><code class="python First attempt at JSON serialization">class Config(object):
    pass


def get_hive_config():
    """ Get pre-defined Hive configuration.

    :return: Config object for Hive.
    """

    conn = Config()
    conn.type = "hive"
    conn.host = "192.168.5.184"
    conn.user = "cloudera"
    conn.password = "password"
    conn.url = "jdbc:hive2://192.168.5.184:10000/DWH"

    return conn


def get_vertica_config():
    """ Get pre-defined Vertica configuration.

    :return: Config object for Vertica.
    """

    conn = Config()
    conn.type = "vertica"
    conn.host = "192.168.5.174"
    conn.user = "dbadmin"
    conn.password = "password"
    conn.url = "jdbc:vertica://192.168.5.174:5433/VMart"

    return conn


def create_config_file(filename, query_generator):

    hive_source = get_hive_config()
    vertica_target = get_vertica_config()

    config = Config()
    config.source = hive_source
    config.target = vertica_target
    config.testName = "count"
    config.queries = query_generator

    with open(filename, 'w') as config_file:
        json.dump(config, config_file)


def main():

    FILE_NAME = "hive_vertica_count.json"
    query_generator = generate_count_queries()
    create_config_file(FILE_NAME, query_generator)
</code></pre>

<p>This first attempt with <code>json.dump(config, config_file)</code> will fail with the following error:</p>

<pre><code class="python JSON serialization error">TypeError: &lt;__main__.Config object at 0x10ab824d0&gt; is not JSON serializable
</code></pre>

<p>As the message indicates, <code>Config</code> object is not JSON serializable.
<code>json.dump</code> function expects a serializable object such as one of Python standard object types (see Python to JSON mapping table below) or their subclasses.</p>

<table>
<thead>
<tr>
<th> Python </th>
<th> JSON </th>
</tr>
</thead>
<tbody>
<tr>
<td> dict </td>
<td> object </td>
</tr>
<tr>
<td> list, tuple </td>
<td> array </td>
</tr>
<tr>
<td> str, unicode </td>
<td> string </td>
</tr>
<tr>
<td> int, long, float </td>
<td> number </td>
</tr>
<tr>
<td> True </td>
<td> true </td>
</tr>
<tr>
<td> False </td>
<td> false </td>
</tr>
<tr>
<td> None </td>
<td> null </td>
</tr>
</tbody>
</table>


<p><br></p>

<p>The solution for that problem is to specify the <code>default</code> parameter with a function that returns object&rsquo;s <code>__dict__</code> attribute.
<code>__dict__</code> is the internal attribute dictionary that contains all attributes associated with an object.
Object attribute references are translated to lookups in this dictionary, e.g., <code>o.x</code> is translated to <code>o.__dict__["x"]</code>.</p>

<pre><code class="python Correct options">    with open(filename, 'w') as config_file:
        json.dump(config, config_file, default=vars, indent=4)
</code></pre>

<pre><code class="python Pretty print without ordering">{
    "source": {
        "url": "jdbc:hive2://192.168.5.184:10000/DWH", 
        "host": "192.168.5.184", 
        "password": "password", 
        "type": "hive", 
        "user": "cloudera"
    }, 
    "queries": "...", 
    "target": {
        "url": "jdbc:vertica://192.168.5.174:5433/VMart", 
        "host": "192.168.5.174", 
        "password": "password", 
        "type": "vertica", 
        "user": "dbadmin"
    }, 
    "testName": "count"
}
</code></pre>

<p>Here, we use <code>vars</code> <a href="https://docs.python.org/2/library/functions.html#vars">built-in function</a> to retrieve the object&rsquo;s <code>__dict__</code> attribute.
Note that simply using <code>json.dump(vars(config), config_file)</code> will NOT work if any attribute of the object is another complex object (e.g., <code>source</code> and <code>target</code> attributes in this example).
For more complex objects such as those include <code>set</code>s, we may have to define our own Encoder that extends <code>json.JSONEncoder</code> and provide it to <code>json.dump</code> function.
The next <a href="/blog/2016/05/25/convert-python-objects-to-json-ordered-keys/">post</a> will discuss how to print keys in order of which they are defined, like in the Java example.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Use One Mocking Framework ONLY]]></title>
    <link href="http://tdongsi.github.io/blog/2016/02/21/java-1-single-mocking-framework/"/>
    <updated>2016-02-21T12:20:46-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/02/21/java-1-single-mocking-framework</id>
    <content type="html"><![CDATA[<p>We know that mocking is a critical enabler for unit tests and automated functional tests that don’t require networks and databases and can complete in reasonable time.
In a large corporate such as Intuit, different business groups tend to adopt different mocking tools/frameworks for their development and test automation needs.
The choice of mocking framework is usually decided by personal preference and experience of few key members of development/automation team.
Mocking tools work by integrating with and replacing critical parts of the Java Class Loader.
It means that having multiple mocking tools in use will lead to those tools contend to replace the class loader in JVM.
This will lead to complex and unexpected consequences and, as a result, random test failures and unreliable tests.
For example, we might have tests that work fine locally but start failing when running in combination with others (using other mocking tools) because different mocking frameworks take over the class loader in different order or in different ways.</p>

<p>To fix that, we need to standardize and settle early on a single mocking framework for an organization or a project.
Sadly, this is often overlooked before it is too late.</p>
]]></content>
  </entry>
  
</feed>
