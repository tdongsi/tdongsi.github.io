<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Git | Personal Programming Notes]]></title>
  <link href="http://tdongsi.github.io/blog/categories/git/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/"/>
  <updated>2017-07-12T02:34:38-07:00</updated>
  <id>http://tdongsi.github.io/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Jenkins Pipeline Shared Libraries]]></title>
    <link href="http://tdongsi.github.io/blog/2017/03/17/jenkins-pipeline-shared-libraries/"/>
    <updated>2017-03-17T15:38:14-07:00</updated>
    <id>http://tdongsi.github.io/blog/2017/03/17/jenkins-pipeline-shared-libraries</id>
    <content type="html"><![CDATA[<p>When you have multiple Pipeline jobs, you often want to share some parts of the Jenkinsfiles between them to keep Jenkinfiles <a href="https://en.wikipedia.org/wiki/Don't_repeat_yourself">DRY</a>.
A very common use case is that you have many projects that are built in the similar way, such as Nexus authentication step in Gradle build.
One way is to use <a href="https://github.com/jenkinsci/workflow-cps-global-lib-plugin">Workflow plugin</a>.
Comprehensive user documentation can be found in <a href="https://jenkins.io/doc/book/pipeline/shared-libraries/">this section</a> of Jenkins handbook.</p>

<p>In the following sections, we review a couple <strong>older</strong>, but not necessarily worse, ways of updating shared Groovy code which are still used in some Jenkins system.</p>

<!--more-->


<h3>Simple copying</h3>

<p>A quick and dirty way of updating shared Groovy codes in Jenkinsfile is to overwrite Groovy files on Jenkins in its <code>$JENKINS_HOME</code>.
All such Groovy files are stored in <em>$JENKINS_HOME/workflow-libs</em> folder, following this directory structure:</p>

<pre><code class="plain Directory structure of a Shared Library repository">(root)
+- src                     # Groovy source files
|   +- org
|       +- foo
|           +- Bar.groovy  # for org.foo.Bar class
+- vars
|   +- foo.groovy          # for global 'foo' variable
|   +- foo.txt             # help for 'foo' variable
+- resources               # resource files (external libraries only)
|   +- org
|       +- foo
|           +- bar.json    # static helper data for org.foo.Bar
</code></pre>

<p>By manually modifying the Groovy files (e.g., <em>vars/foo.groovy</em>) and restarting Jenkins, you can update their behaviors accordingly.
This method is dirty and definitely bad since it requires a Jenkins restart and modifications to Groovy codes are not tracked (and code-reviewed) anywhere.</p>

<h3>Git-based update</h3>

<p>A more scalable alternative for updating Groovy codes is to use <code>git push</code>, exposed by Jenkins.</p>

<p>As a side note, this method is no longer mentioned in documentation, as of March 2017.
In fact, you have to look into a <a href="https://github.com/jenkinsci/workflow-cps-global-lib-plugin/tree/ce1177278d4cb05ac6b01f723177cc4b2e0aec8d">very old commit</a>
or <a href="https://github.com/cloudbees/workflow-plugin/tree/master/cps-global-lib">outdated, unofficial fork</a> to find this method briefly mentioned at all.
It is also occasionally mentioned in support articles such as <a href="https://support.cloudbees.com/hc/en-us/articles/218162277-Unable-to-Clone-workflowLibs">this</a>.</p>

<p>In this method, the directory <em>$JENKINS_HOME/workflow-libs</em> is exposed by Jenkins as a Git repository.
You can deploy new changes to this directory through <code>git push</code> and any such event will trigger Jenkins to recompile Groovy files.
There is no Jenkins restart required for this method, which makes it much more suitable for production Jenkins.
The Git repository is exposed in two endpoints:</p>

<ul>
<li><a href="http://server/jenkins/workflowLibs.git">http://server/jenkins/workflowLibs.git</a> (when your Jenkins is <code>http://server/jenkins/</code>).</li>
<li>ssh://USERNAME@server:PORT/workflowLibs.git (when Jenkins acts as <a href="https://wiki.jenkins-ci.org/display/JENKINS/Jenkins+SSH">an SSH server</a>)</li>
</ul>


<p>This method also means that the shared Jenkins library scripts in Groovy are stored in another Git repository (e.g., &ldquo;shared-lib&rdquo; on Github) and only <code>git push</code> to the <code>workflowLibs.git</code> repository in the event of deployment.
Having the shared scripts in Git allows you to track changes, perform tested deployments, and reuse the same shared library across a large number of instances.</p>

<h4>Jenkinsfile to update global library</h4>

<p>In this Git-based update approach, all Groovy files should be in some Git repository (e.g., &ldquo;shared-lib&rdquo;) with certain directory structure (shown in the last section).
Since Jenkinsfile has been extensively used for creating CI/CD pipelines, it is only appropriate to add a Jenkinsfile for deploying Groovy files in this Git repository to update Jenkins.
The Jenkinsfile for such workflow-libs should be as follows:</p>

<pre><code class="plain Jenkinsfile for deployment">  stage 'Checkout'
  checkout scm

  if (env.BRANCH_NAME == 'master') {
    stage 'Update'
    println "Updating Jenkins workflow-libs"
    sshagent(['jenkins_ssh_key']) {
      sh """
         git branch master
         git checkout master
         ssh-keyscan -H -p 12222 \${JENKINS_ADDR} &gt;&gt; ~/.ssh/known_hosts
         git remote add jenkins ssh://tdongsi@\${JENKINS_ADDR}:12222/workflowLibs.git
         git push --force jenkins master
      """
    }
  }
</code></pre>

<p>Some comments on this Jenkinsfile:</p>

<ul>
<li><code>sshagent(['jenkins_ssh_key'])</code> indicates that the current node/slave is known as <a href="https://wiki.jenkins-ci.org/display/JENKINS/SSH+Agent+Plugin">an SSH agent</a> to Jenkins master, using Jenkins credentials with ID <code>jenkins_ssh_key</code>.</li>
<li><code>git remote add</code> uses the currently checked out Git repo and branch as a remote branch (named &ldquo;jenkins&rdquo;) to the <code>workflowLibs</code> repository.</li>
<li>The <code>workflowLibs</code> repository is managed by Jenkins, exposed at that location <em>ssh://tdongsi@\${JENKINS_ADDR}:12222/workflowLibs.git</em>.</li>
<li>Then we force push any new changes to the Git repository on Jenkins.</li>
</ul>


<p>After the push, the Git repository <code>workflowLibs</code> on Jenkins should have latest change, same as the current &ldquo;shared-lib&rdquo; repository.
Upon a <code>git push</code> event, the Jenkins will automatically update its global library with the latest changes, without the need of restarting.
Note that for this SSH push to work, a public-private key pair must be generated and configured accordingly.</p>

<pre><code class="plain Key pair generation">mymac:jenkins tdongsi$ kubectl --namespace=jenkins exec -ti jenkins-ideb4 -- bash

jenkins@jenkins-4076880321-ideb4:~$ ssh-keygen -t rsa -b 4096 -C "example@gmail.com"
Generating public/private rsa key pair.
Enter file in which to save the key (/var/jenkins_home/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
</code></pre>

<p>The generated public key should be added to the user via <em>jenkinsurl.com/user/tdongsi/configure</em> URL and private key should be added to the credentials ID <code>jenkins_ssh_key</code>.</p>

<h3>References</h3>

<ul>
<li><a href="https://github.com/cloudbees/workflow-plugin/tree/master/cps-global-lib">Git-based update</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Git: Allow-empty When Squashing]]></title>
    <link href="http://tdongsi.github.io/blog/2016/07/05/git-allow-empty-when-squashing/"/>
    <updated>2016-07-05T00:15:57-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/07/05/git-allow-empty-when-squashing</id>
    <content type="html"><![CDATA[<p>Many times in Git, we commit some work only to realize that is a mistake, and we should do another way.
The easy way to fix that is to revert the previous commit, a process in which Git creates another commit that undoes exactly everything in the last commit.
After that, we move on with the other way and check in commits for that.
Before pushing everything to the remote branch, as responsible software engineers :), we sometimes want to &ldquo;squash&rdquo; the commits to erase the mistake to keep the commit log clean.</p>

<!--more-->


<p>In the example shown below, my commit <code>daefc6e</code> was a mistake, and I reverted it with <code>f3886c2</code> commit, and then I checked in my correct solution in <code>b4cb02d</code> commit.
I wanted to squash those commits in an interactive rebase session, as seen in the following:</p>

<pre><code class="plain Rebase commands shown in text editor">pick daefc6e KSAFE REMOVAL.
squash f3886c2 Revert "KSAFE REMOVAL."
squash b4cb02d Update constants.

# Rebase 41ab184..b4cb02d onto 41ab184
#
# Commands:
#  p, pick = use commit
#  r, reword = use commit, but edit the commit message
#  e, edit = use commit, but stop for amending
#  s, squash = use commit, but meld into previous commit
#  f, fixup = like "squash", but discard this commit's log message
#  x, exec = run command (the rest of the line) using shell
#
# These lines can be re-ordered; they are executed from top to bottom.
#
# If you remove a line here THAT COMMIT WILL BE LOST.
#
# However, if you remove everything, the rebase will be aborted.
#
# Note that empty commits are commented out
</code></pre>

<p>However, <code>git rebase</code> always fail in such situations with the following &ldquo;error&rdquo; message:</p>

<pre><code class="plain git rebase fails">$ git rebase -i origin/feature/foobar
You asked to amend the most recent commit, but doing so would make
it empty. You can repeat your command with --allow-empty, or you can
remove the commit entirely with "git reset HEAD^".
rebase in progress; onto 41ab184
You are currently rebasing branch 'feature/foobar' on '41ab184'.

No changes

Could not apply f3886c23589e0964a4483f6454c6edeba7d63fb7... KSAFE REMOVAL.
</code></pre>

<p>The error message is very confusing.
When <code>daefc6e</code> and <code>f3886c2</code> commits are squashed, the net effect is nothing, which is the &ldquo;empty commit&rdquo; mentioned in that error message.
However, retrying the <code>git rebase</code> command with <code>--allow-empty</code> as said does not work.</p>

<pre><code class="plain">$ git rebase --interactive --allow-empty 
error: unknown option `allow-empty' 
</code></pre>

<p>Using <code>git rebase --continue</code> does not work as expected: it does not squash three commits into one.</p>

<p>After some Google searching, it turns out that the above error message comes from <code>git commit --amend</code>, which is delegated by <code>git rebase</code> to handle the squash.
When the message says &ldquo;repeat your command&rdquo;, it means repeating the <code>git commit --amend</code> command, something would never occurs to us.
Therefore, the right thing to do here is repeat <code>commit</code> and continue with the interactive rebase session:</p>

<pre><code class="plain">$ git commit --amend --allow-empty
[detached HEAD 706f662] Revert "KSAFE REMOVAL."

$ git rebase --continue
[detached HEAD 923477f] Revert "KSAFE REMOVAL."
 1 file changed, 3 insertions(+), 3 deletions(-)
Successfully rebased and updated refs/heads/feature/foobar.
</code></pre>

<p>By doing that, we will now have all three commits squashed into one and help cleaning up the commit log.</p>

<!--
http://git.661346.n2.nabble.com/Confusing-error-message-in-rebase-when-commit-becomes-empty-td7612948.html
-->

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Symlinks in Git]]></title>
    <link href="http://tdongsi.github.io/blog/2016/02/20/symlinks-in-git/"/>
    <updated>2016-02-20T11:28:11-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/02/20/symlinks-in-git</id>
    <content type="html"><![CDATA[<p>Let&rsquo;s say we have folders with many symbolic links in them, linking to other files in the same Git repository.</p>

<pre><code class="bash Before">$ ls -l link
... link -&gt; /path/to/target
</code></pre>

<p>Unfortunately after committing into Git, they&rsquo;ve turned into plain text files.
Note that even after committing and pushing into Git, the symlinks still work fine.
However, after some branch switches and code merges, the symlinks become actual text files with the link target as the contents.</p>

<pre><code class="bash After">$ cat link
/path/to/target
</code></pre>

<!--more-->


<h3>Restoring the symlinks</h3>

<p>Before going into lengthy discussion on how Git handles symlinks and hard links, the quick solution for the above problem is the following Bash script:</p>

<pre><code class="bash">folder=/Users/tdongsi/Github/my_repo/scripts/sql
ls -d1 $folder/* | while read f; do
  ln -sf "$(cat $f)" "$f"
done
</code></pre>

<p>where <code>ls -d1 $folder/*</code> should be replaced with some command that will list exactly the files you want, preferably in full path.
Note that <code>-f</code> option of <code>ln</code> command is required to replace the file with the symlink. For examples:</p>

<pre><code class="bash Examples">ls -d1 vertica/*.sql | while read f; do
  ln -sf "$(cat $f)" "$f"
done

ls -d1 bash/* | while read f; do
  ln -sf "$(cat $f)" "$f"
done
</code></pre>

<p><strong>Best practice note</strong>: I think that the following template is preferred to the more commonly seen <code>for f in $(ls *);</code> <code>do...done</code>:</p>

<pre><code class="bash">ls * | while read f; do
  # command executed for each file
done
</code></pre>

<p>I think it is the better way to handle all file names, especially with spaces, since <code>"$f"</code> will still work.
In addition, <code>$(cmd)</code> is the same as <code>'cmd'</code> (backticks) but it can be nested, unlike using backticks.
It fact, it&rsquo;s the main reason why the backticks have been <a href="http://wiki.bash-hackers.org/scripting/obsolete">deprecated</a> from Bash scripting.</p>

<h3>How Git deals with symlinks</h3>

<p>How Git deals with symlinks is defined in the <a href="https://git-scm.com/docs/git-config">git config</a> <code>core.symlinks</code>.
If false, symbolic links are checked out as small plain files that contain the link text.
<a href="http://stackoverflow.com/questions/954560/how-does-git-handle-symbolic-links">Otherwise</a>, Git just stores the contents of the link (i.e., the path of the file system) in a &lsquo;blob&rsquo; just like it would for a normal file.
It also stores the name, mode and type (e.g., symlink) in the tree object that represents its containing directory.
When you checkout a tree containing the link, it restores the object as a symlink.</p>

<p>After the symlinks are checked out as plain text files, I believe it is pretty much no way for Git to restore symlinks again (i.e., follow symlinks inside text files).
It would be an insecure, undefined behavior: what if the symlink as text file is modified? What if the target is changed when moving between versions of that text file?</p>

<h3>Use hard links?</h3>

<p>You can use hard links instead of symlinks (a.k.a., soft links).
Git will handle a hard link like a copy of the file, except that the contents of the linked files change at the same time.
Git may see changes in both files if both the original file and the hard link are in the same repository.</p>

<p>One of the disadvantages is that the file will be created as a normal file during <code>git checkout</code>, because there is no way Git understand it as a link.
Moreover, hard link itself has many limitations, compared to symlinks, such as files have to reside on the same file-system or partition.
In Mac OSX, hard links to directories are not supported. There is a <a href="https://github.com/selkhateeb/hardlink">tool</a> to do that, but use it with caution.</p>

<p>Finally, it is important to note that hard links to files can be lost when moving between different versions/branches in Git, even if they are in the same repository.
When you switch branches back and forth, Git remove the old files and create new ones.
You still have the copies of the previous files, but they might have totally different inodes, while others (if not in the same Git repo) still refers to the old inodes.
Eventually, the file and its hard links may be out of sync, and appear like totally unrelated files to Git.
Therefore, using hard links, at best, is just a temporary solution.</p>

<h3>Links</h3>

<ol>
<li><a href="http://superuser.com/questions/638998/easiest-way-to-restore-symbolic-links-turned-into-text-files">Alternative ways to restore symlinks</a></li>
<li><a href="http://stackoverflow.com/questions/246215/how-can-i-list-files-with-their-absolute-path-in-linux">Alternative ways to list files</a></li>
<li><a href="https://git.wiki.kernel.org/index.php/Git">Git design overview</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Virtual Machine for ETL Testing]]></title>
    <link href="http://tdongsi.github.io/blog/2016/01/10/find-and-replace-a-string-in-multiple-files/"/>
    <updated>2016-01-10T23:49:15-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/01/10/find-and-replace-a-string-in-multiple-files</id>
    <content type="html"><![CDATA[<h3>Vertica Virtual Machine as sandbox test environment</h3>

<p>When developing data-warehouse solutions in Vertica, you want to set up some test environment.
Ideally, you should have separate schema for each developer.
However, it is usually NOT possible in my experience: developers and test engineers have to share very few schemas in development environment.
The explanation that I usually get is that having a schema for each developer will not scale in database maintenance and administration, and there are likely some limits in Vertica&rsquo;s commercial license.
If that is the case, I recommend that we look into using Vertica Community Edition on <strong>Virtual Machines (VMs)</strong> for sandbox test environment, as a cheap alternative.</p>

<p>Are VMs really necessary in data-warehouse testing? When testing Extract-Transform-Load (ETL) processes, I find that many of test cases require regular set-up and tear-down, adding mock records to force rare logical branches and corner cases, and/or running ETLs multiple times to simulate daily runs of those processes.
Regular tear-down requires dropping multiple tables regularly, which requires much greater care and drains much mental energy when working with others' data and tables.
Similarly, adding mock records into some commonly shared tables might affect others when they assume the data is production-like.
Running ETL scripts regularly, which could be computationally intensive, on a shared Vertica cluster might affect the performance or get affected by others' processes.
In short, for these tests, I cannot use the common schema that is shared with others since it might interfere others and/or destroy valuable common data.
Using a Vertica VM as the sandbox test environment helps us minimize interference to and from others' data and activities.</p>

<h3>Single-node VM and KSAFE clause</h3>

<p>I have been using a <strong>single-node</strong> Vertica VM to run tests for sometime. And it works wonderfully for testing purpose, especially when you want to isolate issues, for example, a corner case. The Vertica VM can be downloaded from HP Vertica&rsquo;s support website (NOTE: As of 2016 Jan 1st, the Vertica 7.1 VM is taken down while the Vertica 7.2 VM is not available).</p>

<p>The only minor problem is when we add <code>KSAFE 1</code> in our DDL scripts (i.e., <code>CREATE TABLE</code> statements) for production purposes. This gives error on single-node VM when running DDL scripts to set up schema.
The reason is that Vertica database with one or two hosts cannot be <em>k-safe</em> (i.e., it may lose data if it crashes) and three-node cluster is the minimum requirement to have <code>KSAFE 1</code> in <code>CREATE TABLE</code> statements to work.</p>

<p>Even then, the workaround for running those DDL scripts in tests is easy enough if all DDL scripts are all located in a single folder. The idea is that since <code>KSAFE 1</code> does not affect ETL processes' transform logics, we can remove those KSAFE clauses to set up the test schema and go ahead with our ETL testing. Specifically, in my project, my workflow for ETL testing with <strong>Git</strong> is as follows:</p>

<ul>
<li>Branch the latest code (<code>develop</code> branch) into a temporary branch (e.g., <code>local/develop</code> branch).</li>
<li>Find and remove <code>KSAFE 1</code> in all DDL files (see subsection below).</li>
<li>While still in <code>local/develop</code> branch, commit all these changes in a <strong>single</strong> commit with some unique description (e.g., &ldquo;KSAFE REMOVAL&rdquo;).</li>
<li>Add unit and functional tests to ETL scripts in this branch.</li>
<li>After tests are properly developed and checked-in, reverse the &ldquo;KSAFE REMOVAL&rdquo; commit above.

<ul>
<li>In SourceTree, it could be done by a simple right-click on that commit and selecting &ldquo;Reverse Commit&rdquo;.</li>
</ul>
</li>
<li>Merge <code>local/develop</code> branch into <code>develop</code> branch (create a pull request if needed). You will now have your tests with the latest codes in <code>develop</code> branch.</li>
</ul>


<h4>Find and replace a string in multiple files</h4>

<p>There are times and times again that you find that you have to replace every single occurrences of some string in multiple files with another string. Finding and removing <code>KSAFE 1</code> like the above workflow is an example where &ldquo;removing string&rdquo; is a special case of &ldquo;replacing string&rdquo; with nothing. This operation can be quickly done by the following bash command:</p>

<pre><code>grep -rl match_string your_dir/ | xargs sed -i 's/old_string/new_string/g'
</code></pre>

<p>If you are familiar with bash scripting, the above command is straight forward. This quick explanation is for anyone who does not understand the command:</p>

<ul>
<li><code>grep</code> command finds all files in <code>your_dir</code> directory that contain <code>match_string</code>. <code>-l</code> option makes sure it will return a list of files</li>
<li><code>sed</code> command then execute the replacement regex on all those files. A regex tip: the forward slash <code>/</code> delimiter could be another delimiter (e.g., <code>#</code>). This might be useful if you need to search HTML files.</li>
</ul>


<p>Example: In my case, all the DDL scripts are in multiple sub-directories under <code>tables</code> directory. To find and remove all <code>KSAFE 1</code> occurrences, the command is:</p>

<pre><code>grep -rl 'KSAFE 1' tables | xargs sed -i 's/KSAFE 1//g'
</code></pre>

<p>This will search for the string <code>KSAFE 1</code> in all files in the <code>tables</code> directory and replace <code>KSAFE 1</code> with nothing <code>''</code> for each occurrence of the string in each file.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Octopress Cookbook]]></title>
    <link href="http://tdongsi.github.io/blog/2015/05/11/octopress-cookbook/"/>
    <updated>2015-05-11T13:40:13-07:00</updated>
    <id>http://tdongsi.github.io/blog/2015/05/11/octopress-cookbook</id>
    <content type="html"><![CDATA[<h3>Basic workflow</h3>

<p>In summary, the workflow for writing blog in Octopress is as follows:</p>

<ul>
<li><code>rake new_post["Post title"]</code></li>
<li>Edit &amp; Preview:

<ul>
<li><code>rake generate</code>

<ul>
<li>After this step, the published artifacts are generated in the &ldquo;public&rdquo; directory.</li>
</ul>
</li>
<li><code>rake preview</code>

<ul>
<li>Published pages will be served locally at &ldquo;localhost:4000&rdquo;. Preview it in any browser.</li>
<li>Updated Markdown files will be regenerated automatically.</li>
</ul>
</li>
</ul>
</li>
<li>Publish:

<ul>
<li><code>rake generate</code>

<ul>
<li>This step makes sure latest changes are added.</li>
</ul>
</li>
<li><code>rake deploy</code>

<ul>
<li>After this step, the content in the &ldquo;public&rdquo; directory is copied into &ldquo;_deploy&rdquo; directory and git add/commit/push to the remote Github branch.</li>
</ul>
</li>
</ul>
</li>
</ul>


<h3>Setting up new blog</h3>

<p>This section assumes that we will publish in <code>gh-pages</code> branch which is more common (publishing in <code>master</code> branch only works for <code>username.github.io</code> repository).
In general, any project that we work in a repo <code>foo</code> (with main development in branches <code>master</code>/<code>develop</code>) on Github can have associated documentation HTML site in <code>gh-pages</code> branch.
Such documentation site can be accessed publicly at &ldquo;username.github.io/foo/&rdquo;.
Octopress allows easy generation of such static HTML sites.
One can arrange such that each blog post is a tutorial or a documentation page, written in Markdown and &ldquo;compiled&rdquo; into HTML.</p>

<p>The process of setting up such a static &ldquo;documentation&rdquo; site is as follows:</p>

<ol>
<li>Download the zip file from octopress master branch <a href="https://github.com/imathis/octopress">here</a>. Note that <a href="https://github.com/octopress/octopress">this link</a> is version 3, which is different.</li>
<li>Unzip the zip file into the repo. Rename it to &ldquo;docs&rdquo; or &ldquo;octopress&rdquo;.</li>
<li>Commit it to <code>master</code> or <code>develop</code> branch.</li>
<li>Run <code>rake install</code> to generate files. Check in the generated files.</li>
<li>Create <code>_deploy</code> folder for deployment. For new static site, <code>rake setup_github_pages</code> works.</li>
<li>Start blogging/writing documentation. Use the workflow in the last section: <code>rake generate</code> -> <code>rake preview</code> -> <code>rake deploy</code>.</li>
<li>For layout editing, check out one of early commits in <a href="https://github.com/tdongsi/javascript">this repo</a>.</li>
</ol>


<p>NOTE: when previewing the one published in <code>gh-pages</code>, you need to edit &ldquo;destination: public&rdquo; in <code>_config.yml</code> file to &ldquo;destination: public/repo_name&rdquo;.</p>

<h3>Add a new page</h3>

<p>This section is about adding a new page, opposed to a new post.
The common examples of such page in an Octopress-based blog is &ldquo;About&rdquo; page or &ldquo;Resume&rdquo; page.
To create a new page, use the following command:</p>

<pre><code>rake new_page["About"]
</code></pre>

<p>This will create a new file at &ldquo;source/about/index.markdown&rdquo; and you can edit that file to add content.
After <code>rake generate</code> command, the &ldquo;source/about/index.markdown&rdquo; will &ldquo;compiled&rdquo; into &ldquo;public/about/index.html&rdquo; that is displayed in the web browser.
After the page content is ready, you may want to add an &ldquo;About&rdquo; link in the navigation bar to that page.
To do that, edit the file &ldquo;source/_includes/custom/navigation.html&rdquo;.</p>

<h3>Deployment</h3>

<p>Octopress deploys latest changes with the command <code>rake deploy</code>.
In this <code>deploy</code> step, it copies all the latest changes to the generated static HTML site into a <code>_deploy</code> folder which is a clone of one of the public branches (<code>master</code> or <code>gh-pages</code>) of the same repository.
Create <code>_deploy</code> folder by using this command.</p>

<pre><code class="plain Creating _deploy folder for an on-going blog">git clone -b gh-pages git@github.com:user/myproject.git _deploy
</code></pre>

<p>With Git 1.7.10 and later, add <code>--single-branch</code> to prevent fetching of all branches.</p>

<p>Make sure you use the SSH URL for the Github repo since the HTTPS URL will prompt for password for every deployment.
In addition, SSH public/private key pair must be generated and added to the Github accordingly.
Otherwise, you might get the following errorr:</p>

<pre><code class="plain Common public key error">## Pushing generated _deploy website
Permission denied (publickey).
fatal: Could not read from remote repository.

Please make sure you have the correct access rights
and the repository exists.
</code></pre>

<p>If you get the above message even though the public key is already added to Github, check if you are using the right private key.
Make sure it is added to SSH authentication agent.</p>

<pre><code class="plain Adding SSH identity file">mymac:octopress tdongsi$ ssh-add ~/.ssh/id_rsa_git
Identity added: /Users/tdongsi/.ssh/id_rsa_git (/Users/tdongsi/.ssh/id_rsa_git)

mymac:octopress tdongsi$ ssh-add -l -E md5
2048 MD5:ef:c1:d6:4e:92:d2:15:2c:ef:c3:72:d6:c6:98:23:e0 /Users/tdongsi/.ssh/id_rsa_git (RSA)

# Verify your connection
$ ssh -T git@github.com
</code></pre>

<p>The command <code>ssh-add -l -E md5</code> can be used to find if there is a matching public key on Github.
See <a href="https://help.github.com/articles/error-permission-denied-publickey/">here</a> for more information.</p>

<h3>Reference</h3>

<ul>
<li><a href="http://stackoverflow.com/questions/1911109/how-to-clone-a-specific-git-branch">Clone a specific Git branch</a></li>
<li><a href="http://stackoverflow.com/questions/651038/how-do-you-clone-a-git-repository-into-a-specific-folder">Clone to a specific folder</a></li>
<li><a href="https://help.github.com/articles/error-permission-denied-publickey/">Github instructions on public SSH key</a></li>
</ul>


<p>Recipes:</p>

<ul>
<li><a href="http://blog.zhengdong.me/2012/12/19/latex-math-in-octopress/">Latex for Math formulas</a></li>
<li><a href="http://gangmax.me/blog/2012/05/04/add-about-page-in-octopress/">New page</a></li>
<li><a href="http://octopress.org/docs/plugins/include-code/">Include code from file</a></li>
<li><a href="https://blog.pixelingene.com/2011/09/tips-for-speeding-up-octopress-site-generation/">rake isolate/integrate</a></li>
<li><a href="http://octopress.org/docs/plugins/image-tag/">Image</a></li>
<li><a href="https://github.com/optikfluffel/octopress-responsive-video-embed">Video</a>

<ul>
<li><a href="https://gist.github.com/jamieowen">Improved ruby code</a></li>
</ul>
</li>
</ul>


<p>Markdown editing tips:</p>

<ul>
<li><a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet">Cheat sheet</a></li>
<li>Use  <code>&lt;!-- more —&gt;</code> to specify Excerpt.</li>
<li>Internal link: <code>(/2012/01/05/hello-world)</code> gives the link &ldquo;<a href="http://userName.github.io/repoName/blog/2012/01/05/hello-world">http://userName.github.io/repoName/blog/2012/01/05/hello-world</a>&rdquo;</li>
</ul>

]]></content>
  </entry>
  
</feed>
