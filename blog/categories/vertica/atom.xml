<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Vertica | Personal Programming Notes]]></title>
  <link href="http://tdongsi.github.io/blog/categories/vertica/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/"/>
  <updated>2016-02-20T21:18:02-08:00</updated>
  <id>http://tdongsi.github.io/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Symlinks in Git]]></title>
    <link href="http://tdongsi.github.io/blog/2016/02/20/symlinks-in-git/"/>
    <updated>2016-02-20T11:28:11-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/02/20/symlinks-in-git</id>
    <content type="html"><![CDATA[<h3>Context</h3>

<p>I had folders with many symbolic links in them, linking to other files in the same Git repository.</p>

<pre><code class="bash Before">$ ls -l link
... link -&gt; /path/to/target
</code></pre>

<p>Unfortunately after committing into Git, they&rsquo;ve turned into plain text files.
Note that even after committing and pushing into Git, the symlinks still work fine.
However, after some branch switches and code merges, the symlinks become actual text files with the link target as the contents.</p>

<pre><code class="bash After">$ cat link
/path/to/target
</code></pre>

<p>If you unknowingly try to run some symlinks linked to SQL scripts like that, you might end up with numerous errors like this:</p>

<pre><code class="plain">vsql:schema_create.sql:1: ERROR 4856:  Syntax error at or near "/" at character 1
vsql:schema_create.sql:1: LINE 1: /Users/tdongsi/Github/my_repo/db_schema/file...
</code></pre>

<h3>Restoring the symlinks</h3>

<p>Before going into lengthy discussion on how Git handles symlinks and hard links, the quick solution for the above problem is the following Bash script:</p>

<pre><code class="bash">folder=/Users/tdongsi/Github/my_repo/scripts/sql
ls -d1 $folder/* | while read f; do
  ln -sf "$(cat $f)" "$f"
done
</code></pre>

<p>where <code>ls -d1 $folder/*</code> should be replaced with some command that will list exactly the files you want, preferably in full path.
Note that <code>-f</code> option of <code>ln</code> command is required to replace the file with the symlink. For examples:</p>

<pre><code class="bash Examples">ls -d1 vertica/*.sql | while read f; do
  ln -sf "$(cat $f)" "$f"
done

ls -d1 bash/* | while read f; do
  ln -sf "$(cat $f)" "$f"
done
</code></pre>

<p><strong>Best practice notes</strong>: I think that the following template is preferred to the more commonly seen <code>for f in $(ls *);</code> <code>do...done</code>:</p>

<pre><code class="bash">ls * | while read f; do
  # command executed for each file
done
</code></pre>

<p>This is the right way to handle all file names, especially with spaces, since <code>"$f"</code> will still work.
In addition, <code>$(cmd)</code> is the same as <code>'cmd'</code> (backticks) but it can be nested, unlike using backticks.
It fact, it&rsquo;s the main reason why the backticks have been <a href="http://wiki.bash-hackers.org/scripting/obsolete">deprecated</a> from Bash scripting.</p>

<h3>How Git deals with symlinks</h3>

<p>How Git deals with symlinks is defined in the <a href="https://git-scm.com/docs/git-config">git config</a> <code>core.symlinks</code>.
If false, symbolic links are checked out as small plain files that contain the link text.
<a href="http://stackoverflow.com/questions/954560/how-does-git-handle-symbolic-links">Otherwise</a>, Git just stores the contents of the link (i.e., the path of the file system) in a &lsquo;blob&rsquo; just like it would for a normal file.
It also stores the name, mode and type (e.g., symlink) in the tree object that represents its containing directory.
When you checkout a tree containing the link, it restores the object as a symlink.</p>

<p>After the symlinks are checked out as plain text files, I believe it is pretty much no way for Git to restore symlinks again (i.e., follow symlinks inside text files).
It would be an insecure, undefined behavior: what if the symlink as text file is modified? What if the target is changed when moving between versions of that text file?</p>

<h3>Use hard links?</h3>

<p>You can use hard links instead of symlinks (a.k.a., soft links).
Git will handle a hard link like a copy of the file, except that the contents of the linked files change at the same time.
Git may see changes in both files if both the original file and the hard link are in the same repository.</p>

<p>One of the disadvantages is that the file will be created as a normal file during <code>git checkout</code>, because there is no way Git understand it as a link.
Moreover, hard link itself has many limitations, compared to symlinks, such as files have to reside on the same file-system or partition.
In Mac OSX, hard links to directories are not supported. There is a <a href="https://github.com/selkhateeb/hardlink">tool</a> to do that, but use it with caution.</p>

<p>Finally, it is important to note that hard links to files can be lost when moving between different versions/branches in Git, even if they are in the same repository.
When you switch branches back and forth, Git remove the old files and create new ones.
You still have the copies of the previous files, but they might have totally different inodes, while others (if not in the same Git repo) still refers to the old inodes.
Eventually, the file and its hardl links may be out of sync, and appear like totally unrelated files to Git.
Therefore, using hard links, at best, is just a temporary solution.</p>

<h3>Links</h3>

<ol>
<li><a href="http://superuser.com/questions/638998/easiest-way-to-restore-symbolic-links-turned-into-text-files">Alternative ways to restore symlinks</a></li>
<li><a href="http://stackoverflow.com/questions/246215/how-can-i-list-files-with-their-absolute-path-in-linux">Alternative ways to list files</a></li>
<li><a href="https://git.wiki.kernel.org/index.php/Git">Git design overview</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vertica: Performance Optimization Notes]]></title>
    <link href="http://tdongsi.github.io/blog/2016/02/13/vertica-8-performance-tuning/"/>
    <updated>2016-02-13T23:52:44-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/02/13/vertica-8-performance-tuning</id>
    <content type="html"><![CDATA[<p>Most of these optimization notes in this post are learnt through interaction with <a href="http://www.nexius.com/software-and-business-intelligence/">Nexius</a> consultants.
Also see <a href="/blog/2015/12/16/vertica-tip-best-practices/">Vertica Best Practices</a>.</p>

<h3><code>NOT IN</code> better than <code>NOT EXISTS</code></h3>

<p>When we want to insert a row into a dimension table AND check for duplicates at the same time, we usually do this in DML scripts:</p>

<pre><code class="sql BAD">SELECT 'United States', 'English' 
WHERE NOT EXISTS (SELECT 'x' FROM dim_country WHERE country_name = 'United States')
</code></pre>

<p>However, for all such inserts, we were recently informed that it is better <strong>in Vertica</strong> to do <code>NOT IN</code> instead of <code>NOT EXISTS</code>.
So, for example above:</p>

<pre><code class="sql GOOD">SELECT 'United States', 'English' 
WHERE 'United States' NOT IN (select country_name from dim_country)
</code></pre>

<h3>Avoid using <code>LEFT JOIN</code> to check existence</h3>

<p>Let&rsquo;s say we have an ETL that regularly inserts new data into an existing dimension table.</p>

<pre><code class="sql BAD">INSERT INTO dim_country                    
(
    country_id,
    country_name,
    country_language,
) 
SELECT ssp.country_id,
    ssp.country_name,
    ssp.country_language,
FROM staging_table ssp
LEFT JOIN dim_country dc on dc.country_id=ssp.country_id
WHERE dc.country_id is NULL;
</code></pre>

<p>We are sometimes doing <code>LEFT JOIN</code> like this only to determine whether or not an entry already exists in the table.
It would be faster to use a <code>WHERE</code> clause instead to perform that existence check.
Although it might sound counter-intuitive, but reducing <code>JOIN</code> operations like this has been regularly recommended.</p>

<pre><code class="sql GOOD">INSERT INTO dim_country                    
(
    country_id,
    country_name,
    country_language,
) 
SELECT ssp.country_id,
    ssp.country_name,
    ssp.country_language,
FROM staging_table ssp
WHERE ssp.country_id NOT IN (SELECT country_id FROM dim_country);
</code></pre>

<h3>Avoid function calls in <code>WHERE</code> and <code>JOIN</code> clauses</h3>

<p>For this performance tip, we make a slight change to the example ETL in the last section above where <code>country_id</code> column is removed. In this case, we can use a normalized <code>country_name</code> as the ID to check for existing entries in the table:</p>

<pre><code class="sql BAD">INSERT INTO dim_country                    
(
    country_name,
    country_language,
) SELECT ssp.country_name,
    ssp.country_language,
FROM staging_table ssp
LEFT JOIN dim_country dc on lower(dc.country_name)=lower(ssp.country_name)
WHERE dc.country_name is NULL;
</code></pre>

<p>In this example, we normalize <code>country_name</code> to lower case. Note that <code>WHERE</code> clause should be used instead of <code>LEFT JOIN</code> as discussed above.</p>

<pre><code class="sql BETTER, but still BAD">INSERT INTO dim_country                    
(
    country_name,
    country_language,
) SELECT ssp.country_name,
    ssp.country_language,
FROM staging_table ssp
WHERE lower(ssp.country_name) NOT IN (SELECT lower(country_name) FROM dim_country);;
</code></pre>

<p>However, such change still has bad performance because, in general, function calls in <code>WHERE</code> and <code>JOIN</code> clauses should be avoided in Vertica.
In both examples above, calling functions like <code>LOWER</code> in <code>WHERE</code> and <code>JOIN</code> clauses will affect the performance of the ETLs.</p>

<p>The solution for this scenario is that, since we control what goes into dimension tables, we can ensure that columns like <code>country_name</code> are always stored in lower-case.
Then, we can do the same when creating the temporary table such as <code>staging_table</code> that we are comparing to for checking existence.</p>

<h3>Use  <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/Functions/VerticaFunctions/ANALYZE_STATISTICS.htm">ANALYZE_STATISTICS</a></h3>

<p>Make sure to run <code>ANALYZE_STATISTICS</code> after all data loads.
Using this function, tables are analyzed for best performance in subsequent queries ran against it.
Without information from <code>ANALYZE_STATISTICS</code>, the query optimizer assumes uniform distribution of data values and equal storage usage for all projections.</p>

<p>Note that <code>ANALYZE_STATISTICS</code> is only supported on <em>local</em> temporary tables, but not on <em>global</em> temporary tables.
In addition, when we add <code>ANALYZE_STATISTICS</code> function calls into our ETL scripts, errors might be thrown when a second <code>ANALYZE_STATISTICS</code> call is made while the first is still running.
Those errors can be ignored but they must be caught accordingly to separate with other Vertica error messages.</p>

<h3>Avoid creating temporary tables using <code>SELECT</code></h3>

<p>Instead of creating temporary tables using <code>SELECT</code>, it is recommended to:</p>

<ol>
<li>Create the temporary table first without a projection.</li>
<li>Create a super <a href="/blog/2016/02/07/vertica-post-7/">projection</a> with the correct column encodings and <code>ORDER BY</code> clause</li>
<li>Populate it using <code>INSERT /*+ direct */ INTO</code>. Note the <code>/*+ direct */</code> hint to write data directly to disk, bypassing memory.</li>
<li>Run <code>ANALYZE_STATISTICS</code>. See the last section.</li>
</ol>


<p>For example, in a Vertica ETL script that runs daily, we usually create a temporary table to retrieve the latest records from a source table like this:</p>

<pre><code class="sql BAD">CREATE TEMPORARY TABLE customer_last_temp 
ON COMMIT PRESERVE ROWS
AS(
  select * from (
    select *,
    row_number() OVER (PARTITION BY customer_id ORDER BY last_modify_date DESC) AS rank 
    from  stg_customer rpt 
  ) t1 where t1.rank =1
);
</code></pre>

<p>In this example, <code>last_modify_date</code> is the <a href="https://en.wikipedia.org/wiki/Change_data_capture">CDC</a> column and <code>customer_id</code> is the primary key column.
Although this SQL statement is simple and easy to understand, it is really slow for a large and growing <code>stg_customer</code> table that contains updates to all customers on multiple dates, with millions of <em>new</em> customer entries each day.
Instead, the recommended coding pattern is to create a temporary table first without a projection:</p>

<pre><code class="sql Create a temporary table without projection">CREATE LOCAL TEMPORARY TABLE customer_last_temp  ( 
        customer_id                     int,
        subscribe_date                  timestamp,
        cancel_date                     timestamp,
        last_modify_date                timestamp,
)
ON COMMIT PRESERVE ROWS NO PROJECTION;
</code></pre>

<p>It is also recommended that the column names are explicitly specified, so that only required columns are created in the temporary table.
A <code>LOCAL</code> temporary table is created, instead of <code>GLOBAL</code>, so that we can use <code>ANALYZE_STATISTICS</code> functions as discussed above.
Next, create a super projection with the correct column encodings and <code>ORDER BY</code> clause:</p>

<pre><code class="sql Create a super projection">CREATE PROJECTION customer_last_temp_super (
      customer_id ENCODING DELTARANGE_COMP 
    , subscribe_date ENCODING GCDDELTA
    , cancel_date ENCODING BLOCKDICT_COMP     
    , last_modify_date ENCODING BLOCKDICT_COMP 
)
AS 
SELECT customer_id 
     , subscribe_date
     , cancel_date
     , last_modify_date
  FROM customer_last_temp 
 ORDER BY customer_id
SEGMENTED BY HASH (customer_id) ALL NODES;
</code></pre>

<p>Finally, insert &ldquo;directly&rdquo; into the temporary table:</p>

<pre><code class="sql Populate the table">INSERT /*+ direct */ INTO customer_last_temp (
      customer_id 
    , subscribe_date 
    , cancel_date 
    , last_modify_date 
)
WITH t1 AS (
    SELECT company_id 
         , subscribe_date 
         , cancel_date 
         , last_modify_date 
         , ROW_NUMBER() OVER (PARTITION BY customer_id 
                                  ORDER BY last_modify_date DESC) AS rank 
      FROM stg_customer AS rpt 
)
SELECT company_id 
     , subscribe_date 
     , cancel_date 
     , last_modify_date 
FROM t1
WHERE t1.rank = 1;  
</code></pre>

<p>The <code>WITH</code> clause is just a more readable way to write the sub-query in the original SQL statement (see <a href="/blog/2016/02/03/vertica-post-8/">WITH clause</a>).
In addition, the wildcard <code>*</code> in the original SQL query is also avoided, in case the table <code>stg_customer</code> is a very wide table.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vertica Projections]]></title>
    <link href="http://tdongsi.github.io/blog/2016/02/07/vertica-7-projections/"/>
    <updated>2016-02-07T00:50:44-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/02/07/vertica-7-projections</id>
    <content type="html"><![CDATA[<p>Projections are key in Vertica performance tuning.
Details of Vertica projections are discussed in the following blog posts from HP-Vertica:</p>

<ol>
<li><a href="https://www.vertica.com/2011/09/01/the-power-of-projections-part-1/">https://www.vertica.com/2011/09/01/the-power-of-projections-part-1/</a></li>
<li><a href="https://www.vertica.com/2011/09/02/the-power-of-projections-part-2/">https://www.vertica.com/2011/09/02/the-power-of-projections-part-2/</a></li>
<li><a href="https://www.vertica.com/2011/09/06/the-power-of-projections-part-3/">https://www.vertica.com/2011/09/06/the-power-of-projections-part-3/</a></li>
</ol>


<p>In summary, Vertica projections represent collections of columns (like table) but they are optimized for analytics at the physical storage structure level and they are not constrained by the logical schema.
For each regular table, Vertica requires a minimum of one projection, called a “superprojection”.
Vertica creates a default super-projection when running CREATE TABLE statement.
<a href="https://www.vertica.com/2011/09/06/the-power-of-projections-part-3/">Part 3</a> also compares Vertica projections with &ldquo;Materialized Views&rdquo; and &ldquo;Indexes&rdquo; in traditional databases.</p>

<p>For Vertica performance tuning, we create multiple projections, customize them and parameters of each projection to achieve the best performance.
Database Designer is a tool provided by Vertica to help us find the optimal projections, based on data statistics and frequent queries.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[WITH Clause in SQL]]></title>
    <link href="http://tdongsi.github.io/blog/2016/02/03/vertica-6-with-clause/"/>
    <updated>2016-02-03T00:50:48-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/02/03/vertica-6-with-clause</id>
    <content type="html"><![CDATA[<p>I am pleasantly surprised that Vertica SQL supports <code>WITH</code> clause, as documented <a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/AnalyzingData/Queries/WITHClausesInSELECT.htm">here</a>.
<code>WITH</code> syntax as a standard is only defined in <a href="https://en.wikipedia.org/wiki/SQL:1999">SQL-99</a>, also called <em>Common Table Expressions</em>.
Therefore, I do not usually expect <code>WITH</code> clause since it is a fairly recent feature in most SQL dialects.
For example: <code>WITH</code> clause support is only added into SQLite since Feb 2014.</p>

<p>In summary, the <code>WITH</code> clause allows us to arrange sub-queries in a SQL query in order of human logic.
This will make our query much easier to read: we can read from top to bottom like reading a story (i.e., <a href="https://en.wikipedia.org/wiki/Literate_programming">literate programming</a>).</p>

<p>For example, we can look into the following <code>SELECT</code> query:</p>

<pre><code class="sql Hard to read">SELECT * FROM (
  SELECT *,
  row_number() OVER (PARTITION BY customer_id ORDER BY last_modify_date DESC) AS rank 
  FROM stg_customer
) sorted_by_modify_date where sorted_by_modify_date.rank =1
</code></pre>

<p>Before <code>WITH</code> clause, SQL scripts are usually hard to read due to nesting of sub-queries.
To understand a SQL statement, we have to find and understand the innermost sub-query first and start working from inside out.
In addition, as shown in the first example, name <code>sorted_by_modify_date</code> following the sub-query makes reading harder, even with meaningful names.
The longer the inner query gets, the more likely the name for that query is pushed out of sight despite the fact that it is important to see an intention revealing name before reading such inner query.</p>

<p>The above example can be made easier to read using <code>WITH</code> clause as follows:</p>

<pre><code class="sql Easy to read">WITH sorted_by_modify_date AS (
    SELECT *, ROW_NUMBER() OVER (PARTITION BY customer_id 
                                  ORDER BY last_modify_date DESC) AS rank 
    FROM stg_customer
)
SELECT * FROM sorted_by_modify_date
WHERE sorted_by_modify_date.rank = 1;  
</code></pre>

<p>As the second example demonstrates, <code>WITH</code> clause solves two problems: 1) names come first, 2) sub-queries are un-nested.
The <code>WITH</code> clause puts the name above the code, like declaring a function with code in the sub-query.
We can pick a meaningful, intention revealing name for it and we can refer to that &ldquo;function&rdquo; in the following sub-queries in the same <code>WITH</code> clause.
Moreover, the most powerful impact of <code>WITH</code> clause is that sub-queries can be un-nested to follow the order and flow of developers' thoughts.
We can define multiple queries for multiple steps, and each of them can refer to the <em>previously</em> defined queries in the same <code>WITH</code> clause.</p>

<p>The following example demonstrates the power of <a href="https://en.wikipedia.org/wiki/Literate_programming">literate programming</a> in SQL, enabled by <code>WITH</code> clause:</p>

<pre><code class="sql Traffic classification of a Music website">WITH Total_Traffic AS
(
    SELECT temp.* from temp as clickstream_data
    where .... -- filtering
)
, Rock_Music as
(
    select * from Total_Traffic
    WHERE lower(evar28) LIKE 'rock_mus%'
)
, Instrumental_Music as
(
    select * from Total
    WHERE evar28 LIKE '%[ins_mus]%'
)
, Defined_Traffic as
(
    select * from Rock_Music
    UNION
    select * from Instrumental_Music
)
select traffic_date_key
, count(distinct visitor_id) as unique_visitor
from Defined_Traffic 
group by traffic_date_key
</code></pre>

<p>The purpose of this query is to find the daily number of &ldquo;Defined&rdquo; unique visitors from clickstream data.
Finding daily total unique visitors from Clickstream data is easy and, by subtracting &ldquo;Defined&rdquo; numbers from &ldquo;Total&rdquo; numbers, we can find the &ldquo;Unknown&rdquo; traffic numbers that help determine marketing decisions.
Note that the total &ldquo;defined&rdquo; unique visitor count is NOT equal to sum of all unique visitor counts from each classification (e.g., &ldquo;Rock&rdquo; + &ldquo;Instrumental&rdquo;) since some visitors will listen to both Rock and Instrumental music on the website.</p>

<p>It would be hard, if not impossible, to write such query using only nested sub-queries and achieve the same readability.
The ease of reading is from a combination of top-down code structure and meaningful block names before code blocks, both are properties of <code>WITH</code> clause.</p>

<p>In the past, without <code>WITH</code> clause, we used to create <code>TEMPORARY TABLES</code> in Vertica to save the immediate steps.
Now, we have a native SQL solution in <code>WITH</code> clause and a more powerful technique to create sub-queries.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Virtual Machine for ETL Testing]]></title>
    <link href="http://tdongsi.github.io/blog/2016/01/10/find-and-replace-a-string-in-multiple-files/"/>
    <updated>2016-01-10T23:49:15-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/01/10/find-and-replace-a-string-in-multiple-files</id>
    <content type="html"><![CDATA[<h3>Vertica Virtual Machine as sandbox test environment</h3>

<p>When developing data-warehouse solutions in Vertica, you want to set up some test environment.
Ideally, you should have separate schema for each developer.
However, it is usually NOT possible in my experience: developers and test engineers have to share very few schemas in development environment.
The explanation that I usually get is that having a schema for each developer will not scale in database maintenance and administration, and there are likely some limits in Vertica&rsquo;s commercial license.
If that is the case, I recommend that we look into using Vertica Community Edition on <strong>Virtual Machines (VMs)</strong> for sandbox test environment, as a cheap alternative.</p>

<p>Are VMs really necessary in data-warehouse testing? When testing Extract-Transform-Load (ETL) processes, I find that many of test cases require regular set-up and tear-down, adding mock records to represent corner cases, and/or running ETLs multiple times to simulate daily runs of those processes.
Regular tear-down requires dropping multiple tables regularly, which requires much greater care and drains much mental energy when working with others' data and tables.
Similarly, adding mock records into some commonly shared tables might affect others when they assume the data is production-like.
Running ETL scripts regularly, which could be computationally intensive, on a shared Vertica cluster might affect the performance or get affected by others' processes.</p>

<p>In short, for these tests, I cannot use the common schema that is shared with others since it might interfere others and/or destroy valuable common data.
Using a Vertica VM as the sandbox test environment helps us minimize interference to and from others' data and activities.</p>

<h3>Single-node VM and KSAFE clause</h3>

<p>I have been using a <strong>single-node</strong> Vertica VM to run tests for sometime. And it works wonderfully for testing purpose, especially when you want to isolate issues, for example, a corner case. The Vertica VM can be downloaded from HP Vertica&rsquo;s support website (NOTE: As of 2016 Jan 1st, the Vertica 7.1 VM is taken down while the Vertica 7.2 VM is not available).</p>

<p>The only minor problem is when we add <code>KSAFE 1</code> in our DDL scripts (i.e., <code>CREATE TABLE</code> statements) for production purposes which gives error on single-node VM when running DDL scripts to set up schema.
The reason is that Vertica database with 1 or 2 hosts cannot be <em>k-safe</em> (i.e., it may lose data if it crashes) and three-node cluster is the minimum requirement to have <code>KSAFE 1</code> in <code>CREATE TABLE</code> statements to work.</p>

<p>Even then, the workaround for running those DDL scripts in tests is easy enough if all DDL scripts are all located in a single folder. The idea is that since <code>KSAFE 1</code> does not affect ETL processes' transform logics, we can remove those KSAFE clauses to set up the test schema and go ahead with our ETL testing. Specifically, in my project, my workflow for ETL testing with <strong>Git</strong> is as follows:</p>

<ul>
<li>Branch the latest code (<code>develop</code> branch) into a temporary branch (e.g., <code>local/develop</code> branch).</li>
<li>Find and remove <code>KSAFE 1</code> in all DDL files (see subsection below).</li>
<li>While still in <code>local/develop</code> branch, commit all these changes in a <strong>single</strong> commit with some unique description (e.g., &ldquo;KSAFE REMOVAL&rdquo;).</li>
<li>Add unit and functional tests to ETL scripts in this branch.</li>
<li>After tests are properly developed and checked-in, reverse the &ldquo;KSAFE REMOVAL&rdquo; commit above.

<ul>
<li>In SourceTree, it could be done by a simple right-click on that commit and selecting &ldquo;Reverse Commit&rdquo;.</li>
</ul>
</li>
<li>Merge <code>local/develop</code> branch into <code>develop</code> branch. You will now have your tests with the latest codes in <code>develop</code> branch.</li>
</ul>


<h4>Find and replace a string in multiple files</h4>

<p>There are times and times again that you find that you have to replace every single occurrences of some string in multiple files with another string. Finding and removing <code>KSAFE 1</code> like the above workflow is an example where &ldquo;removing string&rdquo; is a special case of &ldquo;replacing string&rdquo; with nothing. This operation can be quickly done by the following bash command:</p>

<pre><code>grep -rl match_string your_dir/ | xargs sed -i 's/old_string/new_string/g'
</code></pre>

<p>If you are familiar with bash scripting, the above command is straight forward. This quick explanation is for anyone who does not understand the command:</p>

<ul>
<li><code>grep</code> command finds all files in <code>your_dir</code> directory that contain <code>match_string</code>. <code>-l</code> option makes sure it will return a list of files</li>
<li><code>sed</code> command then execute the replacement regex on all those files. A regex tip: the forward slash <code>/</code> delimiter could be another delimiter (e.g., <code>#</code>). This might be useful if you need to search HTML files.</li>
</ul>


<p>Example: In my case, all the DDL scripts are in multiple sub-directories under <code>tables</code> directory. To find and remove all <code>KSAFE 1</code> occurrences, the command is:</p>

<pre><code>grep -rl 'KSAFE 1' tables | xargs sed -i 's/KSAFE 1//g'
</code></pre>

<p>This will search for the string <code>KSAFE 1</code> in all files in the <code>tables</code> directory and replace <code>KSAFE 1</code> with nothing <code>''</code> for each occurrence of the string in each file.</p>
]]></content>
  </entry>
  
</feed>
