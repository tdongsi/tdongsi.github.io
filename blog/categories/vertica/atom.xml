<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Vertica | Personal Programming Notes]]></title>
  <link href="http://tdongsi.github.io/blog/categories/vertica/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/"/>
  <updated>2018-01-06T18:34:20-08:00</updated>
  <id>http://tdongsi.github.io/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Docker Image for ETL Development in Vertica]]></title>
    <link href="http://tdongsi.github.io/blog/2016/09/01/docker-image-for-vertica/"/>
    <updated>2016-09-01T11:38:27-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/09/01/docker-image-for-vertica</id>
    <content type="html"><![CDATA[<p>Docker is Awesome!!!</p>

<!--more-->


<p>I wish I knew Docker earlier, before going through the hassle of creating VMs for local ETL development and testing.
Docker can make the whole setup even easier.
It can be done in just a few commands, using <a href="https://github.com/tdongsi/vertica/tree/master/docker">a Vertica Dockerfile</a>, created based on <a href="https://github.com/wmarinho/docker-hp-vertica">this</a>.
In addition to easy virtualization, Docker also enables the entire setup can be automated in a script, allowing it to be version-controlled (i.e., <a href="https://en.wikipedia.org/wiki/Infrastructure_as_Code">Infrastructure as Code</a>).</p>

<p>Some notes about this Dockerfile, compared to <code>wmarinho</code>&rsquo;s:</p>

<ul>
<li>Added new schema, new user and new role as examples. Avoid using <code>dbadmin</code> user for development purpose.</li>
<li>Added Java and Maven for Java-based ETL and automated test execution.</li>
<li>Demonstrated running Bash and SQL scripts to initialize the container/database.</li>
</ul>


<h3>How to run</h3>

<p>Before running <code>docker build</code>, download Vertica Community Edition from <a href="https://my.vertica.com/">https://my.vertica.com/</a> and place in the same folder as the <code>Dockerfile</code>.
This <code>Dockerfile</code> takes &ldquo;vertica-7.2.3-0.x86_64.RHEL6.rpm&rdquo; as the install file.</p>

<pre><code class="plain Windows output">epigineer@epigineerpc MINGW64 /c/Work/Github/vertica/docker (develop)
$ docker build -t vertica .
...

epigineer@epigineerpc MINGW64 /c/Work/Github/vertica/docker (develop)
$ docker images
REPOSITORY          TAG                 IMAGE ID            CREATED
SIZE
vertica             latest              d2607fa1f457        13 seconds ago
1.638 GB
&lt;none&gt;              &lt;none&gt;              486163abe73f        11 minutes ago
1.638 GB
centos              centos6.6           2c886f766286        8 weeks ago
202.6 MB

epigineer@epigineerpc MINGW64 /c/Work/Github/vertica/docker (develop)
$ docker run -p 5433:5433 --hostname=verthost --privileged=true --memory 4G -t
-i d2607fa1f457 /bin/bash
Info: no password specified, using none
        Starting nodes:
                v_docker_node0001 (127.0.0.1)
        Starting Vertica on all nodes. Please wait, databases with large catalog
 may take a while to initialize.
        Node Status: v_docker_node0001: (DOWN)
        Node Status: v_docker_node0001: (DOWN)
        Node Status: v_docker_node0001: (DOWN)
        Node Status: v_docker_node0001: (DOWN)
        Node Status: v_docker_node0001: (UP)
Database docker started successfully
creating schema
CREATE SCHEMA
creating user
CREATE USER
creating role
CREATE ROLE
grant usage, create on schema
GRANT PRIVILEGE
</code></pre>

<h3>Troubleshooting Notes</h3>

<p>In Mac OSX, remember that the <code>entrypoint.sh</code> file should have executable permission.
Otherwise, you might get the error &ldquo;oci runtime error: exec: &rdquo;/entrypoint.sh": permission denied".
After changing the file permission, you have to rebuild the image with <code>docker build</code> before <code>docker run</code> again.</p>

<h4>&ldquo;Insufficient resources&rdquo; error when running ETL</h4>

<p>You might get &ldquo;Insufficient resources to execute plan on pool general &hellip; Memory exceeded&rdquo; error when running a large ETL script against the Vertica container.
For complex ETL, Vertica might need additional memory to execute the query plan.
Simply setting higher memory allocation using <code>--memory</code> option of <code>docker run</code> might NOT work if using <strong>Docker Toolbox</strong>.
To set higher memory allowance, stop the <code>docker-machine</code> and set memory as follows:</p>

<pre><code class="plain">tdongsi$ docker-machine stop
Stopping "default"...
Machine "default" was stopped.

tdongsi$ VBoxManage modifyvm default --memory 8192

tdongsi$ docker-machine start
Starting "default"...
(default) Check network to re-create if needed...
(default) Waiting for an IP...
Machine "default" was started.
Waiting for SSH to be available...
Detecting the provisioner...
Started machines may have new IP addresses. You may need to re-run the `docker-machine env` command.
</code></pre>

<p>Note that after running the above commands, <code>docker-machine inspect</code> still shows <code>"Memory":"2048"</code>.
To verify if memory is properly allocated as desired, run <code>free</code> command, for example, inside the container to verify.</p>

<h3>Links</h3>

<ul>
<li><a href="https://github.com/tdongsi/vertica/tree/master/docker">My Dockerfile for ETL development and testing on Vertica</a></li>
<li><a href="https://github.com/wmarinho/docker-hp-vertica">Original Dockerfile</a></li>
<li><a href="https://www.docker.com/">Docker</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Analytic Functions in MySQL]]></title>
    <link href="http://tdongsi.github.io/blog/2016/08/17/analytic-functions-in-mysql/"/>
    <updated>2016-08-17T23:12:54-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/08/17/analytic-functions-in-mysql</id>
    <content type="html"><![CDATA[<p>MySQL has traditionally lagged behind in support for the SQL standard.
Unfortunately, from my experience, MySQL is often used as the sandbox for SQL code challenges and interviews.
If you are used to work with <a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/SQLReferenceManual.htm">Vertica SQL</a>, writing SQL statements in MySQL can be challenging exercises, NOT necessarily in a good way, because many useful features are not supported.</p>

<!--more-->


<h3>WITH clause</h3>

<p>As discussed in this <a href="/blog/2016/02/03/vertica-6-with-clause/">blog post</a>, <code>WITH</code> clause syntax, also known as <em>Common Table Expressions</em> (CTE), is thankfully supported in Vertica.
In summary, <code>WITH</code> clause allows us to arrange sub-queries, usually intermediate steps, in a complex SQL query in sequential, logical order.
This will make the complex queries easier to compose and read: we can write steps by steps of the query from top to bottom like a story (i.e., <a href="https://en.wikipedia.org/wiki/Literate_programming">literate programming</a>).
Unfortunately, <code>WITH</code> clause is not supported by MySQL although this feature has been requested since <a href="https://bugs.mysql.com/bug.php?id=16244">2006</a>.
There are <a href="http://guilhembichot.blogspot.fr/2013/11/with-recursive-and-mysql.html">work-arounds</a> for MySQL&rsquo;s lack of CTE, but the easiest way is probably to revert back to using nested subqueries.</p>

<p>Personally, lack of <code>WITH</code> clause support in MySQL is my greatest hindrance as I often ended up writing queries using <code>WITH</code> clauses as first draft before rewriting those queries using nested subqueries.
This might appear clumsy in SQL interviews even though writing SQL codes with CTE instead of subqueries is the recommended practice for maintainable code.</p>

<h3>Analytic functions</h3>

<p>Another regrettable hindrance when working in MySQL is its lack of analytic functions such as <code>ROW_NUMBER</code>, <code>RANK</code> and <code>DENSE_RANK</code>.
Those <a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/Functions/Analytic/AnalyticFunctions.htm">analytic functions</a> are supported in Vertica.
The difference between these three functions can be a bit subtle, and would be best described in the following example:</p>

<pre><code class="sql Example of ROW_NUMBER, RANK, and DENSE_RANK functions">SELECT customer_name, SUM(annual_income),
ROW_NUMBER () OVER (ORDER BY TO_CHAR(SUM(annual_income),'100000') DESC) row_number, 
RANK () OVER (ORDER BY TO_CHAR(SUM(annual_income),'100000') DESC) rank, 
DENSE_RANK () OVER (ORDER BY TO_CHAR(SUM(annual_income),'100000') DESC) dense_rank 
FROM customer_dimension
GROUP BY customer_name
LIMIT 15;
</code></pre>

<p>The outputs of these functions are only different if there are duplicates in <code>SUM(annual_income)</code> value, as seen in rows 75-81 in the example output below:</p>

<table border="1"><tr BGCOLOR="#CCCCFF"><th>customer_name</th><th>SUM</th><th>row_number</th><th>rank</th><th>dense_rank</th></tr>
<tr><td>Theodore R. King</td><td>97444</td><td>71</td><td>71</td><td>71</td></tr>
<tr><td>Laura Y. Pavlov</td><td>97417</td><td>72</td><td>72</td><td>72</td></tr>
<tr><td>Carla . Garcia</td><td>97371</td><td>73</td><td>73</td><td>73</td></tr>
<tr><td>Jack Z. Miller</td><td>97356</td><td>74</td><td>74</td><td>74</td></tr>
<tr><td>Steve W. Williams</td><td>97343</td><td>75</td><td>75</td><td>75</td></tr>
<tr><td>Lauren Y. Rodriguez</td><td>97343</td><td>76</td><td>75</td><td>75</td></tr>
<tr><td>Lucas . Webber</td><td>97318</td><td>77</td><td>77</td><td>76</td></tr>
<tr><td>Sarah N. Moore</td><td>97243</td><td>78</td><td>78</td><td>77</td></tr>
<tr><td>Lucas O. Li</td><td>97184</td><td>79</td><td>79</td><td>78</td></tr>
<tr><td>Doug K. Reyes</td><td>97166</td><td>80</td><td>80</td><td>79</td></tr>
<tr><td>Michael . Weaver</td><td>97162</td><td>81</td><td>81</td><td>80</td></tr>
</table>


<p><br/></p>

<p>Sadly, these useful analytic functions are not supported in MySQL.
Fortunately, MySQL supports user variables in SQL queries and we can reproduce those functionalities in MySQL using variables and subqueries as follows:</p>

<pre><code class="sql ROW_NUMBER, RANK, and DENSE_RANK functions in MySQL">-- In Vertica
SELECT 
ROW_NUMBER () OVER (PARTITION BY col_1, col_2 ORDER BY col_3 DESC) AS row_number,
RANK () OVER (PARTITION BY col_1, col_2 ORDER BY col_3 DESC) AS rank,
DENSE_RANK () OVER (PARTITION BY col_1, col_2 ORDER BY col_3 DESC) AS dense_rank,
t.* 
FROM table_1 t

-- In MySQL
SELECT
@row_num:=IF(@prev_col_1=t.col_1 AND @prev_col_2=t.col_2, @row_num+1, 1) AS row_number,
@rank:=IF(@prev_col_1=t.col_1 AND @prev_col_2=t.col_2 AND @prev_col_3=col_3, @rank, @row_num) AS rank,
@dense:=IF(@prev_col_1=t.col_1 AND @prev_col_2=t.col_2, IF(@prev_col_3=col_3, @dense, @dense+1), 1) AS dense_rank,
@prev_col_1 = t.col_1,
@prev_col_2 = t.col_2,
@prev_col_3 = t.col_3,
t.*
FROM (SELECT * FROM table_1 ORDER BY col_1, col_2, col_3 DESC) t,
     (SELECT @row_num:=1, @dense:=1, @rank:=1, @prev_col_1:=NULL, @prev_col_2:=NULL, @prev_col_3:=NULL) var
</code></pre>

<p>The MySQL work-around is intentionally generic so that I can adapt it to any use case.
In addition, it intentionally has a single pass (no <code>SET</code> statements, temporary table) since most SQL code challenges expect a single query.
Finally, note that the above MySQL solution is intentionally incomplete to make it less convoluted.
You need to put that solution in a subquery and <code>SELECT</code> only relevant columns from it.</p>

<p>As an example, the above code template is used to solve <a href="https://leetcode.com/problems/rank-scores/">this Rank Scores problem</a>.
In summary, the question asks for <code>DENSE_RANK</code> functionality to be applied on Score column.</p>

<pre><code class="plain Input table">+----+-------+
| Id | Score |
+----+-------+
| 1  | 3.50  |
| 2  | 3.65  |
| 3  | 4.00  |
| 4  | 3.85  |
| 5  | 4.00  |
| 6  | 3.65  |
+----+-------+
</code></pre>

<pre><code class="plain Expected output">+-------+------+
| Score | Rank |
+-------+------+
| 4.00  | 1    |
| 4.00  | 1    |
| 3.85  | 2    |
| 3.65  | 3    |
| 3.65  | 3    |
| 3.50  | 4    |
+-------+------+
</code></pre>

<p>The solution in Vertica SQL would be straight-forward as follows:</p>

<pre><code class="sql Solution in Vertica SQL">select Score,
DENSE_RANK() OVER (ORDER BY Score DESC) AS Rank
FROM Scores;
</code></pre>

<p>In MySQL, apply the above code template and note that there is no <code>partition clause</code> to arrive at the following solution:</p>

<pre><code class="sql Solution in MySQL">SELECT Score, Rank FROM
( SELECT t.Score,
@dense:=IF(@prev_col2=t.Score, @dense, @dense+1) AS Rank,
@prev_col2:=t.Score
FROM (SELECT Score FROM Scores ORDER BY Score DESC) t, 
(SELECT @dense:=0, @prev_col2:=NULL) var ) x
</code></pre>

<p>Note that the outer <code>SELECT</code> is used to only expose only columns of interest while the main SQL code is enclosed in a subquery.</p>

<h3>Reference</h3>

<ul>
<li><a href="http://www.folkstalk.com/2013/03/grouped-row-number-function-mysql.html">ROW_NUMBER in MySQL</a></li>
<li><a href="http://www.folkstalk.com/2013/03/grouped-dense-rank-function-mysql-sql-query.html">DENSE_RANK in MySQL</a>: this link actually shows <code>RANK</code> implementation.</li>
<li><a href="https://my.vertica.com/docs/7.1.x/HTML/index.htm#Authoring/SQLReferenceManual/Functions/Analytic/AnalyticFunctions.htm">Vertica Analytic Functions</a></li>
<li><a href="http://dev.mysql.com/doc/refman/5.7/en/user-variables.html">MySQL user variables</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bash Trap]]></title>
    <link href="http://tdongsi.github.io/blog/2016/03/02/bash-trap/"/>
    <updated>2016-03-02T00:07:48-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/03/02/bash-trap</id>
    <content type="html"><![CDATA[<p>In this post, we discuss common usage of bash <code>trap</code> to ensure proper cleanup operations in Bash scripts.
It also discusses a common idiom <code>trap cleanup INT TERM EXIT</code> where other signals such as INT and TERM is also trapped in addition to EXIT.
While such idiom could be valid in some Unix system, it is usually redundant and can be simply wrong (duplicate executions) in most cases, as shown on Mac.
A simple test is provided to verify if such idiom is applicable in your current system.</p>

<!--more-->


<h3>Standard usage</h3>

<p>There is a simple idiom to ensure your bash scripts to always do proper cleanup operations before exiting, even when something goes wrong during execution.
In the context of Java or Python, this is similar to a <code>finally</code> clause that will execute after any exception is caught during execution.</p>

<pre><code class="bash DO THIS"># Setup trap to cleanup before exiting script
function cleanup {
    echo "Removing temp files..."
    if [[ -f $CMD_TMPFILE ]] ; then
        rm $CMD_TMPFILE
    fi
    if [[ -f $LOG_TMPFILE ]] ; then
        rm $LOG_TMPFILE
    fi
}
trap cleanup EXIT

# Setup

# Thousand lines of code here
</code></pre>

<p>Putting the cleanup operations at the end of the bash script might not work in cases of error.
Since the bash script already stops executing due to some fatal error, those clean up commands might never run.</p>

<pre><code class="bash DON'T DO THIS">
# Setup

# Thousand lines of code here

# This might not run when there is error
echo "Removing temp files..."
if [[ -f $CMD_TMPFILE ]] ; then
    rm $CMD_TMPFILE
fi
if [[ -f $LOG_TMPFILE ]] ; then
    rm $LOG_TMPFILE
fi
</code></pre>

<p>For example, in Vertica, you should always run <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/Functions/VerticaFunctions/START_REFRESH.htm"><code>SELECT START_REFRESH()</code></a>
at the end of a deployment script, regardless of any error encountered during script execution.
It is a good candidate for using <code>trap</code> statement.
Adding those commands at the end of the script will not work in cases there is an error during deployment, and you might end up with &ldquo;AHM Does Not Advance&rdquo;-related errors (see this <a href="/blog/2016/02/29/vertica-9-refresh-projections/">post</a>).</p>

<h3>Trap multiple signals</h3>

<p>Note that many online examples for <code>trap</code> use a list of signals for cleanup tasks like this <code>trap cleanup INT TERM EXIT</code>, i.e., trapping not only EXIT signal but also INT and TERM signals.
I believe that if <code>EXIT</code> signal is used, other signals such as <code>INT</code> or <code>TERM</code> are redundant for cleanup purposes.
<code>EXIT</code> or 0 signal is invoked when the shell exits, an event that also happens when an <code>INT</code> or <code>TERM</code> signal is received.
It is easy to confirm that with the following short bash script:</p>

<pre><code class="plain Trap tests in Mac OSX">MTVL1288aeea2-82:code tdongsi$ cat test_trap.sh
#!/bin/bash
trap 'echo SIGNAL CAPTURED' EXIT
sleep 3

MTVL1288aeea2-82:code tdongsi$ ./test_trap.sh &amp; sleep 1; kill -INT %1
[1] 6613
SIGNAL CAPTURED
[1]+  Interrupt: 2            ./test_trap.sh

MTVL1288aeea2-82:code tdongsi$ ./test_trap.sh &amp; sleep 1; kill -TERM %1
[1] 6624
SIGNAL CAPTURED
[1]+  Terminated: 15          ./test_trap.sh
</code></pre>

<p>As shown above, a lone <code>EXIT</code> is enough to capture <code>INT</code> and <code>TERM</code> signals.
Having said that, I understand that my tests can only verify bash on Mac OSX.
There are probably different shell variants on different operating systems which do not always work that way.</p>

<p>The problem of those <code>trap</code> examples lies in when someone copies and uses the code directly from the web, without understanding how it works.
Listing multiple signals can make the <code>cleanup</code> steps executed twice, once for the signal such as <code>TERM</code> and once for <code>EXIT</code>, as shown in the modified experiment below.
Not all cleanup steps could be and should be executed twice.
For example, it is almost always true that removing some temporary file/folder should not be executed twice during a cleanup.</p>

<pre><code class="plain Problem of trapping multiple signals">MTVL1288aeea2-82:code tdongsi$ cat test_trap.sh
#!/bin/bash
trap 'echo SIGNAL CAPTURED' INT TERM EXIT
sleep 3

MTVL1288aeea2-82:code tdongsi$ ./test_trap.sh &amp; sleep 1; kill -INT %1
[1] 7258
SIGNAL CAPTURED
SIGNAL CAPTURED
[1]+  Exit 130                ./test_trap.sh

MTVL1288aeea2-82:code tdongsi$ ./test_trap.sh &amp; sleep 1; kill -TERM %1
[1] 7278
Terminated: 15
SIGNAL CAPTURED
SIGNAL CAPTURED
[1]+  Exit 143                ./test_trap.sh
</code></pre>

<p>In short, you should know how <code>trap</code> works on your production system before listing multiple signals as its parameters, especially when coupled with <code>EXIT</code> signal.</p>

<h3>Other usage notes</h3>

<p>The signal names might be specified with or without prefix <code>SIG</code> or even with numeric values for signal numbers, e.g., 2 for INT (see list below).</p>

<pre><code class="plain List of signals">MTVL1288aeea2-82:octopress tdongsi$ kill -l
 1) SIGHUP   2) SIGINT   3) SIGQUIT  4) SIGILL
 5) SIGTRAP  6) SIGABRT  7) SIGEMT   8) SIGFPE
 9) SIGKILL 10) SIGBUS  11) SIGSEGV 12) SIGSYS
13) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGURG
17) SIGSTOP 18) SIGTSTP 19) SIGCONT 20) SIGCHLD
21) SIGTTIN 22) SIGTTOU 23) SIGIO   24) SIGXCPU
25) SIGXFSZ 26) SIGVTALRM   27) SIGPROF 28) SIGWINCH
29) SIGINFO 30) SIGUSR1 31) SIGUSR2

OR 

MTVL1288aeea2-82:octopress tdongsi$ man signal
</code></pre>

<p>If one of the signals specified in <code>trap</code> statement is <code>DEBUG</code>, the list of COMMANDS specified in <code>trap</code> statement will be executed after every simple command.
This is useful for debugging purpose.
The following example is taken from <a href="http://tldp.org/LDP/Bash-Beginners-Guide/html/chap_12.html">here</a>:</p>

<pre><code class="bash Tracing when a variable is used">declare -t VARIABLE=value
trap "echo VARIABLE is being used here." DEBUG

# rest of the script
</code></pre>

<h3>References</h3>

<ol>
<li><a href="http://tldp.org/LDP/Bash-Beginners-Guide/html/chap_12.html">Signals and Traps</a></li>
<li><a href="http://redsymbol.net/articles/bash-exit-traps/">Other usages</a></li>
<li><a href="http://wiki.bash-hackers.org/commands/builtin/declare">declare</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vertica: Refresh Your Projections]]></title>
    <link href="http://tdongsi.github.io/blog/2016/02/29/vertica-9-refresh-projections/"/>
    <updated>2016-02-29T00:54:02-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/02/29/vertica-9-refresh-projections</id>
    <content type="html"><![CDATA[<p>Most information presented in this post is directly quoted from <a href="https://community.dev.hpe.com/t5/Vertica-Knowledge-Base/Understanding-Vertica-Epochs/ta-p/233749">this page</a>.</p>

<p><strong>Epoch</strong>: An epoch is 64-bit number that represents a logical time stamp for the data in Vertica.
The epoch advances when the logical state of the system changes or when the data is committed with a DML operation (INSERT, UPDATE, MERGE, COPY, or DELETE).
The <code>EPOCHS</code> system table contains the date and time of each closed epoch and the corresponding epoch number of the closed epoch.</p>

<pre><code class="plain epochs table">=&gt; select * from epochs;

epoch_close_time              epoch_number
2016-03-04 21:44:24.192495  610131
</code></pre>

<p><strong>Ancient History Mark (AHM)</strong>: A large epoch map can increase the catalog size.
The ancient history mark is the epoch prior to which historical data can be purged from physical storage.
You cannot run any historical queries prior to the AHM.
By default, Vertica advances the AHM at an interval of 5 minutes.</p>

<p>There are scenarios that the ancient history marker does not advance: there is an unrefreshed <a href="/blog/2016/02/07/vertica-7-projections/">projection</a>.
To find about the unrefreshed projection, use the following command:</p>

<pre><code class="plain">SELECT * FROM projections where is_up_to_date = 'f';
</code></pre>

<p>It was already mentioned in the HPE page that AHM will not advance if there’s any projection not up to date.
However, it also means that AHM will also not advance if there’s no activity (data insert/update or delete) on a table.
AHM could lag behind at the create epoch of some unrefreshed projection.
Therefore, we need to make sure we are <strong>always</strong> refreshing projections after creating them.</p>

<p>Generally, you can refresh a projection by executing the <code>START_REFRESH</code> meta-function, which is a background process, or the <code>REFRESH</code> meta-function, which is a foreground process.</p>

<pre><code class="plain">select START_REFRESH();
</code></pre>

<h3>Links</h3>

<ol>
<li><a href="https://community.dev.hpe.com/t5/Vertica-Knowledge-Base/Understanding-Vertica-Epochs/ta-p/233749">Epoch and AHM</a></li>
<li><a href="https://community.dev.hpe.com/t5/Vertica-Blog/Best-Practices-for-Refreshing-Large-Projections/ba-p/229505">Best Practices</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vertica: Performance Optimization Notes]]></title>
    <link href="http://tdongsi.github.io/blog/2016/02/13/vertica-8-performance-tuning/"/>
    <updated>2016-02-13T23:52:44-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/02/13/vertica-8-performance-tuning</id>
    <content type="html"><![CDATA[<p>In this post, most of optimization notes for Vertica performance are from our team&rsquo;s interaction with <a href="http://www.nexius.com/software-and-business-intelligence/">Nexius</a> consultants.
Also see <a href="/blog/2015/12/16/vertica-tip-best-practices/">Vertica Best Practices</a>.</p>

<!--more-->


<h3><code>NOT IN</code> better than <code>NOT EXISTS</code></h3>

<p>When we want to insert a row into a dimension table AND check for duplicates at the same time, we usually do this in DML scripts:</p>

<pre><code class="sql BAD">SELECT 'United States', 'English' 
WHERE NOT EXISTS (SELECT 'x' FROM dim_country WHERE country_name = 'United States')
</code></pre>

<p>However, for all such inserts, we were recently informed that it is better <strong>in Vertica</strong> to do <code>NOT IN</code> instead of <code>NOT EXISTS</code>.
So, for example above:</p>

<pre><code class="sql GOOD">SELECT 'United States', 'English' 
WHERE 'United States' NOT IN (select country_name from dim_country)
</code></pre>

<h3>Avoid using <code>LEFT JOIN</code> to check existence</h3>

<p>Let&rsquo;s say we have an ETL that regularly inserts new data into an existing dimension table.</p>

<pre><code class="sql BAD">INSERT INTO dim_country                    
(
    country_id,
    country_name,
    country_language,
) 
SELECT ssp.country_id,
    ssp.country_name,
    ssp.country_language,
FROM staging_table ssp
LEFT JOIN dim_country dc on dc.country_id=ssp.country_id
WHERE dc.country_id is NULL;
</code></pre>

<p>We are sometimes doing <code>LEFT JOIN</code> like this only to determine whether or not an entry already exists in the table.
It would be faster to use a <code>WHERE</code> clause instead to perform that existence check.
Although it might sound counter-intuitive, but reducing <code>JOIN</code> operations like this has been regularly recommended.</p>

<pre><code class="sql GOOD">INSERT INTO dim_country                    
(
    country_id,
    country_name,
    country_language,
) 
SELECT ssp.country_id,
    ssp.country_name,
    ssp.country_language,
FROM staging_table ssp
WHERE ssp.country_id NOT IN (SELECT country_id FROM dim_country);
</code></pre>

<h3>Avoid function calls in <code>WHERE</code> and <code>JOIN</code> clauses</h3>

<p>For this performance tip, we make a slight change to the example ETL in the last section above where <code>country_id</code> column is removed. In this case, we can use a normalized <code>country_name</code> as the ID to check for existing entries in the table:</p>

<pre><code class="sql BAD">INSERT INTO dim_country                    
(
    country_name,
    country_language,
) SELECT ssp.country_name,
    ssp.country_language,
FROM staging_table ssp
LEFT JOIN dim_country dc on lower(dc.country_name)=lower(ssp.country_name)
WHERE dc.country_name is NULL;
</code></pre>

<p>In this example, we normalize <code>country_name</code> to lower case. Note that <code>WHERE</code> clause should be used instead of <code>LEFT JOIN</code> as discussed above.</p>

<pre><code class="sql BETTER, but still BAD">INSERT INTO dim_country                    
(
    country_name,
    country_language,
) SELECT ssp.country_name,
    ssp.country_language,
FROM staging_table ssp
WHERE lower(ssp.country_name) NOT IN (SELECT lower(country_name) FROM dim_country);;
</code></pre>

<p>However, such change still has bad performance because, in general, function calls in <code>WHERE</code> and <code>JOIN</code> clauses should be avoided in Vertica.
In both examples above, calling functions like <code>LOWER</code> in <code>WHERE</code> and <code>JOIN</code> clauses will affect the performance of the ETLs.</p>

<p>The solution for this scenario is that, since we control what goes into dimension tables, we can ensure that columns like <code>country_name</code> are always stored in lower-case.
Then, we can do the same when creating the temporary table such as <code>staging_table</code> that we are comparing to for checking existence.</p>

<h3>Use  <a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/Functions/VerticaFunctions/ANALYZE_STATISTICS.htm">ANALYZE_STATISTICS</a></h3>

<p>Make sure to run <code>ANALYZE_STATISTICS</code> after all data loads.
Using this function, tables are analyzed for best performance in subsequent queries ran against it.
Without information from <code>ANALYZE_STATISTICS</code>, the query optimizer assumes uniform distribution of data values and equal storage usage for all projections.</p>

<p>Note that <code>ANALYZE_STATISTICS</code> is only supported on <em>local</em> temporary tables, but not on <em>global</em> temporary tables.
In addition, when we add <code>ANALYZE_STATISTICS</code> function calls into our ETL scripts, errors might be thrown when a second <code>ANALYZE_STATISTICS</code> call is made while the first is still running.
Those errors can be ignored but they must be caught accordingly to separate with other Vertica error messages.</p>

<h3>Avoid creating temporary tables using <code>SELECT</code></h3>

<p>Instead of creating temporary tables using <code>SELECT</code>, it is recommended to:</p>

<ol>
<li>Create the temporary table first without a projection.</li>
<li>Create a super <a href="/blog/2016/02/07/vertica-post-7/">projection</a> with the correct column encodings and <code>ORDER BY</code> clause</li>
<li>Populate it using <code>INSERT /*+ direct */ INTO</code>. Note the <code>/*+ direct */</code> hint to write data directly to disk, bypassing memory.</li>
<li>Run <code>ANALYZE_STATISTICS</code>. See the last section.</li>
</ol>


<p>For example, in a Vertica ETL script that runs daily, we usually create a temporary table to retrieve the latest records from a source table like this:</p>

<pre><code class="sql BAD">CREATE TEMPORARY TABLE customer_last_temp 
ON COMMIT PRESERVE ROWS
AS(
  select * from (
    select *,
    row_number() OVER (PARTITION BY customer_id ORDER BY last_modify_date DESC) AS rank 
    from  stg_customer rpt 
  ) t1 where t1.rank =1
);
</code></pre>

<p>In this example, <code>last_modify_date</code> is the <a href="https://en.wikipedia.org/wiki/Change_data_capture">CDC</a> column and <code>customer_id</code> is the primary key column.
Although this SQL statement is simple and easy to understand, it is really slow for a large and growing <code>stg_customer</code> table that contains updates to all customers on multiple dates, with millions of <em>new</em> customer entries each day.
Instead, the recommended coding pattern is to create a temporary table first without a projection:</p>

<pre><code class="sql Create a temporary table without projection">CREATE LOCAL TEMPORARY TABLE customer_last_temp  ( 
        customer_id                     int,
        subscribe_date                  timestamp,
        cancel_date                     timestamp,
        last_modify_date                timestamp,
)
ON COMMIT PRESERVE ROWS NO PROJECTION;
</code></pre>

<p>It is also recommended that the column names are explicitly specified, so that only required columns are created in the temporary table.
A <code>LOCAL</code> temporary table is created, instead of <code>GLOBAL</code>, so that we can use <code>ANALYZE_STATISTICS</code> functions as discussed above.
Next, create a super projection with the correct column encodings and <code>ORDER BY</code> clause:</p>

<pre><code class="sql Create a super projection">CREATE PROJECTION customer_last_temp_super (
      customer_id ENCODING DELTARANGE_COMP 
    , subscribe_date ENCODING GCDDELTA
    , cancel_date ENCODING BLOCKDICT_COMP     
    , last_modify_date ENCODING BLOCKDICT_COMP 
)
AS 
SELECT customer_id 
     , subscribe_date
     , cancel_date
     , last_modify_date
  FROM customer_last_temp 
 ORDER BY customer_id
SEGMENTED BY HASH (customer_id) ALL NODES;
</code></pre>

<p>Finally, insert &ldquo;directly&rdquo; into the temporary table:</p>

<pre><code class="sql Populate the table">INSERT /*+ direct */ INTO customer_last_temp (
      customer_id 
    , subscribe_date 
    , cancel_date 
    , last_modify_date 
)
WITH t1 AS (
    SELECT company_id 
         , subscribe_date 
         , cancel_date 
         , last_modify_date 
         , ROW_NUMBER() OVER (PARTITION BY customer_id 
                                  ORDER BY last_modify_date DESC) AS rank 
      FROM stg_customer AS rpt 
)
SELECT company_id 
     , subscribe_date 
     , cancel_date 
     , last_modify_date 
FROM t1
WHERE t1.rank = 1;  
</code></pre>

<p>The <code>WITH</code> clause is just a more readable way to write the sub-query in the original SQL statement (see <a href="/blog/2016/02/03/vertica-post-8/">WITH clause</a>).
In addition, the wildcard <code>*</code> in the original SQL query is also avoided, in case the table <code>stg_customer</code> is a very wide table.</p>
]]></content>
  </entry>
  
</feed>
