<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Jmockit | Personal Programming Notes]]></title>
  <link href="http://tdongsi.github.io/blog/categories/jmockit/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/"/>
  <updated>2016-09-25T23:57:50-07:00</updated>
  <id>http://tdongsi.github.io/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Unit Tests Pass on Local but Fail on CI]]></title>
    <link href="http://tdongsi.github.io/blog/2016/06/30/java-intermittent-test-failures/"/>
    <updated>2016-06-30T17:51:13-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/06/30/java-intermittent-test-failures</id>
    <content type="html"><![CDATA[<p>We have all seen it before: intermittent unit test failures.
It could be agonizing that unit tests pass locally, but then fail in the Jenkins unit test build.</p>

<p>In our experience, one of the most common causes is:
<strong>static initialization code that dynamically sets a static member variable from a config file value.</strong></p>

<p>What happens locally?
If you’re running from the command line, you probably have some environment variables set.
These allow some ConfigHelper class to find the resource properties files and load them.
In the end, code that looks like the following often ends up succeeding:</p>

<pre><code class="java DbQueue class">private static final String MY_CONFIG = ConfigHelper.getBoolean("config_key", false);
</code></pre>

<p>But the unit tests on the CI server run without being set up for a Tomcat application server run.
Instead, they run using some mock framework such as JMockit.
Mocking in this scenario is a good, desirable thing.
However, it also means that code like that ends up failing to find those resources.
In the example above, the class <code>DbQueue</code>&rsquo;s static code was invoked <strong>even though the class itself has been mocked out</strong>.
And very often, classes like that throw some misleading exceptions, especially when trying to load and convert to a numeric value from a resource.</p>

<p>So, how do we fix it?
How do we prevent that class static member initialization code from being invoked in Jenkins test build?
The answer is when we mock the class in JMockit using the <code>@Mocked</code> annotation, we can provide the <code>stubOutClassInitialization=true</code> parameter, like this:</p>

<pre><code class="java Mock with JMockit">public class MyTest {
    @Mocked( stubOutClassInitialization = true )
    DbQueue queue;

    ...
}
</code></pre>

<p>That will prevent the static code in the class <code>DbQueue</code> from running in Jenkins unit test builds.
The additional benefit of doing this <em>correctly</em> and <em>completely</em> is that we’ll be able to run our unit tests from inside Eclipse WITHOUT setting the <code>–DSBNHOME=</code> environment variable and the test will still complete as desired.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java: Unit Test Performance]]></title>
    <link href="http://tdongsi.github.io/blog/2016/06/06/java-unit-test-performance/"/>
    <updated>2016-06-06T22:47:42-07:00</updated>
    <id>http://tdongsi.github.io/blog/2016/06/06/java-unit-test-performance</id>
    <content type="html"><![CDATA[<p>According to <a href="https://www.youtube.com/watch?v=wEhu57pih5w">this</a>, the right way of automated testing is that we have lots of unit tests as majority of our overall automated tests, supplemented by a smaller set of functional tests and even fewer sets of integration tests (a.k.a., Test Automation Pyramid).
However, for that strategy to work, we should pay attention to unit test performance.
It is not productive for us developers to wait 30+ minutes to run unit tests locally, especially when we have multiple check-ins per day.
In addition, the runtime will get compounded as we add more unit tests.
Here, I list out few commonly observed mistakes to avoid and suggestions that frequently improve Java unit test performance.</p>

<p>1) Do NOT add loggings/printing to your tests.
Use TestNG assertions instead of checking screen output.
Remove from the test classes all the <code>System.out.println</code> statements (that we might add when we start writing unit tests).
The logs don&rsquo;t matter when we&rsquo;re running in parallel.
Moreover, it could add 5-10 minutes to the build time, regardless of running in sequential or parallel.</p>

<p>2) Another common mistake is to override the default <code>System.out</code> by calling <code>System.setOut(PrintStream)</code> and verify by asserting against log statements.
This tactic is often used to verify expected method invocations, which will subsequently generate some specific log entries.
For such behavior testing, consider using <a href="https://jmockit.googlecode.com/svn-history/r2056/trunk/www/tutorial/BehaviorBasedTesting.html">Jmockit Verifications</a> instead of depending on output of logs generated.</p>

<p>3) Mock logging and config classes if applicable.
Otherwise, we might encountered errors like &ldquo;Exception encountered, logging will be disabled&rdquo;, probably thrown by JMockit.
If there is any static initialization block in the mocked class for logging and configuration purposes, consider using <code>(stubOutClassInitialization = true)</code> (see <a href="/blog/2016/06/30/java-intermittent-test-failures/">this</a>).</p>

<p>4) Choosing the right parallel execution settings can substantially improve the execution time.
However, for parallel test runs, consider splitting big test classes (> 100 tests) that are taking much longer than others.
As we are running test classes in parallel across multiple JVMs, it is often the case that all JVMs are shut down except for one or two which are running some big test classes.
Splitting those classes into multiple smaller classes will distribute the load equally across multiple JVMs.</p>

<p>5) Out of all the <code>maven-surefire</code> options for running tests in parallel, the one that worked considering JMockit limitations with parallel execution (and our test structure) are as below:</p>

<pre><code class="xml Maven-surefire options">&lt;parallel&gt;classes&lt;/parallel&gt;
&lt;forkCount&gt;${forkCount}&lt;/forkCount&gt;
&lt;reuseForks&gt;false&lt;/resuseForks&gt;
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Use JMockit ONLY]]></title>
    <link href="http://tdongsi.github.io/blog/2016/02/21/java-1-single-mocking-framework/"/>
    <updated>2016-02-21T12:20:46-08:00</updated>
    <id>http://tdongsi.github.io/blog/2016/02/21/java-1-single-mocking-framework</id>
    <content type="html"><![CDATA[<p>A more general title would be &ldquo;Use a single mocking framework ONLY&rdquo;.
Personally, it just means that I should defer learning Wiremock&rsquo;s advanced features and learn JMockit (specifically JMockit 1.2x) which is recently adopted at work.</p>

<p>We know that mocking is a critical enabler for unit tests and automated functional tests that don’t require networks and databases and can complete in reasonable time.
Mocking tools work by integrating with and replacing critical parts of the Java Class Loader.
It means that having multiple mocking tools in use will lead to those tools contend to replace the class loader in JVM.
This will lead to complex and unexpected consequences and, as a result, random test failures and unreliable tests.
For example, we might have tests that work fine locally but start failing when running in combination with others (using other mocking tools) because different mocking frameworks take over the class loader in different order or in different ways.</p>

<p>To fix that, we need to standardize and settle on a single mocking framework for an organization or a project.</p>
]]></content>
  </entry>
  
</feed>
